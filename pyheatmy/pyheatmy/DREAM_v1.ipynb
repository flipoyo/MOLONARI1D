{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyheatmy import *\n",
    "from typing import List, Sequence, Union\n",
    "from numbers import Number\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from layers import AllPriors,LayerPriors, Layer, getListParameters\n",
    "PARAM_LIST = (\"moinslog10IntrinK\", \"n\", \"lambda_s\", \"rhos_cs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "capteur_riviere = pd.read_csv(\"../data/Point034_processed/processed_pressures.csv\", sep = ',', names = ['dates', 'tension', 'temperature_riviere'], skiprows=1)\n",
    "capteur_ZH = pd.read_csv(\"../data/Point034_processed/processed_temperatures.csv\", sep = ',', names = ['dates', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_40'], skiprows=1)\n",
    "etalonage_capteur_riv = pd.read_csv(\"../configuration/pressure_sensors/P508.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDates(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Convert dates from a list of strings by testing several different input formats\n",
    "    Try all date formats already encountered in data points\n",
    "    If none of them is OK, try the generic way (None)\n",
    "    If the generic way doesn't work, this method fails\n",
    "    (in that case, you should add the new format to the list)\n",
    "    \n",
    "    This function works directly on the giving Pandas dataframe (in place)\n",
    "    This function assumes that the first column of the given Pandas dataframe\n",
    "    contains the dates as characters string type\n",
    "    \n",
    "    For datetime conversion performance, see:\n",
    "    See https://stackoverflow.com/questions/40881876/python-pandas-convert-datetime-to-timestamp-effectively-through-dt-accessor\n",
    "    \"\"\"\n",
    "    formats = (\"%m/%d/%y %H:%M:%S\", \"%m/%d/%y %I:%M:%S %p\",\n",
    "               \"%d/%m/%y %H:%M\",    \"%d/%m/%y %I:%M %p\",\n",
    "               \"%m/%d/%Y %H:%M:%S\", \"%m/%d/%Y %I:%M:%S %p\", \n",
    "               \"%d/%m/%Y %H:%M\",    \"%d/%m/%Y %I:%M %p\",\n",
    "               \"%y/%m/%d %H:%M:%S\", \"%y/%m/%d %I:%M:%S %p\", \n",
    "               \"%y/%m/%d %H:%M\",    \"%y/%m/%d %I:%M %p\",\n",
    "               \"%Y/%m/%d %H:%M:%S\", \"%Y/%m/%d %I:%M:%S %p\", \n",
    "               \"%Y/%m/%d %H:%M\",    \"%Y/%m/%d %I:%M %p\",\n",
    "               None)\n",
    "    times = df[df.columns[0]]\n",
    "    for f in formats:\n",
    "        try:\n",
    "            # Convert strings to datetime objects\n",
    "            new_times = pd.to_datetime(times, format=f)\n",
    "            # Convert datetime series to numpy array of integers (timestamps)\n",
    "            new_ts = new_times.values.astype(np.int64)\n",
    "            # If times are not ordered, this is not the appropriate format\n",
    "            test = np.sort(new_ts) - new_ts\n",
    "            if np.sum(abs(test)) != 0 :\n",
    "                #print(\"Order is not the same\")\n",
    "                raise ValueError()\n",
    "            # Else, the conversion is a success\n",
    "            #print(\"Found format \", f)\n",
    "            df[df.columns[0]] = new_times\n",
    "            return\n",
    "        \n",
    "        except ValueError:\n",
    "            #print(\"Format \", f, \" not valid\")\n",
    "            continue\n",
    "    \n",
    "    # None of the known format are valid\n",
    "    raise ValueError(\"Cannot convert dates: No known formats match your data!\")\n",
    "\n",
    "convertDates(capteur_riviere)\n",
    "convertDates(capteur_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# conversion des mesures de pression\n",
    "intercept = float(etalonage_capteur_riv['P508'][2])\n",
    "a = float(etalonage_capteur_riv['P508'][3])\n",
    "b = float(etalonage_capteur_riv['P508'][4])\n",
    "capteur_riviere['dH'] = (capteur_riviere['tension'].astype(float)-intercept-capteur_riviere['temperature_riviere'].astype(float)*b)/a\n",
    "\n",
    "# conversion mesures de tempétratures\n",
    "capteur_riviere['temperature_riviere'] = capteur_riviere['temperature_riviere'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_10'] = capteur_ZH['temperature_10'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_20'] = capteur_ZH['temperature_20'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_30'] = capteur_ZH['temperature_30'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_40'] = capteur_ZH['temperature_40'] + ZERO_CELSIUS\n",
    "\n",
    "# définition des attributs de colonnes\n",
    "dH_measures = list(zip(capteur_riviere['dates'],list(zip(capteur_riviere['dH'], capteur_riviere['temperature_riviere']))))\n",
    "T_measures = list(zip(capteur_ZH['dates'], capteur_ZH[['temperature_10', 'temperature_20', 'temperature_30', 'temperature_40']].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {\n",
    "\t\"river_bed\": 1., \n",
    "    \"depth_sensors\": [.1, .2, .3, .4],\n",
    "\t\"offset\": .0,\n",
    "    \"dH_measures\": dH_measures,\n",
    "\t\"T_measures\": T_measures,\n",
    "    \"sigma_meas_P\": None,\n",
    "    \"sigma_meas_T\": None,\n",
    "    \"inter_mode\": 'lagrange'\n",
    "}\n",
    "\n",
    "col = Column.from_dict(col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Compute Solve Transi ---\n",
      "One layer : moinslog10IntrinK = 4, n = 0.1, lambda_s = 2, rhos_cs = 4000000.0\n",
      "Solving the flow with intrinsec permeability 0.0001, and permeability 981.0000000000001\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "params = Param(\n",
    "    moinslog10IntrinK = 4,\n",
    "    n = .1,\n",
    "    lambda_s = 2,\n",
    "    rhos_cs = 4e6\n",
    ")\n",
    "\n",
    "params_tuple = (4, .1, 2, 4e6)\n",
    "\n",
    "assert params == params_tuple\n",
    "\n",
    "col.compute_solve_transi(params, nb_cells=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors_couche_1 = {\n",
    "    \"moinslog10IntrinK\": ((1, 10), .01), # (intervalle, sigma)\n",
    "    \"n\": ((.001, .25), .005),\n",
    "    \"lambda_s\": ((1, 10), .1),\n",
    "    \"rhos_cs\": ((1e6,1e7), 1e5),\n",
    "}\n",
    "\n",
    "priors_couche_2 = {\n",
    "    \"moinslog10IntrinK\": ((4, 9), .01), # (intervalle, sigma)\n",
    "    \"n\": ((.001, .25), .005),\n",
    "    \"lambda_s\": ((1, 10), .1),\n",
    "    \"rhos_cs\": ((1e6,1e7), 1e5),\n",
    "}\n",
    "\n",
    "priors_couche_3 = {\n",
    "    \"moinslog10IntrinK\": ((4, 9), .01), # (intervalle, sigma)\n",
    "    \"n\": ((.001, .25), .005),\n",
    "    \"lambda_s\": ((1, 10), .1),\n",
    "    \"rhos_cs\": ((1e6,1e7), 1e5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_priors = [\n",
    "    ['Couche 1', 0.4, priors_couche_1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_priors = [['Couche 1', 0.4, priors_couche_1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(layer):\n",
    "    name, prof, priors = layer\n",
    "    if isinstance(priors, dict):\n",
    "        return (\n",
    "            name,\n",
    "            prof,\n",
    "            [Prior(*args) for args in (priors[lbl] for lbl in PARAM_LIST)],\n",
    "        )\n",
    "    else:\n",
    "        return layer\n",
    "\n",
    "if not isinstance(all_priors, AllPriors):\n",
    "    all_priors = AllPriors([LayerPriors(*conv(layer)) for layer in all_priors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 10) (1001, 10, 100, 1309)\n"
     ]
    }
   ],
   "source": [
    "nb_chain = 10\n",
    "nb_iter = 1000\n",
    "nb_param = 4\n",
    "delta = 3\n",
    "ncr = 3\n",
    "c = 0.1\n",
    "c_star=1e-6\n",
    "nb_cells = 100\n",
    "#temp_ref = col._T_measures[:, :].T\n",
    "dz = col._real_z[-1] / nb_cells\n",
    "_z_solve = dz / 2 + np.array([k * dz for k in range(nb_cells)])\n",
    "ind_ref = [np.argmin(np.abs(z - _z_solve)) for z in col._real_z[1:-1]]\n",
    "temp_ref = col.get_temperatures_solve()[ind_ref]\n",
    "sigma2 = 1\n",
    "nb_layer = len(all_priors)\n",
    "col._states = list()\n",
    "\n",
    "ranges = np.empty((nb_layer, nb_param, 2))\n",
    "for l in range(nb_layer):\n",
    "    for p in range(nb_param):\n",
    "        ranges[l,p] = all_priors[l][p].range  \n",
    "\n",
    "\n",
    "def compute_energy(temp: np.array):\n",
    "    norm2 = np.nansum((temp - temp_ref) ** 2)\n",
    "    return 0.5 * norm2 / sigma2\n",
    "\n",
    "def compute_log_acceptance(actual_energy: float, prev_energy: float):\n",
    "    return prev_energy - actual_energy\n",
    "\n",
    "def convert_to_layer(name_layer, z_low, params): \n",
    "    return [Layer(name_layer[i], z_low[i], *params[i]) for i in range(nb_layer)]\n",
    "\n",
    "def check_range(x, ranges): \n",
    "    while np.sum(x < ranges[:,0]) + np.sum(x > ranges[:,1]) > 0:\n",
    "        x = (x < ranges[:,0]) * (ranges[:,1] - (ranges[:,0] - x)) + (x > ranges[:,1]) * (ranges[:,0] + (x - ranges[:,1])) + (x >= ranges[:,0]) * (x <= ranges[:,1]) * x\n",
    "    return x\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def gelman_rubin(nb_current_iter, nb_param, nb_layer, chains, threshold=1.1):\n",
    "    \"\"\"\n",
    "    Input : chains [3D np.array] - chaînes de Markov calculées en parallèle\n",
    "            threshold [float] - seuil de l'indicateur de Gelman-Rubin, légèrement supérieur à 1\n",
    "    \n",
    "    Output : [bool] - True si et seulement si la phase de burn-in est considérée finie\n",
    "    \"\"\"\n",
    "    R = np.zeros((nb_layer, nb_param))\n",
    "    for l in range(nb_layer):   \n",
    "        chains_layered = chains[:,:,l,:]\n",
    "        # Variances intra-chaînes des paramètres\n",
    "        Var_intra = np.var(chains_layered, axis=0)\n",
    "\n",
    "        # Moyenne des variances intra-chaîne\n",
    "        var_intra = np.mean(Var_intra, axis=0)\n",
    "\n",
    "        # Moyennes de chaque chaîne\n",
    "        means_chains = np.mean(chains_layered, axis=0)\n",
    "\n",
    "        # Variance entre les moyennes des chaînes, dite inter-chaînes\n",
    "        var_inter = np.var(means_chains, axis=0)\n",
    "\n",
    "        # Calcul de l'indicateur de Gelman-Rubin\n",
    "        for j in range(nb_param):\n",
    "            if np.isclose(var_intra[j], 0) :\n",
    "                R[l,j] = 2\n",
    "            else:\n",
    "                R[l,j] = np.sqrt( var_inter[j] / var_intra[j] * (nb_current_iter - 1) / nb_current_iter + 1) # Vérifier la formule\n",
    "\n",
    "    print(\"R = \", R)\n",
    "\n",
    "    # On considère que la phase de burn-in est terminée dès que R < threshold\n",
    "    return np.all(R < threshold)\n",
    "\n",
    "# initialisation\n",
    "X = np.array([np.array(all_priors.sample()) for _ in range(nb_chain)])\n",
    "X = np.array([np.array([X[c][l].params for l in range(nb_layer)]) for c in range(nb_chain)])\n",
    "_params = np.zeros((nb_iter + 1, nb_chain, nb_layer, nb_param))\n",
    "_params[0] = X\n",
    "_temp = np.zeros((nb_iter + 1, nb_chain, nb_cells, len(col._times)), np.float32)\n",
    "_energy = np.zeros((nb_iter + 1, nb_chain))\n",
    "temp_new = np.zeros((nb_cells, len(col._times)))\n",
    "energy_new = 0\n",
    "\n",
    "name_layer = [all_priors.sample()[i].name for i in range(nb_layer)]\n",
    "z_low = [all_priors.sample()[i].zLow for i in range(nb_layer)]\n",
    "\n",
    "print(_energy.shape,_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialisation des chaines\n",
    "for i in range(nb_chain): \n",
    "    col.compute_solve_transi(convert_to_layer(name_layer, z_low, X[i]), nb_cells, verbose = False)\n",
    "    _temp[0][i] = col.get_temperatures_solve()\n",
    "    _energy[0][i] = compute_energy(_temp[0][i][ind_ref, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_vec = np.arange(1,ncr+1)/ncr\n",
    "n_id = np.zeros((nb_layer, ncr))\n",
    "J = np.zeros((nb_layer, ncr))\n",
    "pcr = np.ones((nb_layer, ncr))/ncr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R =  [[1.26391084 1.17238177 1.53992173 1.72265318]]\n",
      "R =  [[1.3939944  1.14550758 1.70356765 1.9739562 ]]\n",
      "R =  [[1.50609461 1.16461752 1.76216466 1.65872866]]\n",
      "R =  [[1.58812147 1.19508955 1.86255595 1.64086932]]\n",
      "R =  [[1.64600117 1.24163897 1.7661738  1.56117192]]\n",
      "R =  [[1.71940244 1.17775606 1.68529615 1.41432942]]\n",
      "R =  [[1.79209836 1.17262932 1.6759601  1.3598687 ]]\n",
      "R =  [[1.82238175 1.19619952 1.58304867 1.32022109]]\n",
      "R =  [[1.86750449 1.19763878 1.53878235 1.29495906]]\n",
      "R =  [[1.91386636 1.2107966  1.52449603 1.287511  ]]\n",
      "R =  [[1.90625012 1.22751906 1.53364324 1.28549895]]\n",
      "R =  [[1.83336221 1.23155369 1.55329858 1.28580926]]\n",
      "R =  [[1.76001712 1.23802557 1.56400715 1.2917141 ]]\n",
      "R =  [[1.69423218 1.25045262 1.57882661 1.28496547]]\n",
      "R =  [[1.63484548 1.25488213 1.527274   1.28498576]]\n",
      "R =  [[1.58911714 1.25432054 1.52510672 1.28372872]]\n",
      "R =  [[1.53622668 1.24202789 1.50352049 1.28874436]]\n",
      "R =  [[1.51327289 1.20877253 1.49447707 1.29712376]]\n",
      "R =  [[1.49589876 1.18161612 1.47332215 1.27205471]]\n",
      "R =  [[1.4801628  1.1639391  1.47149261 1.2454542 ]]\n",
      "R =  [[1.46931518 1.15885226 1.47071477 1.23249121]]\n",
      "R =  [[1.45688199 1.15680598 1.47599025 1.2148768 ]]\n",
      "R =  [[1.44652536 1.15656637 1.4832837  1.20447507]]\n",
      "R =  [[1.43860533 1.15813114 1.49334799 1.19848368]]\n",
      "R =  [[1.4285839  1.1633862  1.50467717 1.19548043]]\n",
      "R =  [[1.42196146 1.16983675 1.50195182 1.17564665]]\n",
      "R =  [[1.39415504 1.17496549 1.47358302 1.1434411 ]]\n",
      "R =  [[1.36983226 1.18085455 1.4377008  1.11688817]]\n",
      "R =  [[1.35015668 1.18738902 1.41004738 1.09726599]]\n",
      "R =  [[1.33798156 1.1947216  1.36027549 1.08269654]]\n",
      "R =  [[1.32802093 1.20246038 1.32205459 1.06930002]]\n",
      "R =  [[1.31975337 1.2088347  1.30559    1.05502904]]\n",
      "R =  [[1.31276513 1.21568858 1.2855844  1.04410002]]\n",
      "R =  [[1.30541525 1.22281227 1.26973076 1.03620625]]\n",
      "R =  [[1.29769903 1.22951307 1.25822092 1.03070754]]\n",
      "R =  [[1.29131129 1.23642418 1.24931187 1.02640192]]\n",
      "R =  [[1.28750618 1.23712402 1.23207404 1.02249974]]\n",
      "R =  [[1.28396073 1.23849779 1.21482833 1.01966273]]\n",
      "R =  [[1.28109979 1.24056062 1.20102069 1.01772789]]\n",
      "R =  [[1.27937409 1.24239876 1.19018043 1.01670712]]\n",
      "R =  [[1.27814548 1.24392727 1.18095409 1.01630955]]\n",
      "R =  [[1.27736066 1.24631855 1.17366057 1.01645212]]\n",
      "R =  [[1.27642052 1.24546921 1.16682208 1.01672995]]\n",
      "R =  [[1.27578276 1.24551475 1.16099906 1.01718028]]\n",
      "R =  [[1.27514966 1.24734303 1.15659755 1.01857128]]\n",
      "R =  [[1.27465269 1.24978777 1.15506551 1.02035195]]\n",
      "R =  [[1.27439072 1.252763   1.15641066 1.02252406]]\n",
      "R =  [[1.27351781 1.2558684  1.15407324 1.02374826]]\n",
      "R =  [[1.27285704 1.25988537 1.15657237 1.02530508]]\n",
      "R =  [[1.272289   1.26165857 1.15775988 1.02785753]]\n",
      "R =  [[1.27116588 1.26352432 1.15925558 1.03072945]]\n",
      "R =  [[1.27031574 1.26822454 1.16107922 1.0338802 ]]\n",
      "R =  [[1.26966893 1.27312212 1.16322336 1.03727511]]\n",
      "R =  [[1.26920901 1.27819454 1.16562509 1.0408844 ]]\n",
      "R =  [[1.26792611 1.2827147  1.16918445 1.04399544]]\n",
      "R =  [[1.26683659 1.28739508 1.17291957 1.0473282 ]]\n",
      "R =  [[1.26592552 1.29212297 1.175088   1.05085617]]\n",
      "R =  [[1.26265265 1.29531136 1.1771935  1.05455639]]\n",
      "R =  [[1.25966964 1.29284103 1.17949573 1.05842068]]\n",
      "R =  [[1.25695304 1.29213879 1.18197042 1.06237121]]\n",
      "R =  [[1.25467666 1.29206144 1.18499273 1.06631778]]\n",
      "R =  [[1.25492131 1.29239434 1.18862668 1.07016071]]\n",
      "R =  [[1.25525881 1.2930291  1.19235877 1.07405862]]\n",
      "R =  [[1.25630592 1.29390681 1.19541442 1.07703829]]\n",
      "R =  [[1.25800013 1.28766535 1.19391958 1.07848777]]\n",
      "R =  [[1.25926736 1.28170781 1.19140962 1.07961882]]\n",
      "R =  [[1.26049874 1.2809876  1.18699447 1.08064256]]\n",
      "R =  [[1.2617959  1.28059296 1.18323574 1.08182874]]\n",
      "R =  [[1.26315486 1.2804956  1.18006238 1.08316235]]\n",
      "R =  [[1.26457189 1.28067028 1.17741308 1.08462103]]\n",
      "R =  [[1.26604356 1.28106614 1.17644993 1.08597149]]\n",
      "R =  [[1.266816   1.28169704 1.1776168  1.08774976]]\n",
      "R =  [[1.26765565 1.28254401 1.17899556 1.08962593]]\n",
      "R =  [[1.26855985 1.28577644 1.18042919 1.08853033]]\n",
      "R =  [[1.26952386 1.28908766 1.18205226 1.08772557]]\n",
      "R =  [[1.27054436 1.29043441 1.18316645 1.08718628]]\n",
      "R =  [[1.27161827 1.29187868 1.18448731 1.08688984]]\n",
      "R =  [[1.27277874 1.29340723 1.18594303 1.0867237 ]]\n",
      "R =  [[1.27351024 1.29502461 1.18757479 1.08698216]]\n",
      "R =  [[1.274195   1.29637298 1.18943258 1.0868249 ]]\n",
      "R =  [[1.27494276 1.29780372 1.19143567 1.08684254]]\n",
      "R =  [[1.27575018 1.29931203 1.193572   1.08702246]]\n",
      "R =  [[1.27440401 1.30089345 1.19581547 1.08735316]]\n",
      "R =  [[1.27316047 1.30254382 1.19817261 1.08782413]]\n",
      "R =  [[1.27201414 1.30425925 1.20063434 1.08842576]]\n",
      "R =  [[1.27095996 1.30603611 1.20319245 1.08914924]]\n",
      "R =  [[1.26923112 1.30614683 1.20318924 1.08949351]]\n",
      "R =  [[1.2675939  1.30617458 1.20336138 1.08994575]]\n",
      "R =  [[1.26567564 1.30546267 1.20340498 1.09057617]]\n",
      "R =  [[1.26384596 1.30489097 1.20361945 1.09130363]]\n",
      "R =  [[1.26237861 1.30022374 1.20089357 1.09185713]]\n",
      "R =  [[1.2609881  1.29586318 1.19848014 1.09250815]]\n",
      "R =  [[1.25967097 1.29178935 1.19635531 1.09162032]]\n",
      "R =  [[1.25842398 1.28798401 1.19449755 1.09087525]]\n",
      "R =  [[1.2566211  1.28256694 1.19252017 1.09025234]]\n",
      "R =  [[1.25490215 1.27750188 1.19075924 1.08975595]]\n",
      "R =  [[1.25326334 1.27276499 1.18965049 1.08937856]]\n",
      "R =  [[1.25170111 1.26833454 1.18836232 1.09063854]]\n",
      "R =  [[1.250407   1.26606963 1.18725472 1.09196001]]\n",
      "R =  [[1.24917844 1.26399628 1.18631608 1.09333953]]\n",
      "R =  [[1.24784758 1.26196185 1.18483342 1.09455023]]\n",
      "R =  [[1.24657357 1.26012984 1.18351214 1.09582959]]\n",
      "R =  [[1.24535418 1.25850753 1.18234206 1.09693863]]\n",
      "R =  [[1.24418728 1.25705234 1.18131382 1.09811222]]\n",
      "R =  [[1.24290099 1.25593608 1.17828518 1.09934675]]\n",
      "R =  [[1.24166943 1.25493716 1.17544297 1.10063882]]\n",
      "R =  [[1.24049051 1.25404941 1.17277475 1.10198527]]\n",
      "R =  [[1.23903105 1.2532671  1.17026913 1.10338315]]\n",
      "R =  [[1.23762853 1.25258484 1.16791573 1.10482967]]\n",
      "R =  [[1.23627883 1.25199762 1.16610986 1.10632224]]\n",
      "R =  [[1.23487196 1.24891032 1.16453124 1.10742734]]\n",
      "R =  [[1.23351835 1.24597961 1.1630816  1.10883366]]\n",
      "R =  [[1.23221605 1.2431972  1.16175347 1.11028104]]\n",
      "R =  [[1.23096512 1.23997357 1.15989939 1.11134884]]\n",
      "R =  [[1.22975987 1.23742625 1.15815973 1.11155754]]\n",
      "R =  [[1.22859949 1.23500751 1.15652786 1.11183988]]\n",
      "R =  [[1.22748241 1.23271096 1.15493249 1.11219221]]\n",
      "R =  [[1.22640713 1.23053062 1.15343704 1.11261111]]\n",
      "R =  [[1.22535102 1.22826007 1.15203594 1.11408064]]\n",
      "R =  [[1.22433034 1.22610411 1.15072404 1.11558151]]\n",
      "R =  [[1.22334393 1.22405725 1.14991817 1.11711224]]\n",
      "R =  [[1.22232311 1.22211435 1.14941452 1.11871813]]\n",
      "R =  [[1.22145554 1.22022865 1.14886381 1.1203471 ]]\n",
      "R =  [[1.22061623 1.21845657 1.14839786 1.12199811]]\n",
      "R =  [[1.2198002  1.21679746 1.14793046 1.12235797]]\n",
      "R =  [[1.21901081 1.21524086 1.14754233 1.12275635]]\n",
      "R =  [[1.21824728 1.21378178 1.14722959 1.12319166]]\n",
      "R =  [[1.21750884 1.21241552 1.1469886  1.12394244]]\n",
      "R =  [[1.21652781 1.21121759 1.14682356 1.12471904]]\n",
      "R =  [[1.21557505 1.21010325 1.14672333 1.12552044]]\n",
      "R =  [[1.21464974 1.20906866 1.14668489 1.12634572]]\n",
      "R =  [[1.21375108 1.2081102  1.14670542 1.12719395]]\n",
      "R =  [[1.21287831 1.20722446 1.14678224 1.12806427]]\n",
      "R =  [[1.21203068 1.20640822 1.14691282 1.12895585]]\n",
      "R =  [[1.21120749 1.20565846 1.14709478 1.1298679 ]]\n",
      "R =  [[1.21040805 1.20497231 1.14732588 1.13079966]]\n",
      "R =  [[1.2096317  1.20434706 1.14760398 1.13175042]]\n",
      "R =  [[1.20887781 1.2031778  1.14792706 1.13271946]]\n",
      "R =  [[1.20814577 1.20211107 1.14829323 1.13370614]]\n",
      "R =  [[1.20743499 1.20114176 1.14870066 1.13470981]]\n",
      "R =  [[1.2067449  1.20026508 1.14914766 1.13572986]]\n",
      "R =  [[1.20607495 1.19947653 1.14963258 1.13676571]]\n",
      "R =  [[1.20542461 1.19877191 1.15015388 1.1378168 ]]\n",
      "R =  [[1.20479338 1.19814725 1.1507101  1.13888259]]\n",
      "R =  [[1.20418075 1.19759884 1.15129983 1.13996256]]\n",
      "R =  [[1.20358625 1.19712318 1.15192175 1.14105622]]\n",
      "R =  [[1.20300979 1.19754961 1.15273531 1.14207071]]\n",
      "R =  [[1.20245057 1.19802111 1.15357327 1.14309833]]\n",
      "R =  [[1.20188765 1.19777806 1.15384171 1.14416094]]\n",
      "R =  [[1.20134145 1.1976084  1.15414146 1.14523618]]\n",
      "R =  [[1.20081844 1.19752827 1.15431584 1.14624215]]\n",
      "R =  [[1.20031148 1.1974837  1.15452594 1.14735066]]\n",
      "R =  [[1.1998316  1.19632838 1.15469691 1.14841836]]\n",
      "R =  [[1.19936565 1.1952556  1.15489576 1.14950707]]\n",
      "R =  [[1.19891327 1.19334266 1.15488071 1.15061598]]\n",
      "R =  [[1.19847416 1.1915238  1.15489986 1.15174432]]\n",
      "R =  [[1.19804801 1.18979519 1.15495199 1.15289134]]\n",
      "R =  [[1.19763452 1.18815321 1.15503594 1.15405635]]\n",
      "R =  [[1.19737549 1.18503436 1.15494476 1.15538469]]\n",
      "R =  [[1.19712642 1.1820649  1.15488015 1.15672588]]\n",
      "R =  [[1.1968871  1.17923757 1.15484125 1.15807943]]\n",
      "R =  [[1.19665731 1.17654559 1.15482722 1.15944488]]\n",
      "R =  [[1.19643685 1.17398258 1.15483728 1.16082177]]\n",
      "R =  [[1.19607796 1.17224563 1.15492936 1.16217697]]\n",
      "R =  [[1.19572847 1.17087376 1.15425739 1.16215678]]\n",
      "R =  [[1.1953882  1.16958257 1.15360955 1.16215243]]\n",
      "R =  [[1.19496134 1.1684305  1.15298514 1.16085473]]\n",
      "R =  [[1.19454488 1.16734577 1.15238346 1.15961354]]\n",
      "R =  [[1.1941386  1.16445213 1.15180385 1.15842692]]\n",
      "R =  [[1.19374229 1.16167844 1.15124569 1.15729304]]\n",
      "R =  [[1.19315296 1.15908478 1.15049131 1.15627182]]\n",
      "R =  [[1.19257609 1.15659709 1.14975777 1.15529926]]\n",
      "R =  [[1.19181093 1.15421104 1.14904448 1.15437376]]\n",
      "R =  [[1.1910946  1.15186346 1.14834677 1.15347717]]\n",
      "R =  [[1.19044951 1.14971356 1.147825   1.15250917]]\n",
      "R =  [[1.18981874 1.14764834 1.14732135 1.15158774]]\n",
      "R =  [[1.18920196 1.14566457 1.14683531 1.15071141]]\n",
      "R =  [[1.18859887 1.14375923 1.14636643 1.14987876]]\n",
      "R =  [[1.18800918 1.1419294  1.14591422 1.14908841]]\n",
      "R =  [[1.1874326  1.14017233 1.14547826 1.14833905]]\n",
      "R =  [[1.18679877 1.13834846 1.14505812 1.14758007]]\n",
      "R =  [[1.18617829 1.13659628 1.14465338 1.14685944]]\n",
      "R =  [[1.18557088 1.13491324 1.14426365 1.14617601]]\n",
      "R =  [[1.18497628 1.13329692 1.14388853 1.14552868]]\n",
      "R =  [[1.18446745 1.13176827 1.14344731 1.14547774]]\n",
      "R =  [[1.18397063 1.13030142 1.14302065 1.14544921]]\n",
      "R =  [[1.18336362 1.12889428 1.14260819 1.1454425 ]]\n",
      "R =  [[1.18277009 1.12754483 1.14220957 1.14545703]]\n",
      "R =  [[1.18218977 1.12625116 1.14182446 1.14549225]]\n",
      "R =  [[1.18162237 1.12501142 1.1414525  1.14554763]]\n",
      "R =  [[1.18086581 1.12438134 1.14141563 1.14568916]]\n",
      "R =  [[1.18012769 1.1237851  1.14139205 1.14584872]]\n",
      "R =  [[1.17921075 1.12319187 1.14078164 1.14630875]]\n",
      "R =  [[1.1784019  1.12263116 1.14019316 1.14678816]]\n",
      "R =  [[1.17761114 1.12210205 1.139626   1.14728641]]\n",
      "R =  [[1.1768381  1.12160368 1.13907962 1.14780296]]\n",
      "R =  [[1.17626595 1.12071075 1.13846078 1.14833731]]\n",
      "R =  [[1.17570503 1.1198555  1.13786072 1.14888896]]\n",
      "R =  [[1.17515511 1.11903685 1.13727897 1.14945743]]\n",
      "R =  [[1.174616   1.11825377 1.13671506 1.15004226]]\n",
      "R =  [[1.17408748 1.11750526 1.13616855 1.150643  ]]\n",
      "R =  [[1.17356935 1.11679035 1.135639   1.15125922]]\n",
      "R =  [[1.17306143 1.11610811 1.13512599 1.15189049]]\n",
      "R =  [[1.17256353 1.11545764 1.13462913 1.15253642]]\n",
      "R =  [[1.17207545 1.11483809 1.13414801 1.15319661]]\n",
      "R =  [[1.17159703 1.11424862 1.13368225 1.15387067]]\n",
      "R =  [[1.17112808 1.11368842 1.1332315  1.15455824]]\n",
      "R =  [[1.17066844 1.11315671 1.13279539 1.15525897]]\n",
      "R =  [[1.17021794 1.11265274 1.13237358 1.1559725 ]]\n",
      "R =  [[1.16977641 1.11217579 1.13196573 1.1566985 ]]\n",
      "R =  [[1.16934369 1.11172516 1.13157151 1.15743664]]\n",
      "R =  [[1.16891963 1.11130016 1.13119063 1.15818661]]\n",
      "R =  [[1.16850408 1.11090014 1.13082276 1.15894811]]\n",
      "R =  [[1.16808816 1.11061001 1.13046762 1.15933075]]\n",
      "R =  [[1.16768067 1.11034043 1.13012491 1.15973594]]\n",
      "R =  [[1.16728149 1.11009091 1.12979436 1.16016299]]\n",
      "R =  [[1.16689047 1.10986098 1.1294757  1.16061124]]\n",
      "R =  [[1.16650746 1.10965016 1.12916866 1.16108007]]\n",
      "R =  [[1.16613234 1.10945803 1.128873   1.16156885]]\n",
      "R =  [[1.16568399 1.1092041  1.12862824 1.16205754]]\n",
      "R =  [[1.16524562 1.10897089 1.12839454 1.16256087]]\n",
      "R =  [[1.1648484  1.10779672 1.12816769 1.16303863]]\n",
      "R =  [[1.16446077 1.10665747 1.12794648 1.16353331]]\n",
      "R =  [[1.16408257 1.10555223 1.12773614 1.16404444]]\n",
      "R =  [[1.16371364 1.10448008 1.12753644 1.16457157]]\n",
      "R =  [[1.16335381 1.10298335 1.12734715 1.16472373]]\n",
      "R =  [[1.16300292 1.10153468 1.12716805 1.16489056]]\n",
      "R =  [[1.16266081 1.10013256 1.12699892 1.16507169]]\n",
      "R =  [[1.16232735 1.09877554 1.12683955 1.1652303 ]]\n",
      "R =  [[1.16200238 1.09746226 1.12668973 1.16540318]]\n",
      "R =  [[1.16168575 1.09619139 1.12654928 1.16558999]]\n",
      "R =  [[1.16137733 1.09496164 1.12641798 1.16579038]]\n",
      "R =  [[1.16107697 1.0937718  1.12629565 1.16600405]]\n",
      "R =  [[1.16078455 1.0926207  1.12618212 1.16623067]]\n",
      "R =  [[1.16049993 1.0915072  1.12607719 1.16646993]]\n",
      "R =  [[1.16022297 1.09043022 1.1259807  1.16672155]]\n",
      "R =  [[1.15995357 1.08938871 1.12589248 1.16698522]]\n",
      "R =  [[1.15969158 1.08838166 1.12581236 1.16726068]]\n",
      "R =  [[1.15943689 1.08740811 1.12574018 1.16754766]]\n",
      "R =  [[1.15918939 1.08646713 1.12567577 1.16784587]]\n",
      "R =  [[1.15894895 1.0855578  1.125619   1.16815508]]\n",
      "R =  [[1.15871547 1.08467927 1.12556971 1.16847503]]\n",
      "R =  [[1.15848882 1.0838307  1.12552776 1.16880548]]\n",
      "R =  [[1.15826891 1.08301128 1.125493   1.16914619]]\n",
      "R =  [[1.15804988 1.08222024 1.1255177  1.16941463]]\n",
      "R =  [[1.15783742 1.08171503 1.12554888 1.16969341]]\n",
      "R =  [[1.15763143 1.08122818 1.12558642 1.16998229]]\n",
      "R =  [[1.1574318  1.08075928 1.12563019 1.17028106]]\n",
      "R =  [[1.15723844 1.08030795 1.12568009 1.17058949]]\n",
      "R =  [[1.15705125 1.0798738  1.12573598 1.17090738]]\n",
      "R =  [[1.15687014 1.07945647 1.12579777 1.17123451]]\n",
      "R =  [[1.156695   1.0790556  1.12586534 1.1715707 ]]\n",
      "R =  [[1.15644562 1.07867083 1.12593858 1.17191575]]\n",
      "R =  [[1.15620253 1.07830184 1.12601738 1.17226946]]\n",
      "R =  [[1.15596564 1.07794828 1.12610165 1.17263166]]\n",
      "R =  [[1.15551947 1.07738474 1.12592255 1.17300215]]\n",
      "R =  [[1.1550796  1.07684564 1.12574902 1.17338078]]\n",
      "R =  [[1.15464595 1.07633041 1.12558095 1.17376736]]\n",
      "R =  [[1.15421842 1.07583847 1.12541825 1.17416173]]\n",
      "R =  [[1.15379692 1.07536927 1.12526083 1.17456373]]\n",
      "R =  [[1.15326526 1.07487568 1.12510858 1.17514357]]\n",
      "R =  [[1.15274094 1.07440549 1.12496144 1.17573037]]\n",
      "R =  [[1.15222386 1.07395814 1.1248193  1.17632398]]\n",
      "R =  [[1.1517139  1.07353308 1.12468207 1.17692422]]\n",
      "R =  [[1.15121096 1.07312978 1.12454969 1.17753096]]\n",
      "R =  [[1.15071493 1.07274774 1.12442206 1.17814405]]\n",
      "R =  [[1.15022572 1.07238645 1.1242991  1.17876335]]\n",
      "R =  [[1.14974322 1.07204545 1.12418075 1.17938871]]\n",
      "R =  [[1.14926734 1.07172425 1.12406691 1.18002   ]]\n",
      "R =  [[1.14887318 1.07136529 1.12388855 1.18051145]]\n",
      "R =  [[1.14848455 1.07102792 1.1237159  1.18101017]]\n",
      "R =  [[1.14810136 1.07071161 1.12354884 1.18151599]]\n",
      "R =  [[1.14772355 1.07041587 1.12338729 1.18202876]]\n",
      "R =  [[1.14735103 1.07014021 1.12323114 1.18254832]]\n",
      "R =  [[1.14698373 1.06988416 1.1230803  1.18307453]]\n",
      "R =  [[1.14662158 1.06964727 1.12293469 1.18360725]]\n",
      "R =  [[1.1461369  1.06942909 1.12279421 1.18414942]]\n",
      "R =  [[1.14565822 1.06922919 1.12265878 1.18469751]]\n",
      "R =  [[1.14515911 1.06904716 1.12252832 1.1852448 ]]\n",
      "R =  [[1.14466615 1.06888259 1.12240273 1.18579641]]\n",
      "R =  [[1.14417925 1.06873508 1.12228195 1.18635227]]\n",
      "R =  [[1.14369834 1.06860426 1.12216588 1.18691228]]\n",
      "R =  [[1.14322332 1.06848975 1.12205446 1.18747637]]\n",
      "R =  [[1.14275411 1.06839119 1.1219476  1.18804444]]\n",
      "R =  [[1.14229063 1.06830823 1.12184524 1.18861643]]\n",
      "R =  [[1.14183281 1.06824053 1.1217473  1.18919225]]\n",
      "R =  [[1.141436   1.06873741 1.12165371 1.18977185]]\n",
      "R =  [[1.14104424 1.06924115 1.12172711 1.1903552 ]]\n",
      "R =  [[1.14065746 1.0697516  1.12180441 1.1909422 ]]\n",
      "R =  [[1.14026453 1.0702685  1.12168516 1.19155182]]\n",
      "R =  [[1.139877   1.07079178 1.12157015 1.19216491]]\n",
      "R =  [[1.13949479 1.07132133 1.1214593  1.19278141]]\n",
      "R =  [[1.13911783 1.071857   1.12135255 1.19340125]]\n",
      "R =  [[1.13874605 1.07239866 1.12124984 1.19402437]]\n",
      "R =  [[1.13837937 1.07294619 1.12115111 1.19465069]]\n",
      "R =  [[1.13801774 1.07349947 1.12105629 1.19528016]]\n",
      "R =  [[1.13766108 1.07405836 1.12096532 1.1959127 ]]\n",
      "R =  [[1.13730933 1.07462277 1.12087814 1.19654827]]\n",
      "R =  [[1.13696242 1.07519256 1.12079471 1.19718679]]\n",
      "R =  [[1.13662028 1.07576763 1.12071495 1.19782822]]\n",
      "R =  [[1.13628286 1.07634787 1.12063882 1.19847249]]\n",
      "R =  [[1.13595009 1.07693317 1.12056625 1.19911955]]\n",
      "R =  [[1.13541208 1.07726072 1.12044778 1.19978192]]\n",
      "R =  [[1.13488017 1.07759681 1.1203328  1.20044712]]\n",
      "R =  [[1.1343543  1.07794126 1.12022127 1.20111509]]\n",
      "R =  [[1.13383437 1.07829391 1.12011315 1.20178579]]\n",
      "R =  [[1.1333203  1.07865459 1.12000838 1.20245916]]\n",
      "R =  [[1.13281202 1.07902316 1.11990692 1.20313514]]\n",
      "R =  [[1.13230945 1.07939946 1.11980873 1.20381368]]\n",
      "R =  [[1.13181251 1.07978334 1.11971375 1.20449473]]\n",
      "R =  [[1.13132113 1.08017464 1.11962195 1.20517824]]\n",
      "R =  [[1.13083523 1.08057324 1.11953328 1.20586416]]\n",
      "R =  [[1.13033849 1.08097898 1.1194448  1.20655243]]\n",
      "R =  [[1.12984732 1.08139174 1.11935948 1.20724303]]\n",
      "R =  [[1.12931982 1.08113907 1.1192773  1.20783653]]\n",
      "R =  [[1.12879805 1.08090033 1.1191982  1.20843316]]\n",
      "R =  [[1.12828195 1.08067524 1.11912215 1.20903286]]\n",
      "R =  [[1.12777144 1.08046352 1.11904911 1.20963556]]\n",
      "R =  [[1.12726645 1.08026492 1.11897904 1.21024122]]\n",
      "R =  [[1.1267669  1.08007916 1.1189119  1.21084978]]\n",
      "R =  [[1.12627442 1.07986017 1.118809   1.2100327 ]]\n",
      "R =  [[1.12578722 1.07965543 1.11871032 1.20923618]]\n",
      "R =  [[1.12530523 1.07946462 1.11861578 1.20845982]]\n",
      "R =  [[1.12482838 1.07928747 1.11852533 1.20770323]]\n",
      "R =  [[1.12435661 1.07915286 1.11843893 1.20696603]]\n",
      "R =  [[1.12391956 1.07899788 1.11835669 1.20547226]]\n",
      "R =  [[1.12345243 1.07885533 1.11827838 1.20531999]]\n",
      "R =  [[1.12299042 1.07872498 1.11820395 1.2051739 ]]\n",
      "R =  [[1.12253347 1.07876704 1.11797711 1.20503391]]\n",
      "R =  [[1.12208153 1.07881777 1.11775676 1.20489991]]\n",
      "R =  [[1.12163451 1.078877   1.11754282 1.2047718 ]]\n",
      "R =  [[1.12119237 1.0789446  1.11721881 1.20464948]]\n",
      "R =  [[1.12075504 1.07902042 1.11690549 1.20453287]]\n",
      "R =  [[1.12032247 1.07910433 1.11660268 1.20442186]]\n",
      "R =  [[1.11989458 1.07919617 1.1163102  1.20431636]]\n",
      "R =  [[1.11947133 1.07929582 1.1160279  1.2042163 ]]\n",
      "R =  [[1.11903548 1.07940916 1.1156264  1.20412157]]\n",
      "R =  [[1.11860418 1.07953001 1.11523692 1.2040321 ]]\n",
      "R =  [[1.1180269  1.07948471 1.11480155 1.20323164]]\n",
      "R =  [[1.11745559 1.07944637 1.11437856 1.20245111]]\n",
      "R =  [[1.11689018 1.0794149  1.11396774 1.20169012]]\n",
      "R =  [[1.11633059 1.07939019 1.11356889 1.20094829]]\n",
      "R =  [[1.1157596  1.07901079 1.1130989  1.19998391]]\n",
      "R =  [[1.11519492 1.07864309 1.11264438 1.19903862]]\n",
      "R =  [[1.11463648 1.0782869  1.11220504 1.19811207]]\n",
      "R =  [[1.11408421 1.07794203 1.11181067 1.1972039 ]]\n",
      "R =  [[1.11353801 1.07760827 1.11142924 1.19631381]]\n",
      "R =  [[1.11299782 1.07728545 1.11106054 1.19544145]]\n",
      "R =  [[1.11246356 1.07697338 1.11070434 1.19458651]]\n",
      "R =  [[1.11193516 1.07667188 1.11036042 1.19374869]]\n",
      "R =  [[1.11141253 1.07638077 1.11002857 1.19292769]]\n",
      "R =  [[1.11089562 1.07609989 1.10970859 1.19212321]]\n",
      "R =  [[1.11020453 1.07611142 1.10940027 1.19142984]]\n",
      "R =  [[1.10952115 1.07612958 1.10910341 1.19075203]]\n",
      "R =  [[1.10884538 1.07615426 1.10881783 1.19008949]]\n",
      "R =  [[1.10817712 1.07618536 1.10854332 1.18944197]]\n",
      "R =  [[1.10751626 1.07622278 1.10827972 1.1888092 ]]\n",
      "R =  [[1.1068627  1.07626641 1.10802683 1.18819093]]\n",
      "R =  [[1.10621636 1.07631616 1.10778447 1.1875869 ]]\n",
      "R =  [[1.10557712 1.07637193 1.10755248 1.18699688]]\n",
      "R =  [[1.1049449  1.07643362 1.10733069 1.18642061]]\n",
      "R =  [[1.10431961 1.07650114 1.10711892 1.18585788]]\n",
      "R =  [[1.10370116 1.07657441 1.10691701 1.18523315]]\n",
      "R =  [[1.10308945 1.07665332 1.10672481 1.18462173]]\n",
      "R =  [[1.1024844  1.0767378  1.10654215 1.18402341]]\n",
      "R =  [[1.10188592 1.07682776 1.10635927 1.18343798]]\n",
      "R =  [[1.10129394 1.07692311 1.10618584 1.18286523]]\n",
      "R =  [[1.10070836 1.07702377 1.10602172 1.18230494]]\n",
      "R =  [[1.1001291  1.07712966 1.10586676 1.18175693]]\n",
      "R =  [[1.09955609 1.0772407  1.10572081 1.181221  ]]\n",
      "R =  [[1.09898924 1.0774133  1.10558373 1.18072587]]\n",
      "R =  [[1.09842848 1.07759104 1.10545538 1.18024214]]\n",
      "R =  [[1.09787373 1.07777386 1.10533562 1.17976966]]\n",
      "R =  [[1.09736903 1.07793296 1.10522081 1.17930823]]\n",
      "R =  [[1.09687    1.07809598 1.1051143  1.17885769]]\n",
      "R =  [[1.09637657 1.07826284 1.10501599 1.17841788]]\n",
      "R =  [[1.09588866 1.0784335  1.10492573 1.17798864]]\n",
      "R =  [[1.0954062  1.0786079  1.1048434  1.17756979]]\n",
      "R =  [[1.09492913 1.07878599 1.10476889 1.17716119]]\n",
      "R =  [[1.09442024 1.07886012 1.10454415 1.17665143]]\n",
      "R =  [[1.09391714 1.07893834 1.10433105 1.17615277]]\n",
      "R =  [[1.09341976 1.07902057 1.1041294  1.17566502]]\n",
      "R =  [[1.09292803 1.07910678 1.10393897 1.17518804]]\n",
      "R =  [[1.09244188 1.07919691 1.10375959 1.17472165]]\n",
      "R =  [[1.09196124 1.0792909  1.10359104 1.1742657 ]]\n",
      "R =  [[1.09148605 1.07940821 1.10319288 1.17406351]]\n",
      "R =  [[1.09101622 1.07952966 1.10281322 1.17387011]]\n",
      "R =  [[1.0905517  1.07965521 1.10245163 1.17368539]]\n",
      "R =  [[1.09007245 1.0797848  1.10210769 1.17350921]]\n",
      "R =  [[1.08959868 1.07991838 1.10178101 1.17334145]]\n",
      "R =  [[1.08913032 1.08005589 1.1014712  1.17318198]]\n",
      "R =  [[1.08866732 1.08019728 1.10117786 1.17303069]]\n",
      "R =  [[1.0882096  1.0803425  1.10090065 1.17288744]]\n",
      "R =  [[1.0877571  1.08049149 1.1006392  1.17275213]]\n",
      "R =  [[1.08730976 1.08064422 1.10039316 1.17262464]]\n",
      "R =  [[1.08686751 1.08080063 1.1001622  1.17250485]]\n",
      "R =  [[1.08643029 1.08096067 1.09994598 1.17239266]]\n",
      "R =  [[1.08599805 1.0811243  1.0997442  1.17228796]]\n",
      "R =  [[1.08557071 1.08129147 1.09955653 1.17219063]]\n",
      "R =  [[1.08513799 1.08140004 1.09938299 1.17209836]]\n",
      "R =  [[1.08471002 1.08151196 1.09922271 1.17201327]]\n",
      "R =  [[1.08428675 1.08162718 1.09907541 1.17193524]]\n",
      "R =  [[1.08386811 1.08174567 1.09894082 1.17186418]]\n",
      "R =  [[1.08345405 1.08186739 1.09886614 1.171605  ]]\n",
      "R =  [[1.08304452 1.08199229 1.09880226 1.17135509]]\n",
      "R =  [[1.08263946 1.08212034 1.09874897 1.17111432]]\n",
      "R =  [[1.08223882 1.0822515  1.09870606 1.17088255]]\n",
      "R =  [[1.08184256 1.08238572 1.09867333 1.17065964]]\n",
      "R =  [[1.0814506  1.08252298 1.09865058 1.17044546]]\n",
      "R =  [[1.08106291 1.08266323 1.09863762 1.17023989]]\n",
      "R =  [[1.08067944 1.08280645 1.09863426 1.17004279]]\n",
      "R =  [[1.08030014 1.08295258 1.09864031 1.16985405]]\n",
      "R =  [[1.07992495 1.08310161 1.09865561 1.16967353]]\n",
      "R =  [[1.07955383 1.08325348 1.09867997 1.16950113]]\n",
      "R =  [[1.07919783 1.0832121  1.09879391 1.16946604]]\n",
      "R =  [[1.07886524 1.08317586 1.09891463 1.16944522]]\n",
      "R =  [[1.07853628 1.0831447  1.09904202 1.16943139]]\n",
      "R =  [[1.07821093 1.08311853 1.09917594 1.16942446]]\n",
      "R =  [[1.07790248 1.08308464 1.0991608  1.16923056]]\n",
      "R =  [[1.07759734 1.08305535 1.09915193 1.16904475]]\n",
      "R =  [[1.07729547 1.08303061 1.09914922 1.16886691]]\n",
      "R =  [[1.07699683 1.08301035 1.0991526  1.16869691]]\n",
      "R =  [[1.07670083 1.08286292 1.09916197 1.16853465]]\n",
      "R =  [[1.07640799 1.08272217 1.09917724 1.16838001]]\n",
      "R =  [[1.07611829 1.082588   1.09919834 1.16823289]]\n",
      "R =  [[1.0758317  1.08246032 1.09922517 1.16809317]]\n",
      "R =  [[1.07554817 1.08233905 1.09925767 1.16796075]]\n",
      "R =  [[1.07526769 1.08222409 1.09929573 1.16783553]]\n",
      "R =  [[1.07499021 1.08211536 1.0993393  1.1677174 ]]\n",
      "R =  [[1.0747157  1.08201277 1.09938828 1.16760626]]\n",
      "R =  [[1.07444414 1.08191623 1.09944261 1.16750202]]\n",
      "R =  [[1.0741755  1.08182567 1.09950221 1.16740457]]\n",
      "R =  [[1.07390973 1.081741   1.099567   1.16731383]]\n",
      "R =  [[1.07364682 1.08166215 1.09963692 1.16722969]]\n",
      "R =  [[1.07338673 1.08158903 1.09971188 1.16715207]]\n",
      "R =  [[1.07312944 1.08152157 1.09979183 1.16708088]]\n",
      "R =  [[1.07287491 1.08128809 1.09988642 1.16701603]]\n",
      "R =  [[1.07262312 1.08106129 1.09998629 1.16695743]]\n",
      "R =  [[1.07237404 1.08071731 1.10006976 1.16689169]]\n",
      "R =  [[1.07212764 1.0803806  1.10015884 1.16683234]]\n",
      "R =  [[1.0718839  1.08005107 1.10025343 1.16677928]]\n",
      "R =  [[1.07164278 1.07972862 1.10035346 1.16673242]]\n",
      "R =  [[1.07140426 1.07941316 1.10045885 1.16669168]]\n",
      "R =  [[1.07116832 1.0791046  1.10056953 1.16665696]]\n",
      "R =  [[1.07093493 1.07880284 1.10068541 1.16662819]]\n",
      "R =  [[1.07070407 1.07850781 1.10080644 1.16660529]]\n",
      "R =  [[1.0704757  1.07821941 1.10093254 1.16658817]]\n",
      "R =  [[1.0702498  1.07793755 1.10106363 1.16657675]]\n",
      "R =  [[1.07002636 1.07766216 1.10119965 1.16657096]]\n",
      "R =  [[1.06980534 1.07739314 1.10134053 1.16657072]]\n",
      "R =  [[1.06958673 1.07713043 1.1014862  1.16657595]]\n",
      "R =  [[1.06937049 1.07687393 1.1016366  1.16658658]]\n",
      "R =  [[1.06915661 1.07662357 1.10179167 1.16660254]]\n",
      "R =  [[1.06894506 1.07637927 1.10195133 1.16662376]]\n",
      "R =  [[1.06873582 1.07614096 1.10211553 1.16665016]]\n",
      "R =  [[1.06852887 1.07590857 1.1022842  1.16668167]]\n",
      "R =  [[1.06832419 1.075682   1.10245729 1.16671824]]\n",
      "R =  [[1.06812175 1.07546121 1.10263474 1.16675978]]\n",
      "R =  [[1.06792153 1.07520369 1.10281648 1.16680625]]\n",
      "R =  [[1.06772351 1.07495139 1.10300246 1.16685756]]\n",
      "R =  [[1.06752767 1.07470424 1.10319262 1.16691366]]\n",
      "R =  [[1.06733399 1.07446219 1.10338691 1.16697448]]\n",
      "R =  [[1.06714245 1.07422517 1.10358527 1.16703997]]\n",
      "R =  [[1.06695303 1.07399314 1.10378765 1.16711005]]\n",
      "R =  [[1.06676571 1.07376603 1.103994   1.16718468]]\n",
      "R =  [[1.06658047 1.07354379 1.10420426 1.1672638 ]]\n",
      "R =  [[1.06639729 1.07342797 1.10441838 1.16734734]]\n",
      "R =  [[1.06621615 1.07331578 1.10463631 1.16743525]]\n",
      "R =  [[1.06603704 1.07320717 1.104858   1.16752747]]\n",
      "R =  [[1.06585992 1.07310211 1.1050834  1.16762395]]\n",
      "R =  [[1.06568479 1.07300056 1.10531247 1.16772464]]\n",
      "R =  [[1.06551163 1.07290247 1.10554515 1.16782947]]\n",
      "R =  [[1.06534042 1.07280783 1.10578141 1.16793841]]\n",
      "R =  [[1.0651959  1.0727307  1.10621569 1.16799919]]\n",
      "R =  [[1.06505359 1.0726569  1.1066527  1.16806388]]\n",
      "R =  [[1.06491347 1.07258641 1.10709239 1.16813241]]\n",
      "R =  [[1.06477553 1.07251917 1.10753471 1.16820476]]\n",
      "R =  [[1.06463973 1.07245517 1.10797965 1.16828086]]\n",
      "R =  [[1.06450606 1.07239437 1.10842714 1.16836068]]\n",
      "R =  [[1.0643745  1.07233673 1.10887717 1.16844418]]\n",
      "R =  [[1.06426002 1.07227548 1.10932793 1.16869301]]\n",
      "R =  [[1.06414743 1.07221737 1.10978119 1.16894446]]\n",
      "R =  [[1.06403672 1.07216237 1.11023691 1.16919852]]\n",
      "R =  [[1.06392786 1.07211043 1.11069507 1.16945514]]\n",
      "R =  [[1.06382084 1.07206153 1.11115562 1.1697143 ]]\n",
      "R =  [[1.06371565 1.07207471 1.11161444 1.16997597]]\n",
      "R =  [[1.06361226 1.07209141 1.11207494 1.17024012]]\n",
      "R =  [[1.06350085 1.0721116  1.11254277 1.16991608]]\n",
      "R =  [[1.06339134 1.07213524 1.11301261 1.16959997]]\n",
      "R =  [[1.06328372 1.07216229 1.11348444 1.16929169]]\n",
      "R =  [[1.06317797 1.07219271 1.11395823 1.16899114]]\n",
      "R =  [[1.06307407 1.07222646 1.11443394 1.16869821]]\n",
      "R =  [[1.06297202 1.07226351 1.11491157 1.16841279]]\n",
      "R =  [[1.06287178 1.07230383 1.11539107 1.16813481]]\n",
      "R =  [[1.06277334 1.07234737 1.11587242 1.16786415]]\n",
      "R =  [[1.0626767  1.07239411 1.1163556  1.16760072]]\n",
      "R =  [[1.06258182 1.072444   1.11684059 1.16734442]]\n",
      "R =  [[1.06248869 1.07249702 1.11732736 1.16709517]]\n",
      "R =  [[1.06239731 1.07255313 1.11781588 1.16685287]]\n",
      "R =  [[1.06230764 1.07261229 1.11830613 1.16661744]]\n",
      "R =  [[1.06221968 1.07267448 1.11879809 1.16638878]]\n",
      "R =  [[1.06213342 1.07273967 1.11929174 1.16616682]]\n",
      "R =  [[1.06204882 1.07280781 1.11978705 1.16595145]]\n",
      "R =  [[1.06196589 1.07287889 1.120284   1.16574261]]\n",
      "R =  [[1.06188461 1.07295286 1.12078257 1.16554021]]\n",
      "R =  [[1.06180495 1.0730297  1.12128273 1.16534417]]\n",
      "R =  [[1.06172691 1.07310938 1.12178447 1.1651544 ]]\n",
      "R =  [[1.06165048 1.07319187 1.12228777 1.16497083]]\n",
      "R =  [[1.06157563 1.07327714 1.12279259 1.16479339]]\n",
      "R =  [[1.06150236 1.07336515 1.12329893 1.16462199]]\n",
      "R =  [[1.06134539 1.07345589 1.12380677 1.1643095 ]]\n",
      "R =  [[1.06119061 1.07354932 1.12431608 1.16400231]]\n",
      "R =  [[1.061038   1.07364541 1.12482684 1.16370034]]\n",
      "R =  [[1.06088754 1.07374414 1.12533903 1.16340355]]\n",
      "R =  [[1.0607392  1.07384548 1.12585264 1.16311187]]\n",
      "R =  [[1.06059296 1.07394941 1.12636764 1.16282526]]\n",
      "R =  [[1.06044881 1.07405589 1.12688402 1.16254364]]\n",
      "R =  [[1.06030672 1.0741649  1.12740176 1.16226697]]\n",
      "R =  [[1.06016669 1.07427642 1.12792085 1.16199519]]\n",
      "R =  [[1.06002867 1.07439041 1.12844125 1.16172825]]\n",
      "R =  [[1.05989267 1.07450686 1.12896296 1.1614661 ]]\n",
      "R =  [[1.05975866 1.07462574 1.12948596 1.16120868]]\n",
      "R =  [[1.05956554 1.07466775 1.13001023 1.16093397]]\n",
      "R =  [[1.05937524 1.07471269 1.13053575 1.16066401]]\n",
      "R =  [[1.05918773 1.07476053 1.13106251 1.16039876]]\n",
      "R =  [[1.059003   1.07481124 1.1315905  1.16013816]]\n",
      "R =  [[1.058821   1.07486478 1.13211968 1.15988217]]\n",
      "R =  [[1.05864171 1.07492114 1.13265006 1.15963072]]\n",
      "R =  [[1.0584651  1.07498027 1.13318161 1.15938379]]\n",
      "R =  [[1.05829115 1.07504215 1.13371431 1.15914131]]\n",
      "R =  [[1.05821974 1.07510833 1.13424816 1.15890325]]\n",
      "R =  [[1.05815022 1.07517688 1.13478314 1.15866955]]\n",
      "R =  [[1.05808257 1.07524781 1.13531923 1.15844017]]\n",
      "R =  [[1.05801678 1.07532107 1.13585641 1.15821507]]\n",
      "R =  [[1.05795282 1.07539665 1.13639468 1.15799419]]\n",
      "R =  [[1.05789128 1.07543415 1.13693402 1.15790546]]\n",
      "R =  [[1.05783152 1.07547451 1.13747441 1.15782002]]\n",
      "R =  [[1.05777354 1.0755177  1.13801584 1.15773786]]\n",
      "R =  [[1.05771731 1.07556369 1.1385583  1.15765893]]\n",
      "R =  [[1.05766282 1.07561246 1.13910177 1.15758321]]\n",
      "R =  [[1.05761006 1.07566397 1.13964624 1.15751065]]\n",
      "R =  [[1.05755899 1.07571819 1.14019169 1.15744123]]\n",
      "R =  [[1.05750961 1.07577511 1.14073812 1.15737492]]\n",
      "R =  [[1.05746191 1.07583468 1.14128551 1.15731168]]\n",
      "R =  [[1.05741585 1.0758969  1.14183384 1.15725148]]\n",
      "R =  [[1.05737143 1.07596172 1.14238311 1.1571943 ]]\n",
      "R =  [[1.05732863 1.07602913 1.14293331 1.1571401 ]]\n",
      "R =  [[1.05728744 1.0760991  1.14348441 1.15708885]]\n",
      "R =  [[1.05724783 1.0761716  1.14403641 1.15704053]]\n",
      "R =  [[1.0572098  1.07624662 1.14458929 1.1569951 ]]\n",
      "R =  [[1.05717332 1.07632411 1.14514305 1.15695253]]\n",
      "R =  [[1.05713839 1.07640407 1.14569768 1.1569128 ]]\n",
      "R =  [[1.05710498 1.07643269 1.14623113 1.156883  ]]\n",
      "R =  [[1.05707309 1.07646329 1.14676527 1.15685589]]\n",
      "R =  [[1.0570427  1.07633173 1.14729435 1.15682933]]\n",
      "R =  [[1.05701379 1.07620386 1.14782422 1.1568058 ]]\n",
      "R =  [[1.05698635 1.07607965 1.14835487 1.15678525]]\n",
      "R =  [[1.05696036 1.07595907 1.14888628 1.15676766]]\n",
      "R =  [[1.05693582 1.07584207 1.14941844 1.15675301]]\n",
      "R =  [[1.0569127  1.07572862 1.14995136 1.15674126]]\n",
      "R =  [[1.056891   1.07561869 1.15048501 1.15673238]]\n",
      "R =  [[1.0568707  1.07551225 1.15101939 1.15672634]]\n",
      "R =  [[1.05685179 1.07540924 1.15155449 1.15672312]]\n",
      "R =  [[1.05683425 1.07530965 1.1520903  1.15672269]]\n",
      "R =  [[1.05681807 1.07521344 1.15262681 1.15672501]]\n",
      "R =  [[1.05680325 1.07512058 1.15316402 1.15673007]]\n",
      "R =  [[1.05678976 1.07503102 1.15370191 1.15673784]]\n",
      "R =  [[1.05677759 1.07494475 1.15424047 1.15674828]]\n",
      "R =  [[1.05676673 1.07486173 1.1547797  1.15676137]]\n",
      "R =  [[1.05675718 1.07478192 1.1553196  1.1567771 ]]\n",
      "R =  [[1.05674891 1.0747053  1.15586014 1.15679542]]\n",
      "R =  [[1.05674192 1.07463183 1.15640132 1.15681632]]\n",
      "R =  [[1.05673619 1.07456148 1.15694314 1.15683976]]\n",
      "R =  [[1.05673172 1.07449423 1.15748559 1.15686574]]\n",
      "R =  [[1.05672848 1.07443004 1.15802865 1.15689421]]\n",
      "R =  [[1.05672893 1.07436924 1.15845874 1.15684989]]\n",
      "R =  [[1.05673058 1.07431143 1.15889025 1.15680876]]\n",
      "R =  [[1.05673342 1.07425661 1.15932318 1.15677078]]\n",
      "R =  [[1.05673744 1.07423408 1.1597575  1.15658701]]\n",
      "R =  [[1.05674263 1.0742148  1.1601932  1.15640724]]\n",
      "R =  [[1.05674897 1.07419874 1.16063027 1.15623143]]\n",
      "R =  [[1.05680114 1.07418586 1.16106868 1.15610759]]\n",
      "R =  [[1.05685764 1.07417612 1.16150842 1.15594666]]\n",
      "R =  [[1.05691516 1.0741695  1.16194948 1.1557892 ]]\n",
      "R =  [[1.05697368 1.07416597 1.16239185 1.15563517]]\n",
      "R =  [[1.05703321 1.07416549 1.1628355  1.15548454]]\n",
      "R =  [[1.05709372 1.07416803 1.16328042 1.15533728]]\n",
      "R =  [[1.05715521 1.07417357 1.1637266  1.15519335]]\n",
      "R =  [[1.05721767 1.07418207 1.16417402 1.15505272]]\n",
      "R =  [[1.05728109 1.0741935  1.16462267 1.15491536]]\n",
      "R =  [[1.05734545 1.07428002 1.16507253 1.15478125]]\n",
      "R =  [[1.05741076 1.07436884 1.16552359 1.15465034]]\n",
      "R =  [[1.05747699 1.07445992 1.16597584 1.1545226 ]]\n",
      "R =  [[1.05754415 1.07455325 1.16642927 1.15439802]]\n",
      "R =  [[1.05761221 1.0746488  1.16688385 1.15425352]]\n",
      "R =  [[1.05768118 1.07474655 1.16733958 1.15411211]]\n",
      "R =  [[1.05775104 1.07484649 1.16779644 1.15397377]]\n",
      "R =  [[1.05782178 1.07494858 1.16825443 1.15383847]]\n",
      "R =  [[1.0578934  1.07505282 1.16871352 1.15370618]]\n",
      "R =  [[1.05796588 1.07515917 1.1691737  1.15357688]]\n",
      "R =  [[1.05803922 1.07526762 1.16963497 1.15345052]]\n",
      "R =  [[1.05811342 1.07537814 1.17009731 1.1533271 ]]\n",
      "R =  [[1.05818845 1.07549073 1.1704672  1.15320658]]\n",
      "R =  [[1.05826431 1.07560535 1.17083906 1.15308893]]\n",
      "R =  [[1.058341   1.07572199 1.17121288 1.15297413]]\n",
      "R =  [[1.0584185  1.07584063 1.17158863 1.15286215]]\n",
      "R =  [[1.05849682 1.07594551 1.17195634 1.15268022]]\n",
      "R =  [[1.05857593 1.07605241 1.17232628 1.15250177]]\n",
      "R =  [[1.05865584 1.07616131 1.17269843 1.15232676]]\n",
      "R =  [[1.05878663 1.07627219 1.17307273 1.15215517]]\n",
      "R =  [[1.05891809 1.07638504 1.17344918 1.15198695]]\n",
      "R =  [[1.05905021 1.07649983 1.17382773 1.15182209]]\n",
      "R =  [[1.05918299 1.07661655 1.17420836 1.15166054]]\n",
      "R =  [[1.05931641 1.07673519 1.17459103 1.15150228]]\n",
      "R =  [[1.05945048 1.07685571 1.17497573 1.15134728]]\n",
      "R =  [[1.05958517 1.07697811 1.17536242 1.15119551]]\n",
      "R =  [[1.0597205  1.07710237 1.17575107 1.15104694]]\n",
      "R =  [[1.05985644 1.07722847 1.17614166 1.15090153]]\n",
      "R =  [[1.059993   1.07735639 1.17653415 1.15075927]]\n",
      "R =  [[1.06013016 1.07748612 1.17692853 1.15062011]]\n",
      "R =  [[1.06026793 1.07761765 1.17732477 1.15048404]]\n",
      "R =  [[1.06040629 1.07775094 1.17772284 1.15035103]]\n",
      "R =  [[1.06054524 1.077886   1.17812271 1.15022104]]\n",
      "R =  [[1.06068477 1.0780228  1.17852437 1.15009406]]\n",
      "R =  [[1.06082487 1.07816132 1.17892778 1.14997004]]\n",
      "R =  [[1.06096555 1.07830156 1.17933293 1.14984898]]\n",
      "R =  [[1.06110679 1.07844349 1.17973978 1.14973084]]\n",
      "R =  [[1.06124859 1.0785871  1.18014832 1.14961559]]\n",
      "R =  [[1.06139094 1.07873238 1.18055853 1.14950321]]\n",
      "R =  [[1.06153383 1.07887931 1.18097037 1.14939368]]\n",
      "R =  [[1.06167727 1.07902788 1.18138384 1.14928696]]\n",
      "R =  [[1.06182124 1.07917806 1.1817989  1.14918304]]\n",
      "R =  [[1.06196575 1.07932985 1.18221554 1.14908189]]\n",
      "R =  [[1.06211078 1.07948324 1.18263373 1.14898348]]\n",
      "R =  [[1.06225632 1.0796382  1.18305345 1.14888779]]\n",
      "R =  [[1.06240239 1.07979473 1.18347468 1.14879481]]\n",
      "R =  [[1.06254467 1.08003957 1.1838975  1.14870449]]\n",
      "R =  [[1.0625724  1.08019565 1.18392121 1.14863439]]\n",
      "R =  [[1.0626011  1.08035312 1.18394914 1.14856665]]\n",
      "R =  [[1.06263074 1.08051198 1.18398124 1.14850127]]\n",
      "R =  [[1.06266133 1.08067219 1.18401743 1.14843822]]\n",
      "R =  [[1.06269284 1.08083376 1.18405768 1.14837748]]\n",
      "R =  [[1.06272527 1.08099668 1.18410191 1.14831903]]\n",
      "R =  [[1.06271531 1.08090255 1.18415007 1.14826285]]\n",
      "R =  [[1.06270638 1.08081002 1.18420212 1.14820893]]\n",
      "R =  [[1.06269846 1.0807191  1.18425798 1.14815725]]\n",
      "R =  [[1.06269154 1.08062976 1.18431762 1.14810778]]\n",
      "R =  [[1.06268562 1.080542   1.18438098 1.14806052]]\n",
      "R =  [[1.06268068 1.08045581 1.18444801 1.14801544]]\n",
      "R =  [[1.06267671 1.08037117 1.18451865 1.14797252]]\n",
      "R =  [[1.06267371 1.08028808 1.18459286 1.14793176]]\n",
      "R =  [[1.06267167 1.08020652 1.18467059 1.14789312]]\n",
      "R =  [[1.06267058 1.08012647 1.18475179 1.1478566 ]]\n",
      "R =  [[1.06267043 1.08004795 1.18483642 1.14782217]]\n",
      "R =  [[1.0626712  1.07995421 1.18485631 1.1478325 ]]\n",
      "R =  [[1.0626729  1.079862   1.1848798  1.14784473]]\n",
      "R =  [[1.06268439 1.07973776 1.1849128  1.14783381]]\n",
      "R =  [[1.06269684 1.07961553 1.18494931 1.14782483]]\n",
      "R =  [[1.06271024 1.07949529 1.18498929 1.14781777]]\n",
      "R =  [[1.06272458 1.07937702 1.18503268 1.14781261]]\n",
      "R =  [[1.06273986 1.07926071 1.18507945 1.14780934]]\n",
      "R =  [[1.06275606 1.07914635 1.18512955 1.14780794]]\n",
      "R =  [[1.06277318 1.07903392 1.18518294 1.14780841]]\n",
      "R =  [[1.06279121 1.07892341 1.18523957 1.14781071]]\n",
      "R =  [[1.06281014 1.0788148  1.18529941 1.14781485]]\n",
      "R =  [[1.06282995 1.07870808 1.18536241 1.1478208 ]]\n",
      "R =  [[1.06285066 1.07860323 1.18542853 1.14782856]]\n",
      "R =  [[1.06287224 1.07850024 1.18549773 1.14783811]]\n",
      "R =  [[1.06289468 1.07839911 1.18556997 1.14784943]]\n",
      "R =  [[1.06291799 1.0782998  1.18564521 1.14786251]]\n",
      "R =  [[1.06294215 1.07820232 1.18572342 1.14787734]]\n",
      "R =  [[1.06296716 1.07810664 1.18580456 1.14789391]]\n",
      "R =  [[1.062993   1.07801276 1.18588859 1.14791219]]\n",
      "R =  [[1.06301967 1.07792065 1.18597548 1.14793219]]\n",
      "R =  [[1.06304717 1.07783032 1.18606518 1.14795388]]\n",
      "R =  [[1.06307548 1.07774174 1.18615767 1.14797726]]\n",
      "R =  [[1.0631046  1.0776549  1.18625291 1.14809666]]\n",
      "R =  [[1.06313452 1.07756979 1.18635087 1.14821741]]\n",
      "R =  [[1.06316523 1.0774864  1.1864515  1.14833949]]\n",
      "R =  [[1.06319674 1.07740472 1.18655479 1.14846288]]\n",
      "R =  [[1.06322902 1.07732473 1.18666069 1.14858758]]\n",
      "R =  [[1.06326207 1.07724642 1.18676918 1.14871359]]\n",
      "R =  [[1.0632959  1.07716977 1.18688022 1.14884088]]\n",
      "R =  [[1.06333048 1.07709479 1.18699379 1.14896945]]\n",
      "R =  [[1.06336582 1.07702145 1.18710985 1.14909929]]\n",
      "R =  [[1.06342574 1.07666147 1.18717805 1.1492512 ]]\n",
      "R =  [[1.0634863  1.07630543 1.1872488  1.14940415]]\n",
      "R =  [[1.06354748 1.07595326 1.18732208 1.14955816]]\n",
      "R =  [[1.0636093  1.07560495 1.18739786 1.1497132 ]]\n",
      "R =  [[1.06367173 1.07526046 1.18747611 1.14986927]]\n",
      "R =  [[1.06373478 1.07491975 1.18755681 1.15002637]]\n",
      "R =  [[1.06379843 1.07458278 1.18763992 1.15018449]]\n",
      "R =  [[1.06386269 1.07424953 1.18772542 1.15034361]]\n",
      "R =  [[1.06387866 1.0739854  1.18766955 1.15048307]]\n",
      "R =  [[1.06389554 1.0737242  1.18761699 1.15062405]]\n",
      "R =  [[1.0639133  1.07346593 1.18756772 1.15076656]]\n",
      "R =  [[1.06393196 1.07321056 1.18752169 1.15091056]]\n",
      "R =  [[1.06395149 1.07295806 1.18747888 1.15105606]]\n",
      "R =  [[1.06397189 1.07270841 1.18743924 1.15120304]]\n",
      "R =  [[1.06399316 1.07246159 1.18740275 1.15135148]]\n",
      "R =  [[1.06401528 1.07221756 1.18736937 1.15150138]]\n",
      "R =  [[1.06403825 1.07197632 1.18733907 1.15165273]]\n",
      "R =  [[1.06406206 1.07173784 1.18731182 1.1518055 ]]\n",
      "R =  [[1.06408672 1.07150209 1.18728758 1.1519597 ]]\n",
      "R =  [[1.0641122  1.07126905 1.18726633 1.1521153 ]]\n",
      "R =  [[1.0641385  1.0710387  1.18724803 1.1522723 ]]\n",
      "R =  [[1.06416562 1.07081103 1.18723265 1.15243069]]\n",
      "R =  [[1.06419354 1.070586   1.18722017 1.15259045]]\n",
      "R =  [[1.06422228 1.07036359 1.18721055 1.15275157]]\n",
      "R =  [[1.0642518  1.0701438  1.18720377 1.15291405]]\n",
      "R =  [[1.06428212 1.06992658 1.18719979 1.15307786]]\n",
      "R =  [[1.06433616 1.07004798 1.1872209  1.1532874 ]]\n",
      "R =  [[1.06439079 1.07017041 1.18724459 1.15349771]]\n",
      "R =  [[1.06444602 1.07029386 1.18727083 1.15370876]]\n",
      "R =  [[1.06450182 1.07041834 1.1872996  1.15392057]]\n",
      "R =  [[1.0645582  1.07054384 1.18733087 1.15413312]]\n",
      "R =  [[1.06461516 1.07067034 1.18736461 1.15434641]]\n",
      "R =  [[1.06467269 1.07079784 1.18740081 1.15456044]]\n",
      "R =  [[1.06473078 1.07092633 1.18743943 1.15477519]]\n",
      "R =  [[1.06478943 1.07105581 1.18748046 1.15499067]]\n",
      "R =  [[1.06484864 1.07118627 1.18752386 1.15520686]]\n",
      "R =  [[1.0649084  1.0713177  1.18756962 1.15542377]]\n",
      "R =  [[1.06496871 1.07145009 1.18761771 1.15564139]]\n",
      "R =  [[1.06502956 1.07158345 1.18766811 1.15585971]]\n",
      "R =  [[1.06509094 1.07171775 1.1877208  1.15607873]]\n",
      "R =  [[1.06515287 1.071853   1.18777575 1.15629845]]\n",
      "R =  [[1.06521532 1.07198919 1.18783295 1.15651885]]\n",
      "R =  [[1.0652783  1.07212631 1.18789236 1.15673993]]\n",
      "R =  [[1.0653418  1.07226435 1.18795397 1.1569617 ]]\n",
      "R =  [[1.06540582 1.07240332 1.18801777 1.15718022]]\n",
      "R =  [[1.06547035 1.07254319 1.18808371 1.15739948]]\n",
      "R =  [[1.06553539 1.07268398 1.1881518  1.15761947]]\n",
      "R =  [[1.06560094 1.07282566 1.188222   1.1578402 ]]\n",
      "R =  [[1.06566699 1.07296824 1.18829429 1.15806165]]\n",
      "R =  [[1.06573354 1.0731117  1.18836866 1.15828382]]\n",
      "R =  [[1.06580058 1.07325604 1.18844509 1.1585067 ]]\n",
      "R =  [[1.06586811 1.07340126 1.18852355 1.1587303 ]]\n",
      "R =  [[1.06593613 1.07354735 1.18860402 1.1589546 ]]\n",
      "R =  [[1.06600464 1.0736943  1.1886865  1.1591796 ]]\n",
      "R =  [[1.06607362 1.07384211 1.18877095 1.15940529]]\n",
      "R =  [[1.06614308 1.07399077 1.18885736 1.15963168]]\n",
      "R =  [[1.06621301 1.07414028 1.18894572 1.15985875]]\n",
      "R =  [[1.06628341 1.07429063 1.189036   1.1600865 ]]\n",
      "R =  [[1.06635427 1.07444181 1.18912818 1.16031492]]\n",
      "R =  [[1.0663981  1.07459148 1.1891423  1.16053429]]\n",
      "R =  [[1.06644252 1.07474198 1.18915835 1.1607543 ]]\n",
      "R =  [[1.06648753 1.07489332 1.18917631 1.16097495]]\n",
      "R =  [[1.06653313 1.07504547 1.18919616 1.16119622]]\n",
      "R =  [[1.0665793  1.07519845 1.18921789 1.16141812]]\n",
      "R =  [[1.06662604 1.07535224 1.18924149 1.16164063]]\n",
      "R =  [[1.06667336 1.07550683 1.18939614 1.16186377]]\n",
      "R =  [[1.06672124 1.07566223 1.18955203 1.16208751]]\n",
      "R =  [[1.06676968 1.07581842 1.18970914 1.16231186]]\n",
      "R =  [[1.06681867 1.0759754  1.18986744 1.16253682]]\n",
      "R =  [[1.06686821 1.07613317 1.19002694 1.16276238]]\n",
      "R =  [[1.06691831 1.07629172 1.19018762 1.16298853]]\n",
      "R =  [[1.06696894 1.07645104 1.19034947 1.16321527]]\n",
      "R =  [[1.06702011 1.07661113 1.19051247 1.16344261]]\n",
      "R =  [[1.06707182 1.07677199 1.19067662 1.16367052]]\n",
      "R =  [[1.06712406 1.0769336  1.1908419  1.16389902]]\n",
      "R =  [[1.06717682 1.07709597 1.1910083  1.16412809]]\n",
      "R =  [[1.0672301  1.07725909 1.19117581 1.16435773]]\n",
      "R =  [[1.06727032 1.07742638 1.19107707 1.16458794]]\n",
      "R =  [[1.06731109 1.07759436 1.19098083 1.16481872]]\n",
      "R =  [[1.06735241 1.07776303 1.19088707 1.16505006]]\n",
      "R =  [[1.06739428 1.07793238 1.19079576 1.16528195]]\n",
      "R =  [[1.06743669 1.0781024  1.19070688 1.1655144 ]]\n",
      "R =  [[1.06747964 1.0782731  1.19062039 1.1657474 ]]\n",
      "R =  [[1.06752313 1.07844447 1.19053629 1.16598094]]\n",
      "R =  [[1.06756714 1.07861649 1.19045453 1.16621502]]\n",
      "R =  [[1.06761168 1.07878918 1.1903751  1.16644965]]\n",
      "R =  [[1.06765674 1.07896252 1.19029797 1.16668481]]\n",
      "R =  [[1.06770232 1.07913652 1.19022312 1.1669205 ]]\n",
      "R =  [[1.06774841 1.07931115 1.19015053 1.16715671]]\n",
      "R =  [[1.06779501 1.07948643 1.19008016 1.16739346]]\n",
      "R =  [[1.06784211 1.07966235 1.19001201 1.16763072]]\n",
      "R =  [[1.06788972 1.0798389  1.18994604 1.1678685 ]]\n",
      "R =  [[1.06793782 1.08001609 1.18988224 1.1681068 ]]\n",
      "R =  [[1.06798641 1.08019389 1.18982058 1.1683456 ]]\n",
      "R =  [[1.06803549 1.08037232 1.18976104 1.16858492]]\n",
      "R =  [[1.06808506 1.08055137 1.1897036  1.16882473]]\n",
      "R =  [[1.0681351  1.08073103 1.18964823 1.16906505]]\n",
      "R =  [[1.06818563 1.08091129 1.18959493 1.16932548]]\n",
      "R =  [[1.06823662 1.08109217 1.18954366 1.16958634]]\n",
      "R =  [[1.06829036 1.0812784  1.18946682 1.16981097]]\n",
      "R =  [[1.06834455 1.08146524 1.18939196 1.17003651]]\n",
      "R =  [[1.06839918 1.08165266 1.18931908 1.17026295]]\n",
      "R =  [[1.06845558 1.08183995 1.18925575 1.1704882 ]]\n",
      "R =  [[1.0685124  1.08202781 1.18919432 1.17071436]]\n",
      "R =  [[1.06856965 1.08221626 1.1891348  1.17094144]]\n",
      "R =  [[1.06862732 1.08240529 1.18907715 1.17116941]]\n",
      "R =  [[1.06868541 1.08259489 1.18902136 1.17139828]]\n",
      "R =  [[1.06874391 1.08278506 1.18896741 1.17162804]]\n",
      "R =  [[1.06880283 1.0829758  1.18891529 1.17185868]]\n",
      "R =  [[1.06886215 1.0831671  1.18886498 1.1720902 ]]\n",
      "R =  [[1.06892188 1.08335896 1.18881646 1.17232258]]\n",
      "R =  [[1.06898202 1.08355138 1.18876972 1.17255583]]\n",
      "R =  [[1.06904255 1.08374435 1.18872474 1.17278993]]\n",
      "R =  [[1.06910347 1.08393787 1.1886815  1.17302488]]\n",
      "R =  [[1.0691648  1.08413193 1.18863999 1.17326067]]\n",
      "R =  [[1.06922651 1.08432653 1.18860019 1.17349731]]\n",
      "R =  [[1.0692886  1.08452167 1.18856209 1.17373477]]\n",
      "R =  [[1.06935109 1.08471735 1.18852568 1.17397306]]\n",
      "R =  [[1.06941395 1.08491356 1.18849092 1.17421216]]\n",
      "R =  [[1.06947719 1.08511029 1.18845782 1.17445208]]\n",
      "R =  [[1.06954081 1.08530755 1.18842636 1.17469281]]\n",
      "R =  [[1.0696048  1.08550533 1.18839652 1.17493433]]\n",
      "R =  [[1.06966917 1.08570363 1.18836829 1.17517666]]\n",
      "R =  [[1.06974283 1.08580841 1.1883616  1.1754511 ]]\n",
      "R =  [[1.06981681 1.08591381 1.1883565  1.17572585]]\n",
      "R =  [[1.0698911  1.08601981 1.18835299 1.17600088]]\n",
      "R =  [[1.06996571 1.08612642 1.18835104 1.17627622]]\n",
      "R =  [[1.07004062 1.08623364 1.18835065 1.17655184]]\n",
      "R =  [[1.07011583 1.08634145 1.18835179 1.17682775]]\n",
      "R =  [[1.07019135 1.08644986 1.18835446 1.17710394]]\n",
      "R =  [[1.07026717 1.08655886 1.18835864 1.17726002]]\n",
      "R =  [[1.07034329 1.08666846 1.18836432 1.1774171 ]]\n",
      "R =  [[1.0704197  1.08677864 1.18837148 1.17757519]]\n",
      "R =  [[1.07049641 1.0868894  1.18838011 1.17773427]]\n",
      "R =  [[1.07057341 1.08700074 1.1883902  1.17789434]]\n",
      "R =  [[1.0706507  1.08711266 1.18840173 1.17805539]]\n",
      "R =  [[1.07072828 1.08722515 1.18841469 1.17821741]]\n",
      "R =  [[1.07080614 1.08733821 1.18842906 1.17838041]]\n",
      "R =  [[1.07088428 1.08745184 1.18844484 1.17854436]]\n",
      "R =  [[1.0709627  1.08756603 1.18846202 1.17870927]]\n",
      "R =  [[1.07104141 1.08768079 1.18848057 1.17887512]]\n",
      "R =  [[1.07112039 1.08779609 1.18850049 1.17904192]]\n",
      "R =  [[1.07119964 1.08791196 1.18852176 1.17920965]]\n",
      "R =  [[1.07127917 1.08802837 1.18854438 1.17937831]]\n",
      "R =  [[1.07135896 1.08814533 1.18856832 1.17954789]]\n",
      "R =  [[1.07143903 1.08826284 1.18859359 1.17971839]]\n",
      "R =  [[1.07151936 1.08838089 1.18862016 1.17988979]]\n",
      "R =  [[1.07159996 1.08849948 1.18864803 1.1800621 ]]\n",
      "R =  [[1.07168082 1.0886186  1.18867719 1.18023531]]\n",
      "R =  [[1.07176194 1.08873826 1.18870761 1.1804094 ]]\n",
      "R =  [[1.07184332 1.08885844 1.1887393  1.18058438]]\n",
      "R =  [[1.07192495 1.08897915 1.18877224 1.18076024]]\n",
      "R =  [[1.07200684 1.08910039 1.18880642 1.18093697]]\n",
      "R =  [[1.07208898 1.08922214 1.18884183 1.18111457]]\n",
      "R =  [[1.07217138 1.08934442 1.18887846 1.18129303]]\n",
      "R =  [[1.07225402 1.08946721 1.1889163  1.18147234]]\n",
      "R =  [[1.07233691 1.08959051 1.18895534 1.1816525 ]]\n",
      "R =  [[1.07242005 1.08971432 1.18899556 1.18183351]]\n",
      "R =  [[1.07250343 1.08983864 1.18903696 1.18201535]]\n",
      "R =  [[1.07258706 1.08996346 1.18907953 1.18219802]]\n",
      "R =  [[1.07267092 1.09008879 1.18912326 1.18238152]]\n",
      "R =  [[1.07275502 1.09021461 1.18916813 1.18256584]]\n",
      "R =  [[1.07283936 1.09034093 1.18921414 1.18275097]]\n",
      "R =  [[1.07292394 1.09046774 1.18926128 1.18293692]]\n",
      "R =  [[1.07300874 1.09059504 1.18930954 1.18312367]]\n",
      "R =  [[1.07309379 1.09072283 1.18935891 1.18331121]]\n",
      "R =  [[1.07317906 1.09083922 1.18940938 1.18353443]]\n",
      "R =  [[1.07326456 1.09095599 1.18946094 1.18375864]]\n",
      "R =  [[1.07335028 1.09107313 1.18951358 1.18398385]]\n",
      "R =  [[1.07343623 1.09119065 1.18956729 1.18421004]]\n",
      "R =  [[1.07352241 1.09130853 1.18962207 1.18443721]]\n",
      "R =  [[1.07360881 1.09142678 1.1896779  1.18466535]]\n",
      "R =  [[1.07369543 1.09154539 1.18973478 1.18489446]]\n",
      "R =  [[1.07378227 1.09166437 1.1897927  1.18512452]]\n",
      "R =  [[1.07386932 1.09178371 1.18985164 1.18535553]]\n",
      "R =  [[1.07395659 1.0919034  1.18991161 1.18558748]]\n",
      "R =  [[1.07404408 1.09202346 1.18997259 1.18582036]]\n",
      "R =  [[1.07413178 1.09214387 1.19003457 1.18605418]]\n",
      "R =  [[1.07421969 1.09226463 1.19009754 1.18628891]]\n",
      "R =  [[1.07430781 1.09238575 1.19016151 1.18652455]]\n",
      "R =  [[1.07439614 1.09250721 1.19022645 1.1867611 ]]\n",
      "R =  [[1.07448467 1.09262903 1.19029237 1.18699855]]\n",
      "R =  [[1.07457342 1.09275119 1.19035925 1.1872369 ]]\n",
      "R =  [[1.07466236 1.09287369 1.19042708 1.18747613]]\n",
      "R =  [[1.07475151 1.09299654 1.19049586 1.18771623]]\n",
      "R =  [[1.07484086 1.09311973 1.19056558 1.18795721]]\n",
      "R =  [[1.07493042 1.09324326 1.19063624 1.18819906]]\n",
      "R =  [[1.07502016 1.09336713 1.19070782 1.18844177]]\n",
      "R =  [[1.07511011 1.09349133 1.19078032 1.18868532]]\n",
      "R =  [[1.07520025 1.09361587 1.19085373 1.18892973]]\n",
      "R =  [[1.07529059 1.09374074 1.19092804 1.18917497]]\n",
      "R =  [[1.07538112 1.09386594 1.19100325 1.18942105]]\n",
      "R =  [[1.07547185 1.09399147 1.19107935 1.18966796]]\n",
      "R =  [[1.07556276 1.09411733 1.19115633 1.18991569]]\n",
      "R =  [[1.07565386 1.09424352 1.19123418 1.19016423]]\n",
      "R =  [[1.07574515 1.09437003 1.1913129  1.19041359]]\n",
      "R =  [[1.07583663 1.09449686 1.19139249 1.19066375]]\n",
      "R =  [[1.07592829 1.09462401 1.19147292 1.1909147 ]]\n",
      "R =  [[1.07602014 1.09475148 1.19155421 1.19116645]]\n",
      "R =  [[1.07611217 1.09487927 1.19163634 1.19141898]]\n",
      "R =  [[1.07620438 1.09500738 1.1917193  1.19167229]]\n",
      "R =  [[1.07629678 1.0951358  1.19180309 1.19192637]]\n",
      "R =  [[1.07638935 1.09526454 1.1918877  1.19218123]]\n",
      "R =  [[1.0764821  1.09539358 1.19197313 1.19243684]]\n",
      "R =  [[1.07657503 1.09552294 1.19205936 1.19269322]]\n",
      "R =  [[1.07666813 1.09565261 1.1921464  1.19295034]]\n",
      "R =  [[1.07676141 1.09578258 1.19223423 1.19320821]]\n",
      "R =  [[1.07685486 1.09591286 1.19232286 1.19346682]]\n",
      "R =  [[1.07694848 1.09604344 1.19241227 1.19372617]]\n",
      "R =  [[1.07704228 1.09617432 1.19250245 1.19398624]]\n",
      "R =  [[1.07713624 1.09630551 1.19259341 1.19424704]]\n",
      "R =  [[1.07723038 1.09643699 1.19268514 1.19450856]]\n",
      "R =  [[1.07732468 1.09656877 1.19277762 1.19477079]]\n",
      "R =  [[1.07741914 1.09670085 1.19287086 1.19503373]]\n",
      "R =  [[1.07751378 1.09683322 1.19296485 1.19529737]]\n",
      "R =  [[1.07760857 1.09696589 1.19305958 1.19556171]]\n",
      "R =  [[1.07770354 1.09709885 1.19315505 1.19582674]]\n",
      "R =  [[1.07779866 1.0972321  1.19325126 1.19609246]]\n",
      "R =  [[1.07789394 1.09736564 1.19334818 1.19635887]]\n",
      "R =  [[1.07798939 1.0975102  1.19344583 1.19662595]]\n",
      "R =  [[1.07808499 1.09765504 1.1935442  1.1968937 ]]\n",
      "R =  [[1.07818075 1.09780016 1.19364328 1.19716212]]\n",
      "R =  [[1.07827667 1.09794555 1.19374306 1.19743121]]\n",
      "R =  [[1.07837274 1.09809121 1.19384354 1.19770095]]\n",
      "R =  [[1.07846897 1.09823715 1.19394471 1.19797135]]\n",
      "R =  [[1.07856536 1.09838336 1.19404657 1.19824239]]\n",
      "R =  [[1.07866189 1.09852983 1.19414912 1.19851408]]\n",
      "R =  [[1.07875858 1.09867658 1.19425235 1.19878641]]\n",
      "R =  [[1.07885542 1.09882359 1.19435625 1.19905938]]\n",
      "R =  [[1.07895241 1.09897087 1.19446082 1.19933297]]\n",
      "R =  [[1.07904955 1.09911841 1.19456605 1.19960719]]\n",
      "R =  [[1.07914683 1.09926621 1.19467195 1.19988203]]\n",
      "R =  [[1.07924427 1.09941428 1.19477849 1.20015748]]\n",
      "R =  [[1.07934185 1.0995626  1.19488569 1.20043355]]\n",
      "R =  [[1.07943683 1.09941324 1.19497267 1.20071023]]\n",
      "R =  [[1.07953195 1.0992746  1.19507071 1.20102323]]\n",
      "R =  [[1.07962722 1.09913769 1.19516931 1.20133678]]\n",
      "R =  [[1.07972262 1.09895306 1.19526845 1.20165088]]\n",
      "R =  [[1.07981817 1.09877069 1.19536813 1.20196553]]\n",
      "R =  [[1.07991386 1.09859054 1.19546835 1.20228071]]\n",
      "R =  [[1.08000969 1.09841261 1.19556911 1.20259644]]\n",
      "R =  [[1.08010565 1.09823689 1.1956704  1.20291269]]\n",
      "R =  [[1.08020175 1.09806335 1.19577221 1.20322948]]\n",
      "R =  [[1.08029799 1.09789197 1.19587455 1.20354678]]\n",
      "R =  [[1.08039437 1.09772275 1.1959774  1.20386461]]\n",
      "R =  [[1.08049088 1.09755567 1.19608077 1.20418295]]\n",
      "R =  [[1.08058752 1.09739072 1.19618466 1.20450181]]\n",
      "R =  [[1.08068429 1.09717124 1.19628905 1.20483351]]\n",
      "R =  [[1.0807812  1.09695453 1.19639394 1.20516572]]\n",
      "R =  [[1.08087824 1.09674058 1.19649934 1.20549842]]\n",
      "R =  [[1.08097541 1.09652937 1.19660523 1.20583163]]\n",
      "R =  [[1.08107271 1.09632087 1.19671161 1.20616533]]\n",
      "R =  [[1.08117013 1.09611507 1.19681849 1.20649951]]\n",
      "R =  [[1.08126769 1.09591193 1.19692585 1.20683418]]\n",
      "R =  [[1.08136537 1.09571144 1.1970337  1.20716934]]\n",
      "R =  [[1.08146318 1.09551358 1.19714202 1.20750497]]\n",
      "R =  [[1.08156111 1.09531833 1.19725082 1.20784107]]\n",
      "R =  [[1.08165917 1.09512566 1.19736009 1.20817765]]\n",
      "R =  [[1.08175735 1.09493556 1.19746983 1.20851468]]\n",
      "R =  [[1.08185566 1.09474801 1.19758004 1.20885219]]\n",
      "R =  [[1.08195409 1.09456299 1.19769071 1.20919015]]\n",
      "R =  [[1.08205264 1.09438047 1.19780184 1.20952856]]\n",
      "R =  [[1.08215131 1.09420044 1.19791343 1.20986743]]\n",
      "R =  [[1.0822501  1.09402288 1.19802546 1.21020675]]\n",
      "R =  [[1.08234901 1.09384777 1.19813795 1.21054651]]\n",
      "R =  [[1.0824459  1.09374002 1.19825624 1.21093199]]\n",
      "R =  [[1.08254292 1.09363397 1.19837498 1.21131784]]\n",
      "R =  [[1.08264005 1.09352961 1.19849415 1.21170404]]\n",
      "R =  [[1.0827373  1.09342692 1.19861375 1.2120906 ]]\n",
      "R =  [[1.08283467 1.09332589 1.19873379 1.21247751]]\n",
      "R =  [[1.08293215 1.09322652 1.19885426 1.21286477]]\n",
      "R =  [[1.08302975 1.09312878 1.19897515 1.21325236]]\n",
      "R =  [[1.08312746 1.09303268 1.19909647 1.2136403 ]]\n",
      "R =  [[1.08322529 1.09293819 1.19921821 1.21402858]]\n",
      "R =  [[1.08332323 1.09284531 1.19934036 1.21441719]]\n",
      "R =  [[1.08342129 1.09275403 1.19946293 1.21480614]]\n",
      "R =  [[1.08351946 1.09266434 1.19958591 1.21519541]]\n",
      "R =  [[1.08361774 1.09257622 1.1997093  1.21558501]]\n",
      "R =  [[1.08371613 1.09248967 1.19983309 1.21597493]]\n",
      "R =  [[1.08381463 1.09240467 1.19995729 1.21636517]]\n",
      "R =  [[1.08391324 1.09232122 1.20008189 1.21675572]]\n",
      "R =  [[1.08401195 1.09223931 1.20020688 1.21714659]]\n",
      "R =  [[1.08411078 1.09215892 1.20033227 1.21753777]]\n",
      "R =  [[1.08420971 1.09208005 1.20045806 1.21792926]]\n",
      "R =  [[1.08430875 1.09200269 1.20058423 1.21832105]]\n",
      "R =  [[1.0844079  1.09192682 1.20071079 1.21871315]]\n",
      "R =  [[1.08450715 1.09185244 1.20083773 1.21910554]]\n",
      "R =  [[1.08460651 1.09177953 1.20096506 1.21949824]]\n",
      "R =  [[1.08470597 1.0917081  1.20109276 1.21989122]]\n",
      "R =  [[1.08480554 1.09163812 1.20122084 1.2202845 ]]\n",
      "R =  [[1.0849052  1.09156959 1.2013493  1.22067806]]\n",
      "R =  [[1.08500497 1.0915025  1.20147813 1.22107191]]\n",
      "R =  [[1.08510485 1.09143684 1.20160732 1.22146605]]\n",
      "R =  [[1.08520482 1.0913726  1.20173688 1.22186046]]\n",
      "R =  [[1.08530489 1.09130977 1.20186681 1.22225515]]\n",
      "R =  [[1.08540507 1.09124835 1.2019971  1.22265012]]\n",
      "R =  [[1.08550534 1.09118832 1.20212774 1.22304536]]\n",
      "R =  [[1.08560571 1.09112967 1.20225874 1.22344087]]\n",
      "R =  [[1.08570618 1.09107241 1.2023901  1.22383664]]\n",
      "R =  [[1.08580675 1.09101651 1.20252181 1.22423268]]\n",
      "R =  [[1.08590741 1.09096197 1.20265387 1.22462899]]\n",
      "R =  [[1.08600817 1.09090878 1.20278628 1.22502555]]\n",
      "R =  [[1.08610903 1.09085693 1.20291903 1.22542237]]\n",
      "R =  [[1.08620998 1.09080642 1.20305212 1.22581945]]\n",
      "R =  [[1.08631102 1.09075723 1.20318555 1.22621678]]\n",
      "R =  [[1.08641216 1.09070936 1.20331933 1.22661436]]\n",
      "R =  [[1.08651339 1.0906628  1.20345343 1.22701219]]\n",
      "R =  [[1.08661472 1.09061753 1.20358788 1.22741026]]\n",
      "R =  [[1.08671614 1.09057357 1.20372265 1.22780857]]\n",
      "R =  [[1.08681765 1.09053088 1.20385775 1.22820713]]\n",
      "R =  [[1.08692246 1.09050733 1.20399318 1.22848888]]\n",
      "R =  [[1.08702735 1.09048484 1.20412894 1.2287711 ]]\n",
      "R =  [[1.08713232 1.09044232 1.20426501 1.2288892 ]]\n",
      "R =  [[1.08726954 1.09039968 1.2043938  1.22884684]]\n",
      "R =  [[1.08740683 1.0903584  1.2045231  1.22880618]]\n"
     ]
    }
   ],
   "source": [
    "nb_burn_in_iter = 0 \n",
    "threshold = 1.1\n",
    "\n",
    "for i in range(nb_iter):\n",
    "    # Initialize arrays for new parameter values\n",
    "    x_new = np.zeros((nb_layer, nb_param))\n",
    "    X_new = np.zeros((nb_chain, nb_layer, nb_param))\n",
    "    std_X = np.std(X, axis=0)\n",
    "    \n",
    "    # Loop over chains\n",
    "    for j in range(nb_chain):\n",
    "        # Initialize arrays for new parameter values\n",
    "        dX = np.zeros((nb_layer,nb_param))\n",
    "        \n",
    "        # Loop over layers\n",
    "        for l in range(nb_layer):\n",
    "            # Select a crossover point\n",
    "            id = np.random.choice(ncr, p=pcr[l])\n",
    "            \n",
    "            # Generate random numbers\n",
    "            z = np.random.uniform(0, 1, nb_param)\n",
    "            A = (z <= cr_vec[id])\n",
    "            d_star = np.sum(A)\n",
    "            \n",
    "            # If no parameters are selected, select the smallest one\n",
    "            if d_star == 0:\n",
    "                A[np.argmin(z)] = True\n",
    "                d_star = 1\n",
    "            \n",
    "            # Generate random numbers\n",
    "            lambd = np.random.uniform(-c, c, d_star)\n",
    "            zeta = np.random.normal(0, c_star, d_star)\n",
    "            \n",
    "            # Select chains for difference vectors\n",
    "            choose = np.delete(np.arange(nb_chain), j)\n",
    "            a = np.random.choice(choose, delta, replace=False)\n",
    "            choose = np.delete(choose, np.where(np.isin(a, choose)))\n",
    "            b = np.random.choice(choose, delta, replace=False)\n",
    "            \n",
    "            # Compute difference vectors\n",
    "            gamma = 2.38 / np.sqrt(2 * d_star * delta)\n",
    "            dX[l][A] = zeta + (1 + lambd) * gamma * np.sum(X[a,l][:,A] - X[b,l][:,A], axis=0)\n",
    "            \n",
    "            # Compute new parameter values\n",
    "            x_new[l] = X[j,l] + dX[l]\n",
    "            x_new[l] = check_range(x_new[l], ranges[l])\n",
    "        \n",
    "        # Compute new temperature profile and energy\n",
    "        col.compute_solve_transi(convert_to_layer(name_layer, z_low, x_new), nb_cells, verbose=False)\n",
    "        temp_new = col.get_temperatures_solve()\n",
    "        energy_new = compute_energy(temp_new[ind_ref, :])\n",
    "        \n",
    "        # Compute acceptance probability\n",
    "        log_ratio_accept = compute_log_acceptance(energy_new, _energy[i][j])\n",
    "        \n",
    "        # Accept or reject new parameter values\n",
    "        if np.log(np.random.uniform(0, 1)) < log_ratio_accept:\n",
    "            X_new[j] = x_new\n",
    "            _temp[i+1][j] = temp_new\n",
    "            _energy[i+1][j] = energy_new\n",
    "        else:\n",
    "            dX = np.zeros((nb_layer, nb_param))\n",
    "            X_new[j] = X[j]\n",
    "            _temp[i+1][j] = _temp[i-1][j]\n",
    "            _energy[i+1][j] = _energy[i-1][j]\n",
    "        \n",
    "        # Update J and n_id\n",
    "        for l in range(nb_layer):\n",
    "            J[l,id] += np.sum((dX[l] / std_X[l])**2)\n",
    "            n_id[l,id] += 1\n",
    "    \n",
    "    # Update pcr\n",
    "    for l in range(nb_layer):\n",
    "        pcr[l] = J[l] / n_id[l]\n",
    "        pcr[l] = pcr[l] / np.sum(pcr[l])\n",
    "    \n",
    "    # Update parameter values\n",
    "    X = X_new\n",
    "    _params[i+1] = X_new\n",
    "    \n",
    "    # Check for convergence\n",
    "    if gelman_rubin(i+2, nb_param, nb_layer, _params[:i+2], threshold=threshold):\n",
    "        print(f\"Burn in finished after : {nb_burn_in_iter} iterations\")\n",
    "        break\n",
    "    nb_burn_in_iter += 1 \n",
    "    \n",
    "    \n",
    "# Burn in finished, parameters are now saved\n",
    "_params = np.zeros((nb_iter + 1, nb_chain, nb_layer, nb_param))\n",
    "_params[0] = X\n",
    "_temp = np.zeros((nb_iter + 1, nb_chain, nb_cells, len(col._times)), np.float32)\n",
    "_energy = np.zeros((nb_iter + 1, nb_chain))\n",
    "for i in range(nb_iter):\n",
    "    # Initialize arrays for new parameter values\n",
    "    x_new = np.zeros((nb_layer, nb_param))\n",
    "    X_new = np.zeros((nb_chain, nb_layer, nb_param))\n",
    "    std_X = np.std(X, axis=0)\n",
    "    \n",
    "    # Loop over chains\n",
    "    for j in range(nb_chain):\n",
    "        # Initialize arrays for new parameter values\n",
    "        dX = np.zeros((nb_layer,nb_param))\n",
    "        \n",
    "        # Loop over layers\n",
    "        for l in range(nb_layer):\n",
    "            # Select a crossover point\n",
    "            id = np.random.choice(ncr, p=pcr[l])\n",
    "            \n",
    "            # Generate random numbers\n",
    "            z = np.random.uniform(0, 1, nb_param)\n",
    "            A = (z <= cr_vec[id])\n",
    "            d_star = np.sum(A)\n",
    "            \n",
    "            # If no parameters are selected, select the smallest one\n",
    "            if d_star == 0:\n",
    "                A[np.argmin(z)] = True\n",
    "                d_star = 1\n",
    "            \n",
    "            # Generate random numbers\n",
    "            lambd = np.random.uniform(-c, c, d_star)\n",
    "            zeta = np.random.normal(0, c_star, d_star)\n",
    "            \n",
    "            # Select chains for difference vectors\n",
    "            choose = np.delete(np.arange(nb_chain), j)\n",
    "            a = np.random.choice(choose, delta, replace=False)\n",
    "            choose = np.delete(choose, np.where(np.isin(a, choose)))\n",
    "            b = np.random.choice(choose, delta, replace=False)\n",
    "            \n",
    "            # Compute difference vectors\n",
    "            gamma = 2.38 / np.sqrt(2 * d_star * delta)\n",
    "            dX[l][A] = zeta + (1 + lambd) * gamma * np.sum(X[a,l][:,A] - X[b,l][:,A], axis=0)\n",
    "            \n",
    "            # Compute new parameter values\n",
    "            x_new[l] = X[j,l] + dX[l]\n",
    "            x_new[l] = check_range(x_new[l], ranges[l])\n",
    "        \n",
    "        # Compute new temperature profile and energy\n",
    "        col.compute_solve_transi(convert_to_layer(name_layer, z_low, x_new), nb_cells, verbose=False)\n",
    "        temp_new = col.get_temperatures_solve()\n",
    "        energy_new = compute_energy(temp_new[ind_ref, :])\n",
    "        \n",
    "        # Compute acceptance probability\n",
    "        log_ratio_accept = compute_log_acceptance(energy_new, _energy[i][j])\n",
    "        \n",
    "        # Accept or reject new parameter values\n",
    "        if np.log(np.random.uniform(0, 1)) < log_ratio_accept:\n",
    "            X_new[j] = x_new\n",
    "            _temp[i+1][j] = temp_new\n",
    "            _energy[i+1][j] = energy_new\n",
    "        else:\n",
    "            dX = np.zeros((nb_layer, nb_param))\n",
    "            X_new[j] = X[j]\n",
    "            _temp[i+1][j] = _temp[i-1][j]\n",
    "            _energy[i+1][j] = _energy[i-1][j]\n",
    "        \n",
    "        # Update J and n_id\n",
    "        for l in range(nb_layer):\n",
    "            J[l,id] += np.sum((dX[l] / std_X[l])**2)\n",
    "            n_id[l,id] += 1\n",
    "            \n",
    "    # Update parameter values\n",
    "    X = X_new\n",
    "    _params[i+1] = X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dream_mcmc_without_sigma2(\n",
    "        self,\n",
    "        nb_iter: int,\n",
    "        all_priors: Union[\n",
    "            AllPriors,\n",
    "            Sequence[\n",
    "                Union[\n",
    "                    LayerPriors,\n",
    "                    Sequence[Union[str, float, Sequence[Union[Prior, dict]]]],\n",
    "                ]\n",
    "            ],\n",
    "        ],\n",
    "        nb_cells: int,\n",
    "        nb_chain: int,\n",
    "        quantile: Union[float, Sequence[float]] = (0.05, 0.5, 0.95),\n",
    "        verbose=True,\n",
    "        sigma2=1.0,\n",
    "        delta=3,\n",
    "        ncr=3,\n",
    "        c=0.1,\n",
    "        c_star=1e-6,\n",
    "    ):\n",
    "        if isinstance(quantile, Number):\n",
    "            quantile = [quantile]\n",
    "\n",
    "        if not isinstance(all_priors, AllPriors):\n",
    "            all_priors = AllPriors([LayerPriors(*conv(layer)) for layer in all_priors])\n",
    "\n",
    "        dz = self._real_z[-1] / nb_cells\n",
    "        _z_solve = dz / 2 + np.array([k * dz for k in range(nb_cells)])\n",
    "        ind_ref = [np.argmin(np.abs(z - _z_solve)) for z in self._real_z[1:-1]]\n",
    "        temp_ref = self._T_measures[:, :].T\n",
    "        nb_layer = len(all_priors)\n",
    "        nb_param = 4\n",
    "\n",
    "        def compute_energy(temp: np.array):\n",
    "            norm2 = np.nansum((temp - temp_ref) ** 2)\n",
    "            return 0.5 * norm2 / sigma2\n",
    "\n",
    "        def compute_log_acceptance(actual_energy: float, prev_energy: float):\n",
    "            return prev_energy - actual_energy\n",
    "\n",
    "        def convert_to_layer(name_layer, z_low, params):\n",
    "            return [Layer(name_layer[i], z_low[i], *params[i]) for i in range(nb_layer)]\n",
    "\n",
    "        def check_range(x, ranges):\n",
    "            while np.sum(x < ranges[:, 0]) + np.sum(x > ranges[:, 1]) > 0:\n",
    "                x = (\n",
    "                    (x < ranges[:, 0]) * (ranges[:, 1] - (ranges[:, 0] - x))\n",
    "                    + (x > ranges[:, 1]) * (ranges[:, 0] + (x - ranges[:, 1]))\n",
    "                    + (x >= ranges[:, 0]) * (x <= ranges[:, 1]) * x\n",
    "                )\n",
    "            return x\n",
    "        \n",
    "        def gelman_rubin(nb_current_iter, nb_param, nb_layer, chains, threshold=1.1):\n",
    "            \"\"\"\n",
    "            Input : chains [3D np.array] - chaînes de Markov calculées en parallèle\n",
    "                    threshold [float] - seuil de l'indicateur de Gelman-Rubin, légèrement supérieur à 1\n",
    "            \n",
    "            Output : [bool] - True si et seulement si la phase de burn-in est considérée finie\n",
    "            \"\"\"\n",
    "            R = np.zeros((nb_layer, nb_param))\n",
    "            for l in range(nb_layer):   \n",
    "                chains_layered = chains[:,:,l,:]\n",
    "                # Variances intra-chaînes des paramètres\n",
    "                Var_intra = np.var(chains_layered, axis=0)\n",
    "\n",
    "                # Moyenne des variances intra-chaîne\n",
    "                var_intra = np.mean(Var_intra, axis=0)\n",
    "\n",
    "                # Moyennes de chaque chaîne\n",
    "                means_chains = np.mean(chains_layered, axis=0)\n",
    "\n",
    "                # Variance entre les moyennes des chaînes, dite inter-chaînes\n",
    "                var_inter = np.var(means_chains, axis=0)\n",
    "\n",
    "                # Calcul de l'indicateur de Gelman-Rubin\n",
    "                for j in range(nb_param):\n",
    "                    if np.isclose(var_intra[j], 0) :\n",
    "                        R[l,j] = 2\n",
    "                    else:\n",
    "                        R[l,j] = np.sqrt( var_inter[j] / var_intra[j] * (nb_current_iter - 1) / nb_current_iter + 1) # Vérifier la formule\n",
    "\n",
    "            #print(\"R = \", R)\n",
    "\n",
    "            # On considère que la phase de burn-in est terminée dès que R < threshold\n",
    "            return np.all(R < threshold)\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"--- Compute Mcmc ---\",\n",
    "                \"Priors :\",\n",
    "                *(f\"    {prior}\" for prior in all_priors),\n",
    "                f\"Number of cells : {nb_cells}\",\n",
    "                f\"Number of iterations : {nb_iter}\",\n",
    "                f\"Number of chains : {nb_chain}\",\n",
    "                \"Launch Mcmc\",\n",
    "                sep=\"\\n\",\n",
    "            )\n",
    "\n",
    "        ranges = np.empty((nb_layer, nb_param, 2))\n",
    "        for l in range(nb_layer):\n",
    "            for p in range(nb_param):\n",
    "                ranges[l, p] = all_priors[l][p].range\n",
    "\n",
    "        # paramètres de stockage des résultats\n",
    "        self._states = list()\n",
    "        self._acceptance = np.zeros((nb_iter, nb_chain))\n",
    "        X = np.array([np.array(all_priors.sample()) for _ in range(nb_chain)])\n",
    "        X = np.array(\n",
    "            [\n",
    "                np.array([X[c][l].params for l in range(nb_layer)])\n",
    "                for c in range(nb_chain)\n",
    "            ]\n",
    "        )\n",
    "        _params = np.zeros((nb_iter + 1, nb_chain, nb_layer, nb_param))\n",
    "        _params[0] = X\n",
    "        _temp = np.zeros(\n",
    "            (nb_iter + 1, nb_chain, nb_cells, len(self._times)), np.float32\n",
    "        )\n",
    "        _energy = np.zeros((nb_iter + 1, nb_chain))\n",
    "        temp_new = np.zeros((nb_cells, len(self._times)))\n",
    "        energy_new = 0\n",
    "        name_layer = [all_priors.sample()[i].name for i in range(nb_layer)]\n",
    "        z_low = [all_priors.sample()[i].zLow for i in range(nb_layer)]\n",
    "\n",
    "        # paramètres de DREAM\n",
    "        cr_vec = np.arange(1, ncr + 1) / ncr\n",
    "        n_id = np.zeros((nb_layer, ncr))\n",
    "        J = np.zeros((nb_layer, ncr))\n",
    "        pcr = np.ones((nb_layer, ncr)) / ncr\n",
    "        nb_accepted = 0  # nombre de propositions acceptées\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Burn in phase\")\n",
    "        for i in range(nb_iter):\n",
    "            # Initialisation pour les nouveaux paramètres\n",
    "            x_new = np.zeros((nb_layer, nb_param))\n",
    "            X_new = np.zeros((nb_chain, nb_layer, nb_param))\n",
    "            std_X = np.std(X, axis=0)\n",
    "            for j in range(nb_chain):\n",
    "                dX = np.zeros((nb_layer, nb_param))\n",
    "                # Loop over layers\n",
    "                for l in range(nb_layer):\n",
    "                    # Select a crossover point\n",
    "                    id = np.random.choice(ncr, p=pcr[l])\n",
    "\n",
    "                    # Generate random numbers\n",
    "                    z = np.random.uniform(0, 1, nb_param)\n",
    "                    A = z <= cr_vec[id]\n",
    "                    d_star = np.sum(A)\n",
    "\n",
    "                    # If no parameters are selected, select the smallest one\n",
    "                    if d_star == 0:\n",
    "                        A[np.argmin(z)] = True\n",
    "                        d_star = 1\n",
    "\n",
    "                    # Generate random numbers\n",
    "                    lambd = np.random.uniform(-c, c, d_star)\n",
    "                    zeta = np.random.normal(0, c_star, d_star)\n",
    "\n",
    "                    # Select chains for difference vectors\n",
    "                    choose = np.delete(np.arange(nb_chain), j)\n",
    "                    a = np.random.choice(choose, delta, replace=False)\n",
    "                    choose = np.delete(choose, np.where(np.isin(a, choose)))\n",
    "                    b = np.random.choice(choose, delta, replace=False)\n",
    "\n",
    "                    # Compute difference vectors\n",
    "                    gamma = 2.38 / np.sqrt(2 * d_star * delta)\n",
    "                    dX[l][A] = zeta + (1 + lambd) * gamma * np.sum(\n",
    "                        X[a, l][:, A] - X[b, l][:, A], axis=0\n",
    "                    )\n",
    "\n",
    "                    # Compute new parameter values\n",
    "                    x_new[l] = X[j, l] + dX[l]\n",
    "                    x_new[l] = check_range(x_new[l], ranges[l])\n",
    "\n",
    "                # Compute new temperature profile and energy\n",
    "                self.compute_solve_transi(\n",
    "                    convert_to_layer(name_layer, z_low, x_new), nb_cells, verbose=False\n",
    "                )\n",
    "                temp_new = self.get_temperatures_solve()\n",
    "                energy_new = compute_energy(temp_new[ind_ref, :])\n",
    "\n",
    "                # Compute acceptance probability\n",
    "                log_ratio_accept = compute_log_acceptance(energy_new, _energy[i][j])\n",
    "\n",
    "                # Accept of reject new parameter values\n",
    "                if np.log(np.random.uniform(0, 1)) < log_ratio_accept:\n",
    "                    X_new[j] = x_new\n",
    "                    _temp[i + 1][j] = temp_new\n",
    "                    _energy[i + 1][j] = energy_new\n",
    "                else:\n",
    "                    dX = np.zeros((nb_layer, nb_param))\n",
    "                    X_new[j] = X[j]\n",
    "                    _temp[i + 1][j] = _temp[i - 1][j]\n",
    "\n",
    "                # Update J and n_id\n",
    "                for l in range(nb_layer):\n",
    "                    J[l, id] += np.sum((dX[l] / std_X[l]) ** 2)\n",
    "                    n_id[l, id] += 1\n",
    "            # Update pcr\n",
    "            for l in range(nb_layer):\n",
    "                pcr[l] = J[l] / n_id[l]\n",
    "                pcr[l] = pcr[l] / np.sum(pcr[l])\n",
    "\n",
    "            # Update parameters values\n",
    "            X = X_new\n",
    "            _params[i + 1] = X_new\n",
    "            \n",
    "            # Check for convergence\n",
    "            \"\"\"\n",
    "            Implémenter Gelman Rubin\n",
    "            _params : (nombre d'itération + 1, nombre de chaines, nombre de couche, nombre de paramètres)\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = \"../images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the figure\n",
    "threshold = 1.1  # Example threshold value\n",
    "plt.savefig(f\"{output_dir}/threshold_{int(threshold*100)}.png\")\n",
    "\n",
    "nb_iter, nb_chain, nb_layer, nb_param = _params.shape\n",
    "_params_without_chains = _params.reshape(nb_iter * nb_chain, nb_layer, nb_param)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(f\"Threshold = {threshold}        Burn-in over after {nb_burn_in_iter} iterations\")\n",
    "plt.axis('off')\n",
    "dico = {0 : \"$-log(K)$\", 1 : \"$\\lambda_s$\", 2 : \"$n$\", 3 : \"$rho * C$\"}\n",
    "for k in range(nb_param):\n",
    "    plt.subplot(2, 2, k+1)\n",
    "    plt.hist(_params_without_chains[:,0,k], bins = 100, label=f\"{dico[k]}\")\n",
    "    plt.legend();\n",
    "plt.savefig(f\"../images/threshold_{int(threshold*100)}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul des quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà la façon dont sont calculés les quantiles de température (idem pour le flow) dans le projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile = np.array([0.05, 0.5, 0.95])\n",
    "quantiles_temperatures = np.quantile(_temp, quantile, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le calcul est gourmand en temps de calcul et nécessite de stocker un tableau `quantiles_temps` et un tableau `temp` dont les tailles sont indiquées ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de quantiles_temperatures :  (3, 10, 100, 1309)  (nb_quantiles, nb_chain, n_cells, n_temperatures)\n",
      "Dimensions de quantiles_temperatures :  (1001, 10, 100, 1309)  (nb_iter, nb_chain, n_cells, n_temperatures)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions de quantiles_temperatures : \", quantiles_temperatures.shape, \" (nb_quantiles, nb_chain, n_cells, n_temperatures)\")\n",
    "print(\"Dimensions de quantiles_temperatures : \", _temp.shape, \" (nb_iter, nb_chain, n_cells, n_temperatures)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces deux tableaux représentent un encombrement mémoire important qui dépasse le seuil fixé par le cahier des charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mémoire pour les quantiles de température :  31.416  Méga octets.\n",
      "Mémoire pour les températures :  5.241236 Giga octets.\n"
     ]
    }
   ],
   "source": [
    "print(\"Mémoire pour les quantiles de température : \", quantiles_temperatures.nbytes/1000000, \" Méga octets.\")\n",
    "print(\"Mémoire pour les températures : \", _temp.nbytes/1000000000, \"Giga octets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour réduire cet encombrement mémoire, on peut intuitivement supposer que les profils de température ne varient pas énormément entre deux pas de temps consécutifs. On peut donc réaliser un sous-échantillonnage sur les pas de temps afin de calculer les quantiles. De même, on peut réaliser un sous-échantillonnage spatial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sous_ech_time = 2 # 1 mesure considérée par demi-heure\n",
    "n_sous_ech_space = 4 # 1 mesure considérée tous les 2 cm\n",
    "\n",
    "_temp_sous_ech = _temp[:,:,::n_sous_ech_space,::n_sous_ech_time]\n",
    "quantiles_temperatures_sous_ech = np.quantile(_temp_sous_ech, quantile, axis=0)\n",
    "\n",
    "np.allclose(quantiles_temperatures_sous_ech,  quantiles_temperatures[:, :, ::n_sous_ech_space, ::n_sous_ech_time])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les quantiles sont calculés sur chaque case $(chaine, cellule, temps)$ en utilisant les valeurs obtenues avec les itérations, il est donc normal que ces deux calculs conduisent aux mêmes valeurs de quantiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Déterminons alors le nouvel encombrement mémoire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mémoire pour les quantiles de température :  3.93  Méga octets.\n",
      "Mémoire pour les températures :  0.655655 Giga octets.\n"
     ]
    }
   ],
   "source": [
    "print(\"Mémoire pour les quantiles de température : \", quantiles_temperatures_sous_ech.nbytes/1000000, \" Méga octets.\")\n",
    "print(\"Mémoire pour les températures : \", _temp_sous_ech.nbytes/1000000000, \"Giga octets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation de la méthode P2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, réalisons le calcul des quantiles avec l'algorithme P2 en stockant les données du tableau afin de vérifier si c'est plus rapide ou non que la fonction `np.quantile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P2(p, data):\n",
    "    \"\"\"\n",
    "    Input : p [float] - nombre du quantile que l'on veut estimer (ex: médiane -> p=0.5)\n",
    "            data [2D float np.array] - jeu de données désordonné\n",
    "\n",
    "    Output : [float] estimation du p-ième quantile\n",
    "    \"\"\"\n",
    "\n",
    "    # INITIALISATION\n",
    "\n",
    "    markers = np.sort(data[:5])\n",
    "    markers_index = np.arange(5)\n",
    "    desired_index = np.array([1., 1+2*p, 1+4*p, 3+2*p, 5])\n",
    "    increment = np.array([0, p/2, p, (1+p)/2, 1])\n",
    "\n",
    "    # ITERATION\n",
    "\n",
    "    for x in data[5:]:\n",
    "        # x est l'observable suivante (actuellement avec le tableau data mais à améliorer pour ne rien avoir à stocker)\n",
    "\n",
    "        # Déterminer l'indice k tel que marker[k] <= x < marker[k+1]\n",
    "        k = np.searchsorted(markers, x, side='right') - 1\n",
    "\n",
    "        if k == 0:\n",
    "            # Ajuster le minimum\n",
    "            markers[0] = x\n",
    "        \n",
    "        elif k == 4:\n",
    "            # Ajuster le maximum\n",
    "            markers[4] = x \n",
    "\n",
    "        # Incrémenter les positions des markers au-delà de x\n",
    "        markers_index[k+1:] += 1\n",
    "\n",
    "        # Incrémenter toutes les positions désirées\n",
    "        desired_index += increment \n",
    "\n",
    "        # Ajuster les markers centraux si nécessaire\n",
    "        for i in range(1,4):\n",
    "            d = desired_index[i] - markers_index[i]\n",
    "\n",
    "            if ( (d >= 1) and (markers_index[i+1] - markers_index[i] > 1) ) or ( (d <= -1) and (markers_index[i-1] - markers_index[i] < -1) ):\n",
    "\n",
    "                d = int(np.sign(d))\n",
    "\n",
    "                # P2 formula\n",
    "                a = d / (markers_index[i+1] - markers_index[i-1])\n",
    "                b = (markers_index[i] - markers_index[i-1] + d) * (markers[i+1] - markers[i]) / (markers_index[i+1] - markers_index[i])\n",
    "                c = (markers_index[i+1] - markers_index[i] - d) * (markers[i] - markers[i-1]) / (markers_index[i] - markers_index[i-1])\n",
    "                q = markers_index[i] + a * (b + c)\n",
    "\n",
    "                # Ordonnement des markers\n",
    "                if markers[i-1] <= q <= markers[i+1]:\n",
    "                    markers[i] = q\n",
    "                \n",
    "                else:\n",
    "                    # Linear formula\n",
    "                    markers[i] += d * (markers[i+d] - markers[i]) / (markers_index[i+d] - markers_index[i])\n",
    "\n",
    "                markers_index[i] += d \n",
    "        \n",
    "    # RENVOYER L'APPEOXIMATION DU p-IEME QUANTILE\n",
    "\n",
    "    return markers[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantiles_sous_ech_P2 = np.zeros(quantiles_temperatures.shape)\n",
    "# nb_cells_sous_ech = nb_cells // n_sous_ech_space\n",
    "# nb_times_sous_ech = _temp.shape[-1] // n_sous_ech_time\n",
    "\n",
    "# for i,q in enumerate(quantile):\n",
    "#     for j in range(nb_chain):\n",
    "#         for c in range(nb_cells_sous_ech):\n",
    "#             for t in range(nb_times_sous_ech):\n",
    "#                 tab = _temp_sous_ech\n",
    "#                 quantiles_sous_ech_P2[i,j,c,t] = P2(q, _temp_sous_ech[:,j,c,t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est très lent, je déconseille d'attendre la fin de l'exécution. On rejette donc immédiatement l'éventualité de remplacer `np.quantile` par P2, bien que ce dernier algorithme ait l'avantage de fonctionner même sans stocker les données dans un tableau. Nous utiliserons uniquement le sous-échantillonnage dans la suite et essayerons deux protocoles dans le but de respecter la contrainte de 2Go de mémoire vive imposée par le cahier des charges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les solutions envisagées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ecrire dans un fichier pendant la MCMC pour ne pas encombrer la mémoire de plus de 5Go de données\n",
    "* Ne pas écrire dans un fichier mais retrouver les distributions de température uniquement avec les quantiles obtenus avec le tableau sous-échantillonné, calculé pendant MCMC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
