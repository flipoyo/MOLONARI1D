{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyheatmy import *\n",
    "from typing import List, Sequence, Union\n",
    "from numbers import Number\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from layers import AllPriors,LayerPriors, Layer, getListParameters\n",
    "PARAM_LIST = (\"moinslog10IntrinK\", \"n\", \"lambda_s\", \"rhos_cs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "capteur_riviere = pd.read_csv(\"../data/Point034_processed/processed_pressures.csv\", sep = ',', names = ['dates', 'tension', 'temperature_riviere'], skiprows=1)\n",
    "capteur_ZH = pd.read_csv(\"../data/Point034_processed/processed_temperatures.csv\", sep = ',', names = ['dates', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_40'], skiprows=1)\n",
    "etalonage_capteur_riv = pd.read_csv(\"../configuration/pressure_sensors/P508.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDates(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Convert dates from a list of strings by testing several different input formats\n",
    "    Try all date formats already encountered in data points\n",
    "    If none of them is OK, try the generic way (None)\n",
    "    If the generic way doesn't work, this method fails\n",
    "    (in that case, you should add the new format to the list)\n",
    "    \n",
    "    This function works directly on the giving Pandas dataframe (in place)\n",
    "    This function assumes that the first column of the given Pandas dataframe\n",
    "    contains the dates as characters string type\n",
    "    \n",
    "    For datetime conversion performance, see:\n",
    "    See https://stackoverflow.com/questions/40881876/python-pandas-convert-datetime-to-timestamp-effectively-through-dt-accessor\n",
    "    \"\"\"\n",
    "    formats = (\"%m/%d/%y %H:%M:%S\", \"%m/%d/%y %I:%M:%S %p\",\n",
    "               \"%d/%m/%y %H:%M\",    \"%d/%m/%y %I:%M %p\",\n",
    "               \"%m/%d/%Y %H:%M:%S\", \"%m/%d/%Y %I:%M:%S %p\", \n",
    "               \"%d/%m/%Y %H:%M\",    \"%d/%m/%Y %I:%M %p\",\n",
    "               \"%y/%m/%d %H:%M:%S\", \"%y/%m/%d %I:%M:%S %p\", \n",
    "               \"%y/%m/%d %H:%M\",    \"%y/%m/%d %I:%M %p\",\n",
    "               \"%Y/%m/%d %H:%M:%S\", \"%Y/%m/%d %I:%M:%S %p\", \n",
    "               \"%Y/%m/%d %H:%M\",    \"%Y/%m/%d %I:%M %p\",\n",
    "               None)\n",
    "    times = df[df.columns[0]]\n",
    "    for f in formats:\n",
    "        try:\n",
    "            # Convert strings to datetime objects\n",
    "            new_times = pd.to_datetime(times, format=f)\n",
    "            # Convert datetime series to numpy array of integers (timestamps)\n",
    "            new_ts = new_times.values.astype(np.int64)\n",
    "            # If times are not ordered, this is not the appropriate format\n",
    "            test = np.sort(new_ts) - new_ts\n",
    "            if np.sum(abs(test)) != 0 :\n",
    "                #print(\"Order is not the same\")\n",
    "                raise ValueError()\n",
    "            # Else, the conversion is a success\n",
    "            #print(\"Found format \", f)\n",
    "            df[df.columns[0]] = new_times\n",
    "            return\n",
    "        \n",
    "        except ValueError:\n",
    "            #print(\"Format \", f, \" not valid\")\n",
    "            continue\n",
    "    \n",
    "    # None of the known format are valid\n",
    "    raise ValueError(\"Cannot convert dates: No known formats match your data!\")\n",
    "\n",
    "convertDates(capteur_riviere)\n",
    "convertDates(capteur_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# conversion des mesures de pression\n",
    "intercept = float(etalonage_capteur_riv['P508'][2])\n",
    "a = float(etalonage_capteur_riv['P508'][3])\n",
    "b = float(etalonage_capteur_riv['P508'][4])\n",
    "capteur_riviere['dH'] = (capteur_riviere['tension'].astype(float)-intercept-capteur_riviere['temperature_riviere'].astype(float)*b)/a\n",
    "\n",
    "# conversion mesures de tempétratures\n",
    "capteur_riviere['temperature_riviere'] = capteur_riviere['temperature_riviere'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_10'] = capteur_ZH['temperature_10'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_20'] = capteur_ZH['temperature_20'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_30'] = capteur_ZH['temperature_30'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_40'] = capteur_ZH['temperature_40'] + ZERO_CELSIUS\n",
    "\n",
    "# définition des attributs de colonnes\n",
    "dH_measures = list(zip(capteur_riviere['dates'],list(zip(capteur_riviere['dH'], capteur_riviere['temperature_riviere']))))\n",
    "T_measures = list(zip(capteur_ZH['dates'], capteur_ZH[['temperature_10', 'temperature_20', 'temperature_30', 'temperature_40']].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {\n",
    "\t\"river_bed\": 1., \n",
    "    \"depth_sensors\": [.1, .2, .3, .4],\n",
    "\t\"offset\": .0,\n",
    "    \"dH_measures\": dH_measures,\n",
    "\t\"T_measures\": T_measures,\n",
    "    \"sigma_meas_P\": None,\n",
    "    \"sigma_meas_T\": None,\n",
    "    \"inter_mode\": 'lagrange'\n",
    "}\n",
    "\n",
    "col = Column.from_dict(col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Param(\n",
    "    moinslog10IntrinK = 4,\n",
    "    n = .1,\n",
    "    lambda_s = 2,\n",
    "    rhos_cs = 4e6\n",
    ")\n",
    "\n",
    "params_tuple = (4, .1, 2, 4e6)\n",
    "\n",
    "assert params == params_tuple\n",
    "\n",
    "col.compute_solve_transi(params, nb_cells=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors_couche_1 = {\n",
    "    \"moinslog10IntrinK\": ((1, 10), .01), # (intervalle, sigma)\n",
    "    \"n\": ((.001, .25), .005),\n",
    "    \"lambda_s\": ((1, 10), .1),\n",
    "    \"rhos_cs\": ((1e6,1e7), 1e5),\n",
    "}\n",
    "\n",
    "priors_couche_2 = {\n",
    "    \"moinslog10IntrinK\": ((4, 9), .01), # (intervalle, sigma)\n",
    "    \"n\": ((.001, .25), .005),\n",
    "    \"lambda_s\": ((1, 10), .1),\n",
    "    \"rhos_cs\": ((1e6,1e7), 1e5),\n",
    "}\n",
    "\n",
    "priors_couche_3 = {\n",
    "    \"moinslog10IntrinK\": ((4, 9), .01), # (intervalle, sigma)\n",
    "    \"n\": ((.001, .25), .005),\n",
    "    \"lambda_s\": ((1, 10), .1),\n",
    "    \"rhos_cs\": ((1e6,1e7), 1e5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_priors = [\n",
    "    ['Couche 1', 0.4, priors_couche_1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_priors = [['Couche 1', 0.4, priors_couche_1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(layer):\n",
    "    name, prof, priors = layer\n",
    "    if isinstance(priors, dict):\n",
    "        return (\n",
    "            name,\n",
    "            prof,\n",
    "            [Prior(*args) for args in (priors[lbl] for lbl in PARAM_LIST)],\n",
    "        )\n",
    "    else:\n",
    "        return layer\n",
    "\n",
    "if not isinstance(all_priors, AllPriors):\n",
    "    all_priors = AllPriors([LayerPriors(*conv(layer)) for layer in all_priors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_chain = 10\n",
    "nb_iter = 1000\n",
    "nb_param = 4\n",
    "delta = 3\n",
    "ncr = 3\n",
    "c = 0.1\n",
    "c_star=1e-6\n",
    "nb_cells = 100\n",
    "#temp_ref = col._T_measures[:, :].T\n",
    "dz = col._real_z[-1] / nb_cells\n",
    "_z_solve = dz / 2 + np.array([k * dz for k in range(nb_cells)])\n",
    "ind_ref = [np.argmin(np.abs(z - _z_solve)) for z in col._real_z[1:-1]]\n",
    "temp_ref = col.get_temperatures_solve()[ind_ref]\n",
    "sigma2 = 1\n",
    "nb_layer = len(all_priors)\n",
    "col._states = list()\n",
    "\n",
    "ranges = np.empty((nb_layer, nb_param, 2))\n",
    "for l in range(nb_layer):\n",
    "    for p in range(nb_param):\n",
    "        ranges[l,p] = all_priors[l][p].range  \n",
    "\n",
    "\n",
    "def compute_energy(temp: np.array):\n",
    "    norm2 = np.nansum((temp - temp_ref) ** 2)\n",
    "    return 0.5 * norm2 / sigma2\n",
    "\n",
    "def compute_log_acceptance(actual_energy: float, prev_energy: float):\n",
    "    return prev_energy - actual_energy\n",
    "\n",
    "def convert_to_layer(name_layer, z_low, params): \n",
    "    return [Layer(name_layer[i], z_low[i], *params[i]) for i in range(nb_layer)]\n",
    "\n",
    "def check_range(x, ranges): \n",
    "    while np.sum(x < ranges[:,0]) + np.sum(x > ranges[:,1]) > 0:\n",
    "        x = (x < ranges[:,0]) * (ranges[:,1] - (ranges[:,0] - x)) + (x > ranges[:,1]) * (ranges[:,0] + (x - ranges[:,1])) + (x >= ranges[:,0]) * (x <= ranges[:,1]) * x\n",
    "    return x\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def gelman_rubin(nb_current_iter, nb_param, nb_layer, chains, threshold=1.1):\n",
    "    \"\"\"\n",
    "    Input : chains [3D np.array] - chaînes de Markov calculées en parallèle\n",
    "            threshold [float] - seuil de l'indicateur de Gelman-Rubin, légèrement supérieur à 1\n",
    "    \n",
    "    Output : [bool] - True si et seulement si la phase de burn-in est considérée finie\n",
    "    \"\"\"\n",
    "    R = np.zeros((nb_layer, nb_param))\n",
    "    for l in range(nb_layer):   \n",
    "        chains_layered = chains[:,:,l,:]\n",
    "        # Variances intra-chaînes des paramètres\n",
    "        Var_intra = np.var(chains_layered, axis=0)\n",
    "\n",
    "        # Moyenne des variances intra-chaîne\n",
    "        var_intra = np.mean(Var_intra, axis=0)\n",
    "\n",
    "        # Moyennes de chaque chaîne\n",
    "        means_chains = np.mean(chains_layered, axis=0)\n",
    "\n",
    "        # Variance entre les moyennes des chaînes, dite inter-chaînes\n",
    "        var_inter = np.var(means_chains, axis=0)\n",
    "\n",
    "        # Calcul de l'indicateur de Gelman-Rubin\n",
    "        for j in range(nb_param):\n",
    "            if np.isclose(var_intra[j], 0) :\n",
    "                R[l,j] = 2\n",
    "            else:\n",
    "                R[l,j] = np.sqrt( var_inter[j] / var_intra[j] * (nb_current_iter - 1) / nb_current_iter + 1) # Vérifier la formule\n",
    "\n",
    "    print(\"R = \", R)\n",
    "\n",
    "    # On considère que la phase de burn-in est terminée dès que R < threshold\n",
    "    return np.all(R < threshold)\n",
    "\n",
    "# initialisation\n",
    "X = np.array([np.array(all_priors.sample()) for _ in range(nb_chain)])\n",
    "X = np.array([np.array([X[c][l].params for l in range(nb_layer)]) for c in range(nb_chain)])\n",
    "_params = np.zeros((nb_iter + 1, nb_chain, nb_layer, nb_param))\n",
    "_params[0] = X\n",
    "_temp = np.zeros((nb_iter + 1, nb_chain, nb_cells, len(col._times)), np.float32)\n",
    "_energy = np.zeros((nb_iter + 1, nb_chain))\n",
    "temp_new = np.zeros((nb_cells, len(col._times)))\n",
    "energy_new = 0\n",
    "\n",
    "name_layer = [all_priors.sample()[i].name for i in range(nb_layer)]\n",
    "z_low = [all_priors.sample()[i].zLow for i in range(nb_layer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialisation des chaines\n",
    "for i in range(nb_chain): \n",
    "    col.compute_solve_transi(convert_to_layer(name_layer, z_low, X[i]), nb_cells, verbose = False)\n",
    "    _temp[0][i] = col.get_temperatures_solve()\n",
    "    _energy[0][i] = compute_energy(_temp[0][i][ind_ref, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_vec = np.arange(1,ncr+1)/ncr\n",
    "n_id = np.zeros((nb_layer, ncr))\n",
    "J = np.zeros((nb_layer, ncr))\n",
    "pcr = np.ones((nb_layer, ncr))/ncr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_burn_in_iter = 0 \n",
    "threshold = 1.1\n",
    "\n",
    "for i in range(nb_iter):\n",
    "    # Initialize arrays for new parameter values\n",
    "    x_new = np.zeros((nb_layer, nb_param))\n",
    "    X_new = np.zeros((nb_chain, nb_layer, nb_param))\n",
    "    std_X = np.std(X, axis=0)\n",
    "    \n",
    "    # Loop over chains\n",
    "    for j in range(nb_chain):\n",
    "        # Initialize arrays for new parameter values\n",
    "        dX = np.zeros((nb_layer,nb_param))\n",
    "        \n",
    "        # Loop over layers\n",
    "        for l in range(nb_layer):\n",
    "            # Select a crossover point\n",
    "            id = np.random.choice(ncr, p=pcr[l])\n",
    "            \n",
    "            # Generate random numbers\n",
    "            z = np.random.uniform(0, 1, nb_param)\n",
    "            A = (z <= cr_vec[id])\n",
    "            d_star = np.sum(A)\n",
    "            \n",
    "            # If no parameters are selected, select the smallest one\n",
    "            if d_star == 0:\n",
    "                A[np.argmin(z)] = True\n",
    "                d_star = 1\n",
    "            \n",
    "            # Generate random numbers\n",
    "            lambd = np.random.uniform(-c, c, d_star)\n",
    "            zeta = np.random.normal(0, c_star, d_star)\n",
    "            \n",
    "            # Select chains for difference vectors\n",
    "            choose = np.delete(np.arange(nb_chain), j)\n",
    "            a = np.random.choice(choose, delta, replace=False)\n",
    "            choose = np.delete(choose, np.where(np.isin(a, choose)))\n",
    "            b = np.random.choice(choose, delta, replace=False)\n",
    "            \n",
    "            # Compute difference vectors\n",
    "            gamma = 2.38 / np.sqrt(2 * d_star * delta)\n",
    "            dX[l][A] = zeta + (1 + lambd) * gamma * np.sum(X[a,l][:,A] - X[b,l][:,A], axis=0)\n",
    "            \n",
    "            # Compute new parameter values\n",
    "            x_new[l] = X[j,l] + dX[l]\n",
    "            x_new[l] = check_range(x_new[l], ranges[l])\n",
    "        \n",
    "        # Compute new temperature profile and energy\n",
    "        col.compute_solve_transi(convert_to_layer(name_layer, z_low, x_new), nb_cells, verbose=False)\n",
    "        temp_new = col.get_temperatures_solve()\n",
    "        energy_new = compute_energy(temp_new[ind_ref, :])\n",
    "        \n",
    "        # Compute acceptance probability\n",
    "        log_ratio_accept = compute_log_acceptance(energy_new, _energy[i][j])\n",
    "        \n",
    "        # Accept or reject new parameter values\n",
    "        if np.log(np.random.uniform(0, 1)) < log_ratio_accept:\n",
    "            X_new[j] = x_new\n",
    "            _temp[i+1][j] = temp_new\n",
    "            _energy[i+1][j] = energy_new\n",
    "        else:\n",
    "            dX = np.zeros((nb_layer, nb_param))\n",
    "            X_new[j] = X[j]\n",
    "            _temp[i+1][j] = _temp[i-1][j]\n",
    "            _energy[i+1][j] = _energy[i-1][j]\n",
    "        \n",
    "        # Update J and n_id\n",
    "        for l in range(nb_layer):\n",
    "            J[l,id] += np.sum((dX[l] / std_X[l])**2)\n",
    "            n_id[l,id] += 1\n",
    "    \n",
    "    # Update pcr\n",
    "    for l in range(nb_layer):\n",
    "        pcr[l] = J[l] / n_id[l]\n",
    "        pcr[l] = pcr[l] / np.sum(pcr[l])\n",
    "    \n",
    "    # Update parameter values\n",
    "    X = X_new\n",
    "    _params[i+1] = X_new\n",
    "    \n",
    "    # Check for convergence\n",
    "    if gelman_rubin(i+2, nb_param, nb_layer, _params[:i+2], threshold=threshold):\n",
    "        print(f\"Burn in finished after : {nb_burn_in_iter} iterations\")\n",
    "        break\n",
    "    nb_burn_in_iter += 1 \n",
    "    \n",
    "    \n",
    "# Burn in finished, parameters are now saved\n",
    "_params = np.zeros((nb_iter + 1, nb_chain, nb_layer, nb_param))\n",
    "_params[0] = X\n",
    "_temp = np.zeros((nb_iter + 1, nb_chain, nb_cells, len(col._times)), np.float32)\n",
    "_energy = np.zeros((nb_iter + 1, nb_chain))\n",
    "for i in range(nb_iter):\n",
    "    # Initialize arrays for new parameter values\n",
    "    x_new = np.zeros((nb_layer, nb_param))\n",
    "    X_new = np.zeros((nb_chain, nb_layer, nb_param))\n",
    "    std_X = np.std(X, axis=0)\n",
    "    \n",
    "    # Loop over chains\n",
    "    for j in range(nb_chain):\n",
    "        # Initialize arrays for new parameter values\n",
    "        dX = np.zeros((nb_layer,nb_param))\n",
    "        \n",
    "        # Loop over layers\n",
    "        for l in range(nb_layer):\n",
    "            # Select a crossover point\n",
    "            id = np.random.choice(ncr, p=pcr[l])\n",
    "            \n",
    "            # Generate random numbers\n",
    "            z = np.random.uniform(0, 1, nb_param)\n",
    "            A = (z <= cr_vec[id])\n",
    "            d_star = np.sum(A)\n",
    "            \n",
    "            # If no parameters are selected, select the smallest one\n",
    "            if d_star == 0:\n",
    "                A[np.argmin(z)] = True\n",
    "                d_star = 1\n",
    "            \n",
    "            # Generate random numbers\n",
    "            lambd = np.random.uniform(-c, c, d_star)\n",
    "            zeta = np.random.normal(0, c_star, d_star)\n",
    "            \n",
    "            # Select chains for difference vectors\n",
    "            choose = np.delete(np.arange(nb_chain), j)\n",
    "            a = np.random.choice(choose, delta, replace=False)\n",
    "            choose = np.delete(choose, np.where(np.isin(a, choose)))\n",
    "            b = np.random.choice(choose, delta, replace=False)\n",
    "            \n",
    "            # Compute difference vectors\n",
    "            gamma = 2.38 / np.sqrt(2 * d_star * delta)\n",
    "            dX[l][A] = zeta + (1 + lambd) * gamma * np.sum(X[a,l][:,A] - X[b,l][:,A], axis=0)\n",
    "            \n",
    "            # Compute new parameter values\n",
    "            x_new[l] = X[j,l] + dX[l]\n",
    "            x_new[l] = check_range(x_new[l], ranges[l])\n",
    "        \n",
    "        # Compute new temperature profile and energy\n",
    "        col.compute_solve_transi(convert_to_layer(name_layer, z_low, x_new), nb_cells, verbose=False)\n",
    "        temp_new = col.get_temperatures_solve()\n",
    "        energy_new = compute_energy(temp_new[ind_ref, :])\n",
    "        \n",
    "        # Compute acceptance probability\n",
    "        log_ratio_accept = compute_log_acceptance(energy_new, _energy[i][j])\n",
    "        \n",
    "        # Accept or reject new parameter values\n",
    "        if np.log(np.random.uniform(0, 1)) < log_ratio_accept:\n",
    "            X_new[j] = x_new\n",
    "            _temp[i+1][j] = temp_new\n",
    "            _energy[i+1][j] = energy_new\n",
    "        else:\n",
    "            dX = np.zeros((nb_layer, nb_param))\n",
    "            X_new[j] = X[j]\n",
    "            _temp[i+1][j] = _temp[i-1][j]\n",
    "            _energy[i+1][j] = _energy[i-1][j]\n",
    "        \n",
    "        # Update J and n_id\n",
    "        for l in range(nb_layer):\n",
    "            J[l,id] += np.sum((dX[l] / std_X[l])**2)\n",
    "            n_id[l,id] += 1\n",
    "            \n",
    "    # Update parameter values\n",
    "    X = X_new\n",
    "    _params[i+1] = X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dream_mcmc_without_sigma2(\n",
    "        self,\n",
    "        nb_iter: int,\n",
    "        all_priors: Union[\n",
    "            AllPriors,\n",
    "            Sequence[\n",
    "                Union[\n",
    "                    LayerPriors,\n",
    "                    Sequence[Union[str, float, Sequence[Union[Prior, dict]]]],\n",
    "                ]\n",
    "            ],\n",
    "        ],\n",
    "        nb_cells: int,\n",
    "        nb_chain: int,\n",
    "        quantile: Union[float, Sequence[float]] = (0.05, 0.5, 0.95),\n",
    "        verbose=True,\n",
    "        sigma2=1.0,\n",
    "        delta=3,\n",
    "        ncr=3,\n",
    "        c=0.1,\n",
    "        c_star=1e-6,\n",
    "    ):\n",
    "        if isinstance(quantile, Number):\n",
    "            quantile = [quantile]\n",
    "\n",
    "        if not isinstance(all_priors, AllPriors):\n",
    "            all_priors = AllPriors([LayerPriors(*conv(layer)) for layer in all_priors])\n",
    "\n",
    "        dz = self._real_z[-1] / nb_cells\n",
    "        _z_solve = dz / 2 + np.array([k * dz for k in range(nb_cells)])\n",
    "        ind_ref = [np.argmin(np.abs(z - _z_solve)) for z in self._real_z[1:-1]]\n",
    "        temp_ref = self._T_measures[:, :].T\n",
    "        nb_layer = len(all_priors)\n",
    "        nb_param = 4\n",
    "\n",
    "        def compute_energy(temp: np.array):\n",
    "            norm2 = np.nansum((temp - temp_ref) ** 2)\n",
    "            return 0.5 * norm2 / sigma2\n",
    "\n",
    "        def compute_log_acceptance(actual_energy: float, prev_energy: float):\n",
    "            return prev_energy - actual_energy\n",
    "\n",
    "        def convert_to_layer(name_layer, z_low, params):\n",
    "            return [Layer(name_layer[i], z_low[i], *params[i]) for i in range(nb_layer)]\n",
    "\n",
    "        def check_range(x, ranges):\n",
    "            while np.sum(x < ranges[:, 0]) + np.sum(x > ranges[:, 1]) > 0:\n",
    "                x = (\n",
    "                    (x < ranges[:, 0]) * (ranges[:, 1] - (ranges[:, 0] - x))\n",
    "                    + (x > ranges[:, 1]) * (ranges[:, 0] + (x - ranges[:, 1]))\n",
    "                    + (x >= ranges[:, 0]) * (x <= ranges[:, 1]) * x\n",
    "                )\n",
    "            return x\n",
    "        \n",
    "        def gelman_rubin(nb_current_iter, nb_param, nb_layer, chains, threshold=1.1):\n",
    "            \"\"\"\n",
    "            Input : chains [3D np.array] - chaînes de Markov calculées en parallèle\n",
    "                    threshold [float] - seuil de l'indicateur de Gelman-Rubin, légèrement supérieur à 1\n",
    "            \n",
    "            Output : [bool] - True si et seulement si la phase de burn-in est considérée finie\n",
    "            \"\"\"\n",
    "            R = np.zeros((nb_layer, nb_param))\n",
    "            for l in range(nb_layer):   \n",
    "                chains_layered = chains[:,:,l,:]\n",
    "                # Variances intra-chaînes des paramètres\n",
    "                Var_intra = np.var(chains_layered, axis=0)\n",
    "\n",
    "                # Moyenne des variances intra-chaîne\n",
    "                var_intra = np.mean(Var_intra, axis=0)\n",
    "\n",
    "                # Moyennes de chaque chaîne\n",
    "                means_chains = np.mean(chains_layered, axis=0)\n",
    "\n",
    "                # Variance entre les moyennes des chaînes, dite inter-chaînes\n",
    "                var_inter = np.var(means_chains, axis=0)\n",
    "\n",
    "                # Calcul de l'indicateur de Gelman-Rubin\n",
    "                for j in range(nb_param):\n",
    "                    if np.isclose(var_intra[j], 0) :\n",
    "                        R[l,j] = 2\n",
    "                    else:\n",
    "                        R[l,j] = np.sqrt( var_inter[j] / var_intra[j] * (nb_current_iter - 1) / nb_current_iter + 1) # Vérifier la formule\n",
    "\n",
    "            #print(\"R = \", R)\n",
    "\n",
    "            # On considère que la phase de burn-in est terminée dès que R < threshold\n",
    "            return np.all(R < threshold)\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"--- Compute Mcmc ---\",\n",
    "                \"Priors :\",\n",
    "                *(f\"    {prior}\" for prior in all_priors),\n",
    "                f\"Number of cells : {nb_cells}\",\n",
    "                f\"Number of iterations : {nb_iter}\",\n",
    "                f\"Number of chains : {nb_chain}\",\n",
    "                \"Launch Mcmc\",\n",
    "                sep=\"\\n\",\n",
    "            )\n",
    "\n",
    "        ranges = np.empty((nb_layer, nb_param, 2))\n",
    "        for l in range(nb_layer):\n",
    "            for p in range(nb_param):\n",
    "                ranges[l, p] = all_priors[l][p].range\n",
    "\n",
    "        # paramètres de stockage des résultats\n",
    "        self._states = list()\n",
    "        self._acceptance = np.zeros((nb_iter, nb_chain))\n",
    "        X = np.array([np.array(all_priors.sample()) for _ in range(nb_chain)])\n",
    "        X = np.array(\n",
    "            [\n",
    "                np.array([X[c][l].params for l in range(nb_layer)])\n",
    "                for c in range(nb_chain)\n",
    "            ]\n",
    "        )\n",
    "        _params = np.zeros((nb_iter + 1, nb_chain, nb_layer, nb_param))\n",
    "        _params[0] = X\n",
    "        _temp = np.zeros(\n",
    "            (nb_iter + 1, nb_chain, nb_cells, len(self._times)), np.float32\n",
    "        )\n",
    "        _energy = np.zeros((nb_iter + 1, nb_chain))\n",
    "        temp_new = np.zeros((nb_cells, len(self._times)))\n",
    "        energy_new = 0\n",
    "        name_layer = [all_priors.sample()[i].name for i in range(nb_layer)]\n",
    "        z_low = [all_priors.sample()[i].zLow for i in range(nb_layer)]\n",
    "\n",
    "        # paramètres de DREAM\n",
    "        cr_vec = np.arange(1, ncr + 1) / ncr\n",
    "        n_id = np.zeros((nb_layer, ncr))\n",
    "        J = np.zeros((nb_layer, ncr))\n",
    "        pcr = np.ones((nb_layer, ncr)) / ncr\n",
    "        nb_accepted = 0  # nombre de propositions acceptées\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Burn in phase\")\n",
    "        for i in range(nb_iter):\n",
    "            # Initialisation pour les nouveaux paramètres\n",
    "            x_new = np.zeros((nb_layer, nb_param))\n",
    "            X_new = np.zeros((nb_chain, nb_layer, nb_param))\n",
    "            std_X = np.std(X, axis=0)\n",
    "            for j in range(nb_chain):\n",
    "                dX = np.zeros((nb_layer, nb_param))\n",
    "                # Loop over layers\n",
    "                for l in range(nb_layer):\n",
    "                    # Select a crossover point\n",
    "                    id = np.random.choice(ncr, p=pcr[l])\n",
    "\n",
    "                    # Generate random numbers\n",
    "                    z = np.random.uniform(0, 1, nb_param)\n",
    "                    A = z <= cr_vec[id]\n",
    "                    d_star = np.sum(A)\n",
    "\n",
    "                    # If no parameters are selected, select the smallest one\n",
    "                    if d_star == 0:\n",
    "                        A[np.argmin(z)] = True\n",
    "                        d_star = 1\n",
    "\n",
    "                    # Generate random numbers\n",
    "                    lambd = np.random.uniform(-c, c, d_star)\n",
    "                    zeta = np.random.normal(0, c_star, d_star)\n",
    "\n",
    "                    # Select chains for difference vectors\n",
    "                    choose = np.delete(np.arange(nb_chain), j)\n",
    "                    a = np.random.choice(choose, delta, replace=False)\n",
    "                    choose = np.delete(choose, np.where(np.isin(a, choose)))\n",
    "                    b = np.random.choice(choose, delta, replace=False)\n",
    "\n",
    "                    # Compute difference vectors\n",
    "                    gamma = 2.38 / np.sqrt(2 * d_star * delta)\n",
    "                    dX[l][A] = zeta + (1 + lambd) * gamma * np.sum(\n",
    "                        X[a, l][:, A] - X[b, l][:, A], axis=0\n",
    "                    )\n",
    "\n",
    "                    # Compute new parameter values\n",
    "                    x_new[l] = X[j, l] + dX[l]\n",
    "                    x_new[l] = check_range(x_new[l], ranges[l])\n",
    "\n",
    "                # Compute new temperature profile and energy\n",
    "                self.compute_solve_transi(\n",
    "                    convert_to_layer(name_layer, z_low, x_new), nb_cells, verbose=False\n",
    "                )\n",
    "                temp_new = self.get_temperatures_solve()\n",
    "                energy_new = compute_energy(temp_new[ind_ref, :])\n",
    "\n",
    "                # Compute acceptance probability\n",
    "                log_ratio_accept = compute_log_acceptance(energy_new, _energy[i][j])\n",
    "\n",
    "                # Accept of reject new parameter values\n",
    "                if np.log(np.random.uniform(0, 1)) < log_ratio_accept:\n",
    "                    X_new[j] = x_new\n",
    "                    _temp[i + 1][j] = temp_new\n",
    "                    _energy[i + 1][j] = energy_new\n",
    "                else:\n",
    "                    dX = np.zeros((nb_layer, nb_param))\n",
    "                    X_new[j] = X[j]\n",
    "                    _temp[i + 1][j] = _temp[i - 1][j]\n",
    "\n",
    "                # Update J and n_id\n",
    "                for l in range(nb_layer):\n",
    "                    J[l, id] += np.sum((dX[l] / std_X[l]) ** 2)\n",
    "                    n_id[l, id] += 1\n",
    "            # Update pcr\n",
    "            for l in range(nb_layer):\n",
    "                pcr[l] = J[l] / n_id[l]\n",
    "                pcr[l] = pcr[l] / np.sum(pcr[l])\n",
    "\n",
    "            # Update parameters values\n",
    "            X = X_new\n",
    "            _params[i + 1] = X_new\n",
    "            \n",
    "            # Check for convergence\n",
    "            \"\"\"\n",
    "            Implémenter Gelman Rubin\n",
    "            _params : (nombre d'itération + 1, nombre de chaines, nombre de couche, nombre de paramètres)\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_iter, nb_chain, nb_layer, nb_param = _params.shape\n",
    "_params_without_chains = _params.reshape(nb_iter * nb_chain, nb_layer, nb_param)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(f\"Threshold = {threshold}        Burn-in over after {nb_burn_in_iter} iterations\")\n",
    "plt.axis('off')\n",
    "dico = {0 : \"$-log(K)$\", 1 : \"$\\lambda_s$\", 2 : \"$n$\", 3 : \"$rho * C$\"}\n",
    "for k in range(nb_param):\n",
    "    plt.subplot(2, 2, k+1)\n",
    "    plt.hist(_params_without_chains[:,0,k], bins = 100, label=f\"{dico[k]}\")\n",
    "    plt.legend();\n",
    "plt.savefig(f\"../images/threshold_{int(threshold*100)}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul des quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà la façon dont sont calculés les quantiles de température (idem pour le flow) dans le projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile = np.array([0.05, 0.5, 0.95])\n",
    "quantiles_temperatures = np.quantile(_temp, quantile, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le calcul est gourmand en temps de calcul et nécessite de stocker un tableau `quantiles_temps` et un tableau `temp` dont les tailles sont indiquées ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions de quantiles_temperatures : \", quantiles_temperatures.shape, \" (nb_quantiles, nb_chain, n_cells, n_temperatures)\")\n",
    "print(\"Dimensions de quantiles_temperatures : \", _temp.shape, \" (nb_iter, nb_chain, n_cells, n_temperatures)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces deux tableaux représentent un encombrement mémoire important qui dépasse le seuil fixé par le cahier des charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mémoire pour les quantiles de température : \", quantiles_temperatures.nbytes/1000000, \" Méga octets.\")\n",
    "print(\"Mémoire pour les températures : \", _temp.nbytes/1000000000, \"Giga octets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour réduire cet encombrement mémoire, on peut intuitivement supposer que les profils de température ne varient pas énormément entre deux pas de temps consécutifs. On peut donc réaliser un sous-échantillonnage sur les pas de temps afin de calculer les quantiles. De même, on peut réaliser un sous-échantillonnage spatial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sous_ech_temp = 2 # 1 mesure considérée par demi-heure\n",
    "n_sous_ech_space = 4 # 1 mesure considérée tous les 2 cm\n",
    "\n",
    "_temp_sous_ech = _temp[:,:,::n_sous_ech_space,::n_sous_ech_temp]\n",
    "quantiles_temperatures_sous_ech = np.quantile(_temp_sous_ech, quantile, axis=0)\n",
    "\n",
    "np.allclose(quantiles_temperatures_sous_ech,  quantiles_temperatures[:, :, ::n_sous_ech_space, ::n_sous_ech_temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les quantiles sont calculés sur chaque case $(chaine, cellule, temps)$ en utilisant les valeurs obtenues avec les itérations, il est donc normal que ces deux calculs conduisent aux mêmes valeurs de quantiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Déterminons alors le nouvel encombrement mémoire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mémoire pour les quantiles de température : \", quantiles_temperatures_sous_ech.nbytes/1000000, \" Méga octets.\")\n",
    "print(\"Mémoire pour les températures : \", _temp_sous_ech.nbytes/1000000000, \"Giga octets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation de la méthode P2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, réalisons le calcul des quantiles avec l'algorithme P2 en stockant les données du tableau afin de vérifier si c'est plus rapide ou non que la fonction `np.quantile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P2(p, data):\n",
    "    \"\"\"\n",
    "    Input : p [float] - nombre du quantile que l'on veut estimer (ex: médiane -> p=0.5)\n",
    "            data [2D float np.array] - jeu de données désordonné\n",
    "\n",
    "    Output : [float] estimation du p-ième quantile\n",
    "    \"\"\"\n",
    "\n",
    "    # INITIALISATION\n",
    "\n",
    "    markers = np.sort(data[:5])\n",
    "    markers_index = np.arange(5)\n",
    "    desired_index = np.array([1., 1+2*p, 1+4*p, 3+2*p, 5])\n",
    "    increment = np.array([0, p/2, p, (1+p)/2, 1])\n",
    "\n",
    "    # ITERATION\n",
    "\n",
    "    for x in data[5:]:\n",
    "        # x est l'observable suivante (actuellement avec le tableau data mais à améliorer pour ne rien avoir à stocker)\n",
    "\n",
    "        # Déterminer l'indice k tel que marker[k] <= x < marker[k+1]\n",
    "        k = np.searchsorted(markers, x, side='right') - 1\n",
    "\n",
    "        if k == 0:\n",
    "            # Ajuster le minimum\n",
    "            markers[0] = x\n",
    "        \n",
    "        elif k == 4:\n",
    "            # Ajuster le maximum\n",
    "            markers[4] = x \n",
    "\n",
    "        # Incrémenter les positions des markers au-delà de x\n",
    "        markers_index[k+1:] += 1\n",
    "\n",
    "        # Incrémenter toutes les positions désirées\n",
    "        desired_index += increment \n",
    "\n",
    "        # Ajuster les markers centraux si nécessaire\n",
    "        for i in range(1,4):\n",
    "            d = desired_index[i] - markers_index[i]\n",
    "\n",
    "            if ( (d >= 1) and (markers_index[i+1] - markers_index[i] > 1) ) or ( (d <= -1) and (markers_index[i-1] - markers_index[i] < -1) ):\n",
    "\n",
    "                d = int(np.sign(d))\n",
    "\n",
    "                # P2 formula\n",
    "                a = d / (markers_index[i+1] - markers_index[i-1])\n",
    "                b = (markers_index[i] - markers_index[i-1] + d) * (markers[i+1] - markers[i]) / (markers_index[i+1] - markers_index[i])\n",
    "                c = (markers_index[i+1] - markers_index[i] - d) * (markers[i] - markers[i-1]) / (markers_index[i] - markers_index[i-1])\n",
    "                q = markers_index[i] + a * (b + c)\n",
    "\n",
    "                # Ordonnement des markers\n",
    "                if markers[i-1] <= q <= markers[i+1]:\n",
    "                    markers[i] = q\n",
    "                \n",
    "                else:\n",
    "                    # Linear formula\n",
    "                    markers[i] += d * (markers[i+d] - markers[i]) / (markers_index[i+d] - markers_index[i])\n",
    "\n",
    "                markers_index[i] += d \n",
    "        \n",
    "    # RENVOYER L'APPEOXIMATION DU p-IEME QUANTILE\n",
    "\n",
    "    return markers[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantiles_sous_ech_P2 = np.zeros(quantiles_temperatures.shape)\n",
    "# nb_cells_sous_ech = nb_cells // n_sous_ech_space\n",
    "# nb_times_sous_ech = _temp.shape[-1] // n_sous_ech_temp\n",
    "\n",
    "# for i,q in enumerate(quantile):\n",
    "#     for j in range(nb_chain):\n",
    "#         for c in range(nb_cells_sous_ech):\n",
    "#             for t in range(nb_times_sous_ech):\n",
    "#                 tab = _temp_sous_ech\n",
    "#                 quantiles_sous_ech_P2[i,j,c,t] = P2(q, _temp_sous_ech[:,j,c,t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est très lent, je déconseille d'attendre la fin de l'exécution. On rejette donc immédiatement l'éventualité de remplacer `np.quantile` par P2, bien que ce dernier algorithme ait l'avantage de fonctionner même sans stocker les données dans un tableau. Nous utiliserons uniquement le sous-échantillonnage dans la suite et essayerons deux protocoles dans le but de respecter la contrainte de 2Go de mémoire vive imposée par le cahier des charges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les solutions envisagées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ecrire dans un fichier pendant la MCMC pour ne pas encombrer la mémoire de plus de 5Go de données\n",
    "* Ne pas écrire dans un fichier mais retrouver les distributions de température uniquement avec les quantiles obtenus avec le tableau sous-échantillonné, calculé pendant MCMC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyheatmy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
