{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating synthetic data sets of a river bed column forced by monoperiodic river and aquifer temperature signals\n",
    "\n",
    "2024 developped by the student group from ``demo_genData.ipynb`` created by Nicolas Flipo during MOLONARI 2024 and ``demo_Pyheatmy.ipynb``.\n",
    "\n",
    "The object of this demo is to test the validity of our MCMC inversion.\n",
    "\n",
    "In order to do so, we first generate a virtual point and its data thanks to ``demo_genData.ipynb`` and then inverse those data to find the parameters of the point. We can then see if we find back the parameters we used to generate the virtual point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyheatmy import *\n",
    "import pandas as pd\n",
    "\n",
    "NBITER = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération et traitement d'un jeu de données virtuelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On exécute le notebook ``demo_genData.ipynb`` pour générer un jeu de données dont on connaîtra les caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "path_demoGenData = \"demo_genData.ipynb\"\n",
    "\n",
    "# Fonction pour exécuter un notebook\n",
    "def run_notebook(notebook_path):\n",
    "    # Charger le notebook\n",
    "    with open(notebook_path) as f:\n",
    "        notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "    # Configurer l'ExecutePreprocessor pour exécuter toutes les cellules\n",
    "    ep = ExecutePreprocessor(timeout=600, kernel_name='python3')\n",
    "\n",
    "    # Exécuter le notebook\n",
    "    try:\n",
    "        ep.preprocess(notebook, {'metadata': {'path': './'}})\n",
    "        print(\"Notebook exécuté avec succès.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'exécution du notebook : {e}\")\n",
    "\n",
    "# Fonction pour importer les valeurs des cellules de code d'un notebook dans le contexte global\n",
    "def import_notebook_values(notebook_path):\n",
    "    # Charger le notebook\n",
    "    with open(notebook_path) as f:\n",
    "        notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "    # Créer un dictionnaire pour contenir les variables globales du notebook\n",
    "    notebook_globals = {}\n",
    "\n",
    "    try:\n",
    "        # Exécuter chaque cellule de code\n",
    "        for cell in notebook.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                exec(cell.source, notebook_globals)\n",
    "                \n",
    "        # Maintenant, importer les variables du notebook dans l'espace global\n",
    "        globals().update(notebook_globals)  # Met à jour l'espace global avec les variables du notebook\n",
    "        print(\"Les valeurs du notebook sont maintenant accessibles.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'exécution du notebook : {e}\")\n",
    "\n",
    "run_notebook(path_demoGenData)\n",
    "print(\"\")\n",
    "print(\"Affichage temporaire\")\n",
    "print(\"\")\n",
    "import_notebook_values(path_demoGenData)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On extrait ensuite et traite les données générées par le notebook, de la même façon qu'elles sont traitées dans ``demo_Pyheatmy.ipynb``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the folder path\n",
    "folder = col._dir_print + '/VirtualPoint'\n",
    "\n",
    "# read the data\n",
    "capteur_riviere = pd.read_csv(folder + \"/VirtualPoint_P_measures.csv\", sep = ',', names = ['dates', 'tension', 'temperature_riviere'], skiprows=1)\n",
    "capteur_ZH = pd.read_csv(folder + \"/VirtualPoint_T_measures.csv\", sep = ',', names = ['dates', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_40'], skiprows=1)\n",
    "etalonage_capteur_riv = pd.read_csv(\"./configuration/pressure_sensors/P508.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit une fonction pour convertir les dates des dataframe, cela peut éviter certains problèmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDates(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Convert dates from a list of strings by testing several different input formats\n",
    "    Try all date formats already encountered in data points\n",
    "    If none of them is OK, try the generic way (None)\n",
    "    If the generic way doesn't work, this method fails\n",
    "    (in that case, you should add the new format to the list)\n",
    "    \n",
    "    This function works directly on the giving Pandas dataframe (in place)\n",
    "    This function assumes that the first column of the given Pandas dataframe\n",
    "    contains the dates as characters string type\n",
    "    \n",
    "    For datetime conversion performance, see:\n",
    "    See https://stackoverflow.com/questions/40881876/python-pandas-convert-datetime-to-timestamp-effectively-through-dt-accessor\n",
    "    \"\"\"\n",
    "    formats = (\"%m/%d/%y %H:%M:%S\", \"%m/%d/%y %I:%M:%S %p\",\n",
    "               \"%d/%m/%y %H:%M\",    \"%d/%m/%y %I:%M %p\",\n",
    "               \"%m/%d/%Y %H:%M:%S\", \"%m/%d/%Y %I:%M:%S %p\", \n",
    "               \"%d/%m/%Y %H:%M\",    \"%d/%m/%Y %I:%M %p\",\n",
    "               \"%y/%m/%d %H:%M:%S\", \"%y/%m/%d %I:%M:%S %p\", \n",
    "               \"%y/%m/%d %H:%M\",    \"%y/%m/%d %I:%M %p\",\n",
    "               \"%Y/%m/%d %H:%M:%S\", \"%Y/%m/%d %I:%M:%S %p\", \n",
    "               \"%Y/%m/%d %H:%M\",    \"%Y/%m/%d %I:%M %p\",\n",
    "               None)\n",
    "    times = df[df.columns[0]]\n",
    "    for f in formats:\n",
    "        try:\n",
    "            # Convert strings to datetime objects\n",
    "            new_times = pd.to_datetime(times, format=f)\n",
    "            # Convert datetime series to numpy array of integers (timestamps)\n",
    "            new_ts = new_times.values.astype(np.int64)\n",
    "            # If times are not ordered, this is not the appropriate format\n",
    "            test = np.sort(new_ts) - new_ts\n",
    "            if np.sum(abs(test)) != 0 :\n",
    "                #print(\"Order is not the same\")\n",
    "                raise ValueError()\n",
    "            # Else, the conversion is a success\n",
    "            #print(\"Found format \", f)\n",
    "            df[df.columns[0]] = new_times\n",
    "            return\n",
    "        \n",
    "        except ValueError:\n",
    "            #print(\"Format \", f, \" not valid\")\n",
    "            continue\n",
    "    \n",
    "    # None of the known format are valid\n",
    "    raise ValueError(\"Cannot convert dates: No known formats match your data!\")\n",
    "\n",
    "convertDates(capteur_riviere)\n",
    "convertDates(capteur_ZH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit les objets ``dH_measures`` et ``T_measures``, nécessaires à la création d'un objet ``Column``, qui réalisera les calculs :\n",
    "- ``dH_measures`` contient les dates des mesures, les mesures de différence de charge, et les températures de la rivière.\n",
    "- ``T_measures`` contient les dates des mesures, et les températures mesurées par les 4 capteurs de la tige."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# conversion des mesures de pression\n",
    "intercept = float(etalonage_capteur_riv['P508'][2])\n",
    "a = float(etalonage_capteur_riv['P508'][3])\n",
    "b = float(etalonage_capteur_riv['P508'][4])\n",
    "capteur_riviere['dH'] = (capteur_riviere['tension'].astype(float)-intercept-capteur_riviere['temperature_riviere'].astype(float)*b)/a\n",
    "\n",
    "# conversion mesures de tempétratures\n",
    "capteur_riviere['temperature_riviere'] = capteur_riviere['temperature_riviere'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_10'] = capteur_ZH['temperature_10'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_20'] = capteur_ZH['temperature_20'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_30'] = capteur_ZH['temperature_30'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_40'] = capteur_ZH['temperature_40'] + ZERO_CELSIUS\n",
    "\n",
    "# définition des attributs de colonnes\n",
    "dH_measures = list(zip(capteur_riviere['dates'],list(zip(capteur_riviere['dH'], capteur_riviere['temperature_riviere']))))\n",
    "T_measures = list(zip(capteur_ZH['dates'], capteur_ZH[['temperature_10', 'temperature_20', 'temperature_30', 'temperature_40']].to_numpy()))\n",
    "\n",
    "print(f\"dH : {dH_measures}\")\n",
    "print(f\"Tshaft : {T_measures}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit maintenant l'objet ``Column`` à partir d'un dictionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zbottom = 0.4\n",
    "\n",
    "col_dict = {\n",
    "\t\"river_bed\": 1., \n",
    "    \"depth_sensors\": [.1, .2, .3, Zbottom],\n",
    "\t\"offset\": .0,\n",
    "    \"dH_measures\": dH_measures,\n",
    "\t\"T_measures\": T_measures,\n",
    "    \"sigma_meas_P\": None,\n",
    "    \"sigma_meas_T\": None,\n",
    "    \"inter_mode\": 'lagrange'\n",
    "}\n",
    "\n",
    "col = Column.from_dict(col_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion des données générées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant inverser les données générées pour obtenir les différentes caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBITERMCMC = 20\n",
    "\n",
    "priors = {\n",
    "    \"Prior_IntrinK\": ((1e-14, 1e-8), 5e-10), # (intervalle, sigma)\n",
    "    \"Prior_n\": ((.01, .25), .0125),\n",
    "    \"Prior_lambda_s\": ((1, 10), .5),\n",
    "    \"Prior_rhos_cs\": ((1e6,1e7), 5e5),\n",
    "    \"Prior_q_s\": ((-1e-6,1e-6), 1e-12),\n",
    "}\n",
    "\n",
    "Layer_homogenous = {\n",
    "    \"name\": \"Couche en sable\",\n",
    "    \"zLow\": Zbottom,\n",
    "    \"IntrinK\":1e-11,\n",
    "    \"n\": 0.1,\n",
    "    \"lambda_s\": 2,\n",
    "    \"rhos_cs\": 4e6,\n",
    "    \"q_s\": -1e-8,\n",
    "}\n",
    "\n",
    "Layer_homogenous = Layer.from_dict(Layer_homogenous)\n",
    "\n",
    "# On crée une couche de référence pour la comparaison plus bas\n",
    "reference_params_dict = {\n",
    "    \"name\": \"Couche en sable\",\n",
    "    \"zLow\": Zbottom,\n",
    "    \"IntrinK\":1e-11,\n",
    "    \"n\": 0.1,\n",
    "    \"lambda_s\": 2,\n",
    "    \"rhos_cs\": 4e6,\n",
    "    \"q_s\": -1e-8,\n",
    "}\n",
    "\n",
    "layer_for_simulation = Layer.from_dict(reference_params_dict)\n",
    "\n",
    "col.set_layers(Layer_homogenous)\n",
    "Layer_homogenous.set_priors_from_dict(priors)\n",
    "print(Layer_homogenous.Prior_list)\n",
    "\n",
    "\n",
    "col.all_layers\n",
    "\n",
    "col.compute_mcmc(\n",
    "    nb_iter = NBITERMCMC,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "bestLayers = col.get_best_layers()\n",
    "\n",
    "col.plot_all_param_pdf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des paramètres réels et de ceux inversés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut à présent comparer les données inversées et celles orignales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- ÉTAPE 1 : ACTION (inchangée) ---\n",
    "col.get_best_layers()\n",
    "\n",
    "# --- ÉTAPE 2 : RÉCUPÉRATION (inchangée) ---\n",
    "inverted_params = col.get_list_current_params()[0]\n",
    "\n",
    "# --- ÉTAPE 3 : COMPARAISON (corrigée) ---\n",
    "# On utilise maintenant le dictionnaire de référence pour les \"vraies\" valeurs.\n",
    "data = {\n",
    "    'Paramètre': PARAM_LIST,\n",
    "    'Valeur de Référence': [\n",
    "        reference_params_dict['IntrinK'],\n",
    "        reference_params_dict['n'],\n",
    "        reference_params_dict['lambda_s'],\n",
    "        reference_params_dict['rhos_cs'],\n",
    "        reference_params_dict['q_s']\n",
    "    ],\n",
    "    'Valeur Inversée (MCMC)': [\n",
    "        inverted_params.IntrinK,\n",
    "        inverted_params.n,\n",
    "        inverted_params.lambda_s,\n",
    "        inverted_params.rhos_cs,\n",
    "        inverted_params.q_s\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Créer et afficher le tableau de comparaison\n",
    "comparison_df = pd.DataFrame(data)\n",
    "\n",
    "# Appliquer un formatage pour une meilleure lisibilité\n",
    "comparison_df['Valeur de Référence'] = comparison_df['Valeur de Référence'].map('{:.3e}'.format)\n",
    "comparison_df['Valeur Inversée (MCMC)'] = comparison_df['Valeur Inversée (MCMC)'].map('{:.3e}'.format)\n",
    "\n",
    "print(\"--- Comparaison des paramètres de référence et inversés ---\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion des données dans le cas d'un paramètre fixé (ici $q_s$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBITERMCMC = 20\n",
    "\n",
    "priors = {\n",
    "    \"Prior_IntrinK\": ((1e-14, 1e-8), 1e-11), # (intervalle, sigma)\n",
    "    \"Prior_n\": ((.01, .25), .0125),\n",
    "    \"Prior_lambda_s\": ((1, 10), 0.5),\n",
    "    \"Prior_rhos_cs\": ((1e6,1e7), 5e5),\n",
    "    \"Prior_q_s\": (-1e-8, 0),\n",
    "}\n",
    "\n",
    "Layer_homogenous = {\n",
    "    \"name\": \"Couche en sable\",\n",
    "    \"zLow\": Zbottom,\n",
    "    \"IntrinK\":1e-11,\n",
    "    \"n\": 0.1,\n",
    "    \"lambda_s\": 2,\n",
    "    \"rhos_cs\": 4e6,\n",
    "    \"q_s\": -1e-8,\n",
    "}\n",
    "\n",
    "Layer_homogenous = Layer.from_dict(Layer_homogenous)\n",
    "\n",
    "# On crée une couche de référence pour la comparaison plus bas\n",
    "reference_params_dict = {\n",
    "    \"name\": \"Couche en sable\",\n",
    "    \"zLow\": Zbottom,\n",
    "    \"IntrinK\":1e-11,\n",
    "    \"n\": 0.1,\n",
    "    \"lambda_s\": 2,\n",
    "    \"rhos_cs\": 4e6,\n",
    "    \"q_s\": -1e-8,\n",
    "}\n",
    "\n",
    "layer_for_simulation = Layer.from_dict(reference_params_dict)\n",
    "\n",
    "col.set_layers(Layer_homogenous)\n",
    "Layer_homogenous.set_priors_from_dict(priors)\n",
    "print(Layer_homogenous.Prior_list)\n",
    "\n",
    "\n",
    "col.all_layers\n",
    "\n",
    "col.compute_mcmc(\n",
    "    nb_iter = NBITERMCMC,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "bestLayers = col.get_best_layers()\n",
    "\n",
    "col.plot_all_param_pdf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- ÉTAPE 1 : ACTION (inchangée) ---\n",
    "col.get_best_layers()\n",
    "\n",
    "# --- ÉTAPE 2 : RÉCUPÉRATION (inchangée) ---\n",
    "inverted_params = col.get_list_current_params()[0]\n",
    "\n",
    "# --- ÉTAPE 3 : COMPARAISON (corrigée) ---\n",
    "# On utilise maintenant le dictionnaire de référence pour les \"vraies\" valeurs.\n",
    "data = {\n",
    "    'Paramètre': PARAM_LIST,\n",
    "    'Valeur de Référence': [\n",
    "        reference_params_dict['IntrinK'],\n",
    "        reference_params_dict['n'],\n",
    "        reference_params_dict['lambda_s'],\n",
    "        reference_params_dict['rhos_cs'],\n",
    "        reference_params_dict['q_s']\n",
    "    ],\n",
    "    'Valeur Inversée (MCMC)': [\n",
    "        inverted_params.IntrinK,\n",
    "        inverted_params.n,\n",
    "        inverted_params.lambda_s,\n",
    "        inverted_params.rhos_cs,\n",
    "        inverted_params.q_s\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Créer et afficher le tableau de comparaison\n",
    "comparison_df = pd.DataFrame(data)\n",
    "\n",
    "# Appliquer un formatage pour une meilleure lisibilité\n",
    "comparison_df['Valeur de Référence'] = comparison_df['Valeur de Référence'].map('{:.3e}'.format)\n",
    "comparison_df['Valeur Inversée (MCMC)'] = comparison_df['Valeur Inversée (MCMC)'].map('{:.3e}'.format)\n",
    "\n",
    "print(\"--- Comparaison des paramètres de référence et inversés ---\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
