{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOLONARI 2023 : Mattéo Letturcq-Daligaux\n",
    "MOLONARI 2024 : Martin Jessenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyheatmy import *\n",
    "from typing import List, Sequence, Union\n",
    "from numbers import Number\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "PARAM_LIST = (\"moinslog10IntrinK\", \"n\", \"lambda_s\", \"rhos_cs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capteur_riviere = pd.read_csv(\"../data/Point034_processed/processed_pressures.csv\", sep = ',', names = ['dates', 'tension', 'temperature_riviere'], skiprows=1)\n",
    "capteur_ZH = pd.read_csv(\"../data/Point034_processed/processed_temperatures.csv\", sep = ',', names = ['dates', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_40'], skiprows=1)\n",
    "etalonage_capteur_riv = pd.read_csv(\"../configuration/pressure_sensors/P508.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDates(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Convert dates from a list of strings by testing several different input formats\n",
    "    Try all date formats already encountered in data points\n",
    "    If none of them is OK, try the generic way (None)\n",
    "    If the generic way doesn't work, this method fails\n",
    "    (in that case, you should add the new format to the list)\n",
    "    \n",
    "    This function works directly on the giving Pandas dataframe (in place)\n",
    "    This function assumes that the first column of the given Pandas dataframe\n",
    "    contains the dates as characters string type\n",
    "    \n",
    "    For datetime conversion performance, see:\n",
    "    See https://stackoverflow.com/questions/40881876/python-pandas-convert-datetime-to-timestamp-effectively-through-dt-accessor\n",
    "    \"\"\"\n",
    "    formats = (\"%m/%d/%y %H:%M:%S\", \"%m/%d/%y %I:%M:%S %p\",\n",
    "               \"%d/%m/%y %H:%M\",    \"%d/%m/%y %I:%M %p\",\n",
    "               \"%m/%d/%Y %H:%M:%S\", \"%m/%d/%Y %I:%M:%S %p\", \n",
    "               \"%d/%m/%Y %H:%M\",    \"%d/%m/%Y %I:%M %p\",\n",
    "               \"%y/%m/%d %H:%M:%S\", \"%y/%m/%d %I:%M:%S %p\", \n",
    "               \"%y/%m/%d %H:%M\",    \"%y/%m/%d %I:%M %p\",\n",
    "               \"%Y/%m/%d %H:%M:%S\", \"%Y/%m/%d %I:%M:%S %p\", \n",
    "               \"%Y/%m/%d %H:%M\",    \"%Y/%m/%d %I:%M %p\",\n",
    "               None)\n",
    "    times = df[df.columns[0]]\n",
    "    for f in formats:\n",
    "        try:\n",
    "            # Convert strings to datetime objects\n",
    "            new_times = pd.to_datetime(times, format=f)\n",
    "            # Convert datetime series to numpy array of integers (timestamps)\n",
    "            new_ts = new_times.values.astype(np.int64)\n",
    "            # If times are not ordered, this is not the appropriate format\n",
    "            test = np.sort(new_ts) - new_ts\n",
    "            if np.sum(abs(test)) != 0 :\n",
    "                #print(\"Order is not the same\")\n",
    "                raise ValueError()\n",
    "            # Else, the conversion is a success\n",
    "            #print(\"Found format \", f)\n",
    "            df[df.columns[0]] = new_times\n",
    "            return\n",
    "        \n",
    "        except ValueError:\n",
    "            #print(\"Format \", f, \" not valid\")\n",
    "            continue\n",
    "    \n",
    "    # None of the known format are valid\n",
    "    raise ValueError(\"Cannot convert dates: No known formats match your data!\")\n",
    "\n",
    "convertDates(capteur_riviere)\n",
    "convertDates(capteur_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# conversion des mesures de pression\n",
    "intercept = float(etalonage_capteur_riv['P508'][2])\n",
    "a = float(etalonage_capteur_riv['P508'][3])\n",
    "b = float(etalonage_capteur_riv['P508'][4])\n",
    "capteur_riviere['dH'] = (capteur_riviere['tension'].astype(float)-intercept-capteur_riviere['temperature_riviere'].astype(float)*b)/a\n",
    "\n",
    "# conversion mesures de tempétratures\n",
    "capteur_riviere['temperature_riviere'] = capteur_riviere['temperature_riviere'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_10'] = capteur_ZH['temperature_10'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_20'] = capteur_ZH['temperature_20'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_30'] = capteur_ZH['temperature_30'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_40'] = capteur_ZH['temperature_40'] + ZERO_CELSIUS\n",
    "\n",
    "# définition des attributs de colonnes\n",
    "dH_measures = list(zip(capteur_riviere['dates'],list(zip(capteur_riviere['dH'], capteur_riviere['temperature_riviere']))))\n",
    "T_measures = list(zip(capteur_ZH['dates'], capteur_ZH[['temperature_10', 'temperature_20', 'temperature_30', 'temperature_40']].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {\n",
    "\t\"river_bed\": 1., \n",
    "    \"depth_sensors\": [.1, .2, .3, .4],\n",
    "\t\"offset\": .0,\n",
    "    \"dH_measures\": dH_measures,\n",
    "\t\"T_measures\": T_measures,\n",
    "    \"sigma_meas_P\": None,\n",
    "    \"sigma_meas_T\": None,\n",
    "    \"inter_mode\": 'lagrange'\n",
    "}\n",
    "\n",
    "col = Column.from_dict(col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer_1 = {\n",
    "    \"name\": \"Layer 1\",\n",
    "    \"zLow\": 0.2,\n",
    "    \"Prior_moinslog10IntrinK\": Prior((11, 15), .01), # (intervalle, sigma)\n",
    "    \"Prior_n\": Prior((0.01, 0.25), .005),\n",
    "    \"Prior_lambda_s\": Prior((1, 5), .1),\n",
    "    \"Prior_rhos_cs\": Prior((1e6, 1e7), 1e5),\n",
    "    \"Prior_q\": Prior((1e-6,1e-4), 1e-6)\n",
    "}\n",
    "\n",
    "Layer_2 = {\n",
    "    \"name\": \"Layer 2\",\n",
    "    \"zLow\": 0.3,\n",
    "    \"Prior_moinslog10IntrinK\": Prior((11, 15), .01), # (intervalle, sigma)\n",
    "    \"Prior_n\": Prior((0.01, 0.25), .005),\n",
    "    \"Prior_lambda_s\": Prior((1, 5), .1),\n",
    "    \"Prior_rhos_cs\": Prior((1e6, 1e7), 1e5),\n",
    "    \"Prior_q\": Prior((1e-6,1e-4), 1e-6)\n",
    "}\n",
    "\n",
    "Layer_3 = {\n",
    "    \"name\": \"Layer 3\",\n",
    "    \"zLow\": 0.4,\n",
    "    \"Prior_moinslog10IntrinK\": Prior((11, 15), .01), # (intervalle, sigma)\n",
    "    \"Prior_n\": Prior((0.01, 0.25), .005),\n",
    "    \"Prior_lambda_s\": Prior((1, 5), .1),\n",
    "    \"Prior_rhos_cs\": Prior((1e6, 1e7), 1e5),\n",
    "    \"Prior_q\": Prior((1e-6,1e-4), 1e-6)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col.set_layers([Layer.from_dict(Layer_1), Layer.from_dict(Layer_2), Layer.from_dict(Layer_3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.compute_mcmc(nb_chain=15, delta=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.get_best_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"acceptance : {col._acceptance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.all_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.compute_solve_transi(verbose=False)\n",
    "col.plot_all_param_pdf()\n",
    "col.plot_all_results()\n",
    "col.plot_darcy_flow_quantile()\n",
    "col.plot_quantile_temperatures_sensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul des quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà la façon dont sont calculés les quantiles de température (idem pour le flow) dans le projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"quantile = np.array([0.05, 0.5, 0.95])\n",
    "quantiles_temperatures = np.quantile(_temp, quantile, axis=0)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le calcul est gourmand en temps de calcul et nécessite de stocker un tableau `quantiles_temps` et un tableau `temp` dont les tailles sont indiquées ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"print(\"Dimensions de quantiles_temperatures : \", quantiles_temperatures.shape, \" (nb_quantiles, nb_chain, n_cells, n_temperatures)\")\n",
    "print(\"Dimensions de quantiles_temperatures : \", _temp.shape, \" (nb_iter, nb_chain, n_cells, n_temperatures)\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces deux tableaux représentent un encombrement mémoire important qui dépasse le seuil fixé par le cahier des charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"print(\"Mémoire pour les quantiles de température : \", quantiles_temperatures.nbytes/1000000, \" Méga octets.\")\n",
    "print(\"Mémoire pour les températures : \", _temp.nbytes/1000000000, \"Giga octets.\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour réduire cet encombrement mémoire, on peut intuitivement supposer que les profils de température ne varient pas énormément entre deux pas de temps consécutifs. On peut donc réaliser un sous-échantillonnage sur les pas de temps afin de calculer les quantiles. De même, on peut réaliser un sous-échantillonnage spatial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"n_sous_ech_time = 2 # 1 mesure considérée par demi-heure\n",
    "n_sous_ech_space = 4 # 1 mesure considérée tous les 2 cm\n",
    "\n",
    "_temp_sous_ech = _temp[:,:,::n_sous_ech_space,::n_sous_ech_time]\n",
    "quantiles_temperatures_sous_ech = np.quantile(_temp_sous_ech, quantile, axis=0)\n",
    "\n",
    "np.allclose(quantiles_temperatures_sous_ech,  quantiles_temperatures[:, :, ::n_sous_ech_space, ::n_sous_ech_time])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les quantiles sont calculés sur chaque case $(chaine, cellule, temps)$ en utilisant les valeurs obtenues avec les itérations, il est donc normal que ces deux calculs conduisent aux mêmes valeurs de quantiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Déterminons alors le nouvel encombrement mémoire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Mémoire pour les quantiles de température : \", quantiles_temperatures_sous_ech.nbytes/1000000, \" Méga octets.\")\n",
    "#print(\"Mémoire pour les températures : \", _temp_sous_ech.nbytes/1000000000, \"Giga octets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation de la méthode P2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, réalisons le calcul des quantiles avec l'algorithme P2 en stockant les données du tableau afin de vérifier si c'est plus rapide ou non que la fonction `np.quantile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def P2(p, data):\n",
    "    \"\"\"\n",
    "#    Input : p [float] - nombre du quantile que l'on veut estimer (ex: médiane -> p=0.5)\n",
    "#            data [2D float np.array] - jeu de données désordonné\n",
    "\n",
    "#    Output : [float] estimation du p-ième quantile\n",
    "\"\"\"\n",
    "\n",
    "    # INITIALISATION\n",
    "\n",
    "    markers = np.sort(data[:5])\n",
    "    markers_index = np.arange(5)\n",
    "    desired_index = np.array([1., 1+2*p, 1+4*p, 3+2*p, 5])\n",
    "    increment = np.array([0, p/2, p, (1+p)/2, 1])\n",
    "\n",
    "    # ITERATION\n",
    "\n",
    "    for x in data[5:]:\n",
    "        # x est l'observable suivante (actuellement avec le tableau data mais à améliorer pour ne rien avoir à stocker)\n",
    "\n",
    "        # Déterminer l'indice k tel que marker[k] <= x < marker[k+1]\n",
    "        k = np.searchsorted(markers, x, side='right') - 1\n",
    "\n",
    "        if k == 0:\n",
    "            # Ajuster le minimum\n",
    "            markers[0] = x\n",
    "        \n",
    "        elif k == 4:\n",
    "            # Ajuster le maximum\n",
    "            markers[4] = x \n",
    "\n",
    "        # Incrémenter les positions des markers au-delà de x\n",
    "        markers_index[k+1:] += 1\n",
    "\n",
    "        # Incrémenter toutes les positions désirées\n",
    "        desired_index += increment \n",
    "\n",
    "        # Ajuster les markers centraux si nécessaire\n",
    "        for i in range(1,4):\n",
    "            d = desired_index[i] - markers_index[i]\n",
    "\n",
    "            if ( (d >= 1) and (markers_index[i+1] - markers_index[i] > 1) ) or ( (d <= -1) and (markers_index[i-1] - markers_index[i] < -1) ):\n",
    "\n",
    "                d = int(np.sign(d))\n",
    "\n",
    "                # P2 formula\n",
    "                a = d / (markers_index[i+1] - markers_index[i-1])\n",
    "                b = (markers_index[i] - markers_index[i-1] + d) * (markers[i+1] - markers[i]) / (markers_index[i+1] - markers_index[i])\n",
    "                c = (markers_index[i+1] - markers_index[i] - d) * (markers[i] - markers[i-1]) / (markers_index[i] - markers_index[i-1])\n",
    "                q = markers_index[i] + a * (b + c)\n",
    "\n",
    "                # Ordonnement des markers\n",
    "                if markers[i-1] <= q <= markers[i+1]:\n",
    "                    markers[i] = q\n",
    "                \n",
    "                else:\n",
    "                    # Linear formula\n",
    "                    markers[i] += d * (markers[i+d] - markers[i]) / (markers_index[i+d] - markers_index[i])\n",
    "\n",
    "                markers_index[i] += d \n",
    "        \n",
    "    # RENVOYER L'APPEOXIMATION DU p-IEME QUANTILE\n",
    "\n",
    "    return markers[2]\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantiles_sous_ech_P2 = np.zeros(quantiles_temperatures.shape)\n",
    "# nb_cells_sous_ech = nb_cells // n_sous_ech_space\n",
    "# nb_times_sous_ech = _temp.shape[-1] // n_sous_ech_time\n",
    "\n",
    "# for i,q in enumerate(quantile):\n",
    "#     for j in range(nb_chain):\n",
    "#         for c in range(nb_cells_sous_ech):\n",
    "#             for t in range(nb_times_sous_ech):\n",
    "#                 tab = _temp_sous_ech\n",
    "#                 quantiles_sous_ech_P2[i,j,c,t] = P2(q, _temp_sous_ech[:,j,c,t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est très lent, je déconseille d'attendre la fin de l'exécution. On rejette donc immédiatement l'éventualité de remplacer `np.quantile` par P2, bien que ce dernier algorithme ait l'avantage de fonctionner même sans stocker les données dans un tableau. Nous utiliserons uniquement le sous-échantillonnage dans la suite et essayerons deux protocoles dans le but de respecter la contrainte de 2Go de mémoire vive imposée par le cahier des charges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les solutions envisagées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ecrire dans un fichier pendant la MCMC pour ne pas encombrer la mémoire de plus de 5Go de données\n",
    "* Ne pas écrire dans un fichier mais retrouver les distributions de température uniquement avec les quantiles obtenus avec le tableau sous-échantillonné, calculé pendant MCMC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molonaricompatible",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
