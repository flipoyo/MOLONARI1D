{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOLONARI 2023 : Mattéo Letturcq-Daligaux\n",
    "MOLONARI 2024 : Martin Jessenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyheatmy import *\n",
    "from typing import List, Sequence, Union\n",
    "from numbers import Number\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "PARAM_LIST = (\"moinslog10IntrinK\", \"n\", \"lambda_s\", \"rhos_cs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "capteur_riviere = pd.read_csv(\"../data/Point034_processed/processed_pressures.csv\", sep = ',', names = ['dates', 'tension', 'temperature_riviere'], skiprows=1)\n",
    "capteur_ZH = pd.read_csv(\"../data/Point034_processed/processed_temperatures.csv\", sep = ',', names = ['dates', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_40'], skiprows=1)\n",
    "etalonage_capteur_riv = pd.read_csv(\"../configuration/pressure_sensors/P508.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDates(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Convert dates from a list of strings by testing several different input formats\n",
    "    Try all date formats already encountered in data points\n",
    "    If none of them is OK, try the generic way (None)\n",
    "    If the generic way doesn't work, this method fails\n",
    "    (in that case, you should add the new format to the list)\n",
    "    \n",
    "    This function works directly on the giving Pandas dataframe (in place)\n",
    "    This function assumes that the first column of the given Pandas dataframe\n",
    "    contains the dates as characters string type\n",
    "    \n",
    "    For datetime conversion performance, see:\n",
    "    See https://stackoverflow.com/questions/40881876/python-pandas-convert-datetime-to-timestamp-effectively-through-dt-accessor\n",
    "    \"\"\"\n",
    "    formats = (\"%m/%d/%y %H:%M:%S\", \"%m/%d/%y %I:%M:%S %p\",\n",
    "               \"%d/%m/%y %H:%M\",    \"%d/%m/%y %I:%M %p\",\n",
    "               \"%m/%d/%Y %H:%M:%S\", \"%m/%d/%Y %I:%M:%S %p\", \n",
    "               \"%d/%m/%Y %H:%M\",    \"%d/%m/%Y %I:%M %p\",\n",
    "               \"%y/%m/%d %H:%M:%S\", \"%y/%m/%d %I:%M:%S %p\", \n",
    "               \"%y/%m/%d %H:%M\",    \"%y/%m/%d %I:%M %p\",\n",
    "               \"%Y/%m/%d %H:%M:%S\", \"%Y/%m/%d %I:%M:%S %p\", \n",
    "               \"%Y/%m/%d %H:%M\",    \"%Y/%m/%d %I:%M %p\",\n",
    "               None)\n",
    "    times = df[df.columns[0]]\n",
    "    for f in formats:\n",
    "        try:\n",
    "            # Convert strings to datetime objects\n",
    "            new_times = pd.to_datetime(times, format=f)\n",
    "            # Convert datetime series to numpy array of integers (timestamps)\n",
    "            new_ts = new_times.values.astype(np.int64)\n",
    "            # If times are not ordered, this is not the appropriate format\n",
    "            test = np.sort(new_ts) - new_ts\n",
    "            if np.sum(abs(test)) != 0 :\n",
    "                #print(\"Order is not the same\")\n",
    "                raise ValueError()\n",
    "            # Else, the conversion is a success\n",
    "            #print(\"Found format \", f)\n",
    "            df[df.columns[0]] = new_times\n",
    "            return\n",
    "        \n",
    "        except ValueError:\n",
    "            #print(\"Format \", f, \" not valid\")\n",
    "            continue\n",
    "    \n",
    "    # None of the known format are valid\n",
    "    raise ValueError(\"Cannot convert dates: No known formats match your data!\")\n",
    "\n",
    "convertDates(capteur_riviere)\n",
    "convertDates(capteur_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# conversion des mesures de pression\n",
    "intercept = float(etalonage_capteur_riv['P508'][2])\n",
    "a = float(etalonage_capteur_riv['P508'][3])\n",
    "b = float(etalonage_capteur_riv['P508'][4])\n",
    "capteur_riviere['dH'] = (capteur_riviere['tension'].astype(float)-intercept-capteur_riviere['temperature_riviere'].astype(float)*b)/a\n",
    "\n",
    "# conversion mesures de tempétratures\n",
    "capteur_riviere['temperature_riviere'] = capteur_riviere['temperature_riviere'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_10'] = capteur_ZH['temperature_10'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_20'] = capteur_ZH['temperature_20'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_30'] = capteur_ZH['temperature_30'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_40'] = capteur_ZH['temperature_40'] + ZERO_CELSIUS\n",
    "\n",
    "# définition des attributs de colonnes\n",
    "dH_measures = list(zip(capteur_riviere['dates'],list(zip(capteur_riviere['dH'], capteur_riviere['temperature_riviere']))))\n",
    "T_measures = list(zip(capteur_ZH['dates'], capteur_ZH[['temperature_10', 'temperature_20', 'temperature_30', 'temperature_40']].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {\n",
    "\t\"river_bed\": 1., \n",
    "    \"depth_sensors\": [.1, .2, .3, .4],\n",
    "\t\"offset\": .0,\n",
    "    \"dH_measures\": dH_measures,\n",
    "\t\"T_measures\": T_measures,\n",
    "    \"sigma_meas_P\": None,\n",
    "    \"sigma_meas_T\": None,\n",
    "    \"inter_mode\": 'lagrange'\n",
    "}\n",
    "\n",
    "col = Column.from_dict(col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer_1 = {\n",
    "    \"name\": \"Layer 1\",\n",
    "    \"zLow\": 0.2,\n",
    "    \"Prior_moinslog10IntrinK\": Prior((11, 15), .01), # (intervalle, sigma)\n",
    "    \"Prior_n\": Prior((0.01, 0.25), .005),\n",
    "    \"Prior_lambda_s\": Prior((1, 5), .1),\n",
    "    \"Prior_rhos_cs\": Prior((1e6, 1e7), 1e5),\n",
    "    \"Prior_q\": Prior((1e-6,1e-4), 1e-6)\n",
    "}\n",
    "\n",
    "Layer_2 = {\n",
    "    \"name\": \"Layer 2\",\n",
    "    \"zLow\": 0.3,\n",
    "    \"Prior_moinslog10IntrinK\": Prior((11, 15), .01), # (intervalle, sigma)\n",
    "    \"Prior_n\": Prior((0.01, 0.25), .005),\n",
    "    \"Prior_lambda_s\": Prior((1, 5), .1),\n",
    "    \"Prior_rhos_cs\": Prior((1e6, 1e7), 1e5),\n",
    "    \"Prior_q\": Prior((1e-6,1e-4), 1e-6)\n",
    "}\n",
    "\n",
    "Layer_3 = {\n",
    "    \"name\": \"Layer 3\",\n",
    "    \"zLow\": 0.4,\n",
    "    \"Prior_moinslog10IntrinK\": Prior((11, 15), .01), # (intervalle, sigma)\n",
    "    \"Prior_n\": Prior((0.01, 0.25), .005),\n",
    "    \"Prior_lambda_s\": Prior((1, 5), .1),\n",
    "    \"Prior_rhos_cs\": Prior((1e6, 1e7), 1e5),\n",
    "    \"Prior_q\": Prior((1e-6,1e-4), 1e-6)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col.set_layers([Layer.from_dict(Layer_1), Layer.from_dict(Layer_2), Layer.from_dict(Layer_3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "Initialisation - Utilisation de la mémoire (en Mo) : 307.544064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Burn in phase:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Burn in phase:   4%|▍         | 1/25 [00:00<00:11,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/pgpetitmangin/molo/td/td3/MOLONARI1D/pyheatmy/pyheatmy/core.py\", line 762, in compute_solve_transi\n",
      "    raise ValueError(\"NaN values in compute_solve_transi\")\n",
      "ValueError: NaN values in compute_solve_transi\n",
      "Burn in phase:   4%|▍         | 1/25 [00:00<00:18,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "---Débogage des dimensions avant la boucle : len(K_list) = 60, nablaH.shape = (60, 1309) ---\n",
      "Issue for the following parameters : [Param(moinslog10IntrinK=np.float32(14.696182), n=np.float32(0.18262224), lambda_s=np.float32(1.7628839), rhos_cs=np.float32(4.460957e+06), q=np.float32(9.50229e-05)), Param(moinslog10IntrinK=np.float32(11.132697), n=np.float32(0.039634895), lambda_s=np.float32(3.9080238), rhos_cs=np.float32(4.7349025e+06), q=np.float32(1.759906e-05)), Param(moinslog10IntrinK=np.float32(11.285437), n=np.float32(0.10651493), lambda_s=np.float32(3.297011), rhos_cs=np.float32(3.2045652e+06), q=np.float32(4.0409708e-05))]\n",
      "Issue for the follwing number of layers : 3\n",
      "\n",
      "--- RAPPORT DE BUG DÉFINITIF ---\n",
      "Une erreur inattendue s'est produite : NaN values in compute_solve_transi\n",
      "Voici la trace exacte menant à l'erreur :\n",
      "--- FIN DU RAPPORT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "NaN values in compute_solve_transi",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcol\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_mcmc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb_chain\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/molo/td/td3/MOLONARI1D/pyheatmy/pyheatmy/checker.py:55\u001b[39m, in \u001b[36mchecker.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m new_wrapper.reset = reset\n\u001b[32m     54\u001b[39m \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, checked_meth.\u001b[34m__name__\u001b[39m, new_wrapper)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/molo/td/td3/MOLONARI1D/pyheatmy/pyheatmy/checker.py:47\u001b[39m, in \u001b[36mchecker.<locals>.wrapper.<locals>.new_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(checked_meth)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     46\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, chkd_name, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchecked_meth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/molo/td/td3/MOLONARI1D/pyheatmy/pyheatmy/core.py:1187\u001b[39m, in \u001b[36mColumn.compute_mcmc\u001b[39m\u001b[34m(self, quantile, verbose, typealgo, sigma2, nb_iter, nb_chain, nitmaxburning, delta, n_CR, c, c_star, n_sous_ech_time, n_sous_ech_space, threshold)\u001b[39m\n\u001b[32m   1184\u001b[39m     layer.params = Param(*X_proposal[l])\n\u001b[32m   1186\u001b[39m \u001b[38;5;66;03m# Calcul du profil de température associé aux nouveaux paramètres\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1187\u001b[39m \u001b[43mcolumn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_solve_transi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[38;5;66;03m# On récupère les températures et les débits associés aux nouveaux paramètres\u001b[39;00m\n\u001b[32m   1190\u001b[39m temp_proposal = column._temperatures\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/molo/td/td3/MOLONARI1D/pyheatmy/pyheatmy/checker.py:47\u001b[39m, in \u001b[36mchecker.<locals>.wrapper.<locals>.new_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(checked_meth)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     46\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, chkd_name, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchecked_meth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/molo/td/td3/MOLONARI1D/pyheatmy/pyheatmy/core.py:770\u001b[39m, in \u001b[36mColumn.compute_solve_transi\u001b[39m\u001b[34m(self, verbose)\u001b[39m\n\u001b[32m    768\u001b[39m traceback.print_exc()\n\u001b[32m    769\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- FIN DU RAPPORT ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/molo/td/td3/MOLONARI1D/pyheatmy/pyheatmy/core.py:762\u001b[39m, in \u001b[36mColumn.compute_solve_transi\u001b[39m\u001b[34m(self, verbose)\u001b[39m\n\u001b[32m    756\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    757\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIssue for the following parameters : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.get_list_current_params()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    758\u001b[39m             )\n\u001b[32m    759\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    760\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIssue for the follwing number of layers : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.all_layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    761\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNaN values in compute_solve_transi\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# <-- LE \"EXCEPT\" EST ICI, À LA FIN\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- RAPPORT DE BUG DÉFINITIF ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: NaN values in compute_solve_transi"
     ]
    }
   ],
   "source": [
    "col.compute_mcmc(nb_chain=15, delta=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.get_best_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"acceptance : {col._acceptance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.all_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.compute_solve_transi(verbose=False)\n",
    "col.plot_all_param_pdf()\n",
    "col.plot_all_results()\n",
    "col.plot_darcy_flow_quantile()\n",
    "col.plot_quantile_temperatures_sensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul des quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà la façon dont sont calculés les quantiles de température (idem pour le flow) dans le projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"quantile = np.array([0.05, 0.5, 0.95])\n",
    "quantiles_temperatures = np.quantile(_temp, quantile, axis=0)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le calcul est gourmand en temps de calcul et nécessite de stocker un tableau `quantiles_temps` et un tableau `temp` dont les tailles sont indiquées ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"print(\"Dimensions de quantiles_temperatures : \", quantiles_temperatures.shape, \" (nb_quantiles, nb_chain, n_cells, n_temperatures)\")\n",
    "print(\"Dimensions de quantiles_temperatures : \", _temp.shape, \" (nb_iter, nb_chain, n_cells, n_temperatures)\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces deux tableaux représentent un encombrement mémoire important qui dépasse le seuil fixé par le cahier des charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"print(\"Mémoire pour les quantiles de température : \", quantiles_temperatures.nbytes/1000000, \" Méga octets.\")\n",
    "print(\"Mémoire pour les températures : \", _temp.nbytes/1000000000, \"Giga octets.\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour réduire cet encombrement mémoire, on peut intuitivement supposer que les profils de température ne varient pas énormément entre deux pas de temps consécutifs. On peut donc réaliser un sous-échantillonnage sur les pas de temps afin de calculer les quantiles. De même, on peut réaliser un sous-échantillonnage spatial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"n_sous_ech_time = 2 # 1 mesure considérée par demi-heure\n",
    "n_sous_ech_space = 4 # 1 mesure considérée tous les 2 cm\n",
    "\n",
    "_temp_sous_ech = _temp[:,:,::n_sous_ech_space,::n_sous_ech_time]\n",
    "quantiles_temperatures_sous_ech = np.quantile(_temp_sous_ech, quantile, axis=0)\n",
    "\n",
    "np.allclose(quantiles_temperatures_sous_ech,  quantiles_temperatures[:, :, ::n_sous_ech_space, ::n_sous_ech_time])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les quantiles sont calculés sur chaque case $(chaine, cellule, temps)$ en utilisant les valeurs obtenues avec les itérations, il est donc normal que ces deux calculs conduisent aux mêmes valeurs de quantiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Déterminons alors le nouvel encombrement mémoire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Mémoire pour les quantiles de température : \", quantiles_temperatures_sous_ech.nbytes/1000000, \" Méga octets.\")\n",
    "#print(\"Mémoire pour les températures : \", _temp_sous_ech.nbytes/1000000000, \"Giga octets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation de la méthode P2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, réalisons le calcul des quantiles avec l'algorithme P2 en stockant les données du tableau afin de vérifier si c'est plus rapide ou non que la fonction `np.quantile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def P2(p, data):\n",
    "    \"\"\"\n",
    "#    Input : p [float] - nombre du quantile que l'on veut estimer (ex: médiane -> p=0.5)\n",
    "#            data [2D float np.array] - jeu de données désordonné\n",
    "\n",
    "#    Output : [float] estimation du p-ième quantile\n",
    "\"\"\"\n",
    "\n",
    "    # INITIALISATION\n",
    "\n",
    "    markers = np.sort(data[:5])\n",
    "    markers_index = np.arange(5)\n",
    "    desired_index = np.array([1., 1+2*p, 1+4*p, 3+2*p, 5])\n",
    "    increment = np.array([0, p/2, p, (1+p)/2, 1])\n",
    "\n",
    "    # ITERATION\n",
    "\n",
    "    for x in data[5:]:\n",
    "        # x est l'observable suivante (actuellement avec le tableau data mais à améliorer pour ne rien avoir à stocker)\n",
    "\n",
    "        # Déterminer l'indice k tel que marker[k] <= x < marker[k+1]\n",
    "        k = np.searchsorted(markers, x, side='right') - 1\n",
    "\n",
    "        if k == 0:\n",
    "            # Ajuster le minimum\n",
    "            markers[0] = x\n",
    "        \n",
    "        elif k == 4:\n",
    "            # Ajuster le maximum\n",
    "            markers[4] = x \n",
    "\n",
    "        # Incrémenter les positions des markers au-delà de x\n",
    "        markers_index[k+1:] += 1\n",
    "\n",
    "        # Incrémenter toutes les positions désirées\n",
    "        desired_index += increment \n",
    "\n",
    "        # Ajuster les markers centraux si nécessaire\n",
    "        for i in range(1,4):\n",
    "            d = desired_index[i] - markers_index[i]\n",
    "\n",
    "            if ( (d >= 1) and (markers_index[i+1] - markers_index[i] > 1) ) or ( (d <= -1) and (markers_index[i-1] - markers_index[i] < -1) ):\n",
    "\n",
    "                d = int(np.sign(d))\n",
    "\n",
    "                # P2 formula\n",
    "                a = d / (markers_index[i+1] - markers_index[i-1])\n",
    "                b = (markers_index[i] - markers_index[i-1] + d) * (markers[i+1] - markers[i]) / (markers_index[i+1] - markers_index[i])\n",
    "                c = (markers_index[i+1] - markers_index[i] - d) * (markers[i] - markers[i-1]) / (markers_index[i] - markers_index[i-1])\n",
    "                q = markers_index[i] + a * (b + c)\n",
    "\n",
    "                # Ordonnement des markers\n",
    "                if markers[i-1] <= q <= markers[i+1]:\n",
    "                    markers[i] = q\n",
    "                \n",
    "                else:\n",
    "                    # Linear formula\n",
    "                    markers[i] += d * (markers[i+d] - markers[i]) / (markers_index[i+d] - markers_index[i])\n",
    "\n",
    "                markers_index[i] += d \n",
    "        \n",
    "    # RENVOYER L'APPEOXIMATION DU p-IEME QUANTILE\n",
    "\n",
    "    return markers[2]\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantiles_sous_ech_P2 = np.zeros(quantiles_temperatures.shape)\n",
    "# nb_cells_sous_ech = nb_cells // n_sous_ech_space\n",
    "# nb_times_sous_ech = _temp.shape[-1] // n_sous_ech_time\n",
    "\n",
    "# for i,q in enumerate(quantile):\n",
    "#     for j in range(nb_chain):\n",
    "#         for c in range(nb_cells_sous_ech):\n",
    "#             for t in range(nb_times_sous_ech):\n",
    "#                 tab = _temp_sous_ech\n",
    "#                 quantiles_sous_ech_P2[i,j,c,t] = P2(q, _temp_sous_ech[:,j,c,t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est très lent, je déconseille d'attendre la fin de l'exécution. On rejette donc immédiatement l'éventualité de remplacer `np.quantile` par P2, bien que ce dernier algorithme ait l'avantage de fonctionner même sans stocker les données dans un tableau. Nous utiliserons uniquement le sous-échantillonnage dans la suite et essayerons deux protocoles dans le but de respecter la contrainte de 2Go de mémoire vive imposée par le cahier des charges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les solutions envisagées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ecrire dans un fichier pendant la MCMC pour ne pas encombrer la mémoire de plus de 5Go de données\n",
    "* Ne pas écrire dans un fichier mais retrouver les distributions de température uniquement avec les quantiles obtenus avec le tableau sous-échantillonné, calculé pendant MCMC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
