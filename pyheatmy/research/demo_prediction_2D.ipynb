{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d4475dc",
   "metadata": {},
   "source": [
    "### Test de pertinence des 2 méthodes: AICC et LRT\n",
    "\n",
    "Notre méthode va consister à simuler plusieurs écoulements avec un débit **q** transversal variant de $10^{-11}$ à $10^{-3}$. \n",
    "\n",
    "Pour chacun de ces débit, on applique nos méthodes AICC et LRT afin de savoir ce qu'elles prédisent. \n",
    "\n",
    "On tracera ensuite les prédictions des 2 modèles en fonction de **q** afin de déterminer leurs caractéristiques et les valeurs limites de **q**.\n",
    "\n",
    "Problème : Nécessite 2 fichiers CSV + problème moinslog10IntrinK. \n",
    "Les fichiers CSV sont sur la branche 205-frequentiel-amortissement_et_dephasage-copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4482d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyheatmy import *\n",
    "from datetime import datetime, timedelta\n",
    "import os, csv\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "from frequency import frequency_analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e151a",
   "metadata": {},
   "source": [
    "On écrit ici une fonction qui automatise, à partir de q simplement, un jeu de données, une observation aux différentes profondeurs, ainsi que la transformée de Fourier.\n",
    "\n",
    "On retourne en sortie l'objet fa qui appartient à la classe \"frequentiel_analysis\" (définie dans le notebook \"frequency_updated\"), qui contient les 4 valeurs d'amplitude qui m'intéresse. On renvoit aussi en sortie \"depths\" qui est simplement les profondeurs des capteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db95d590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fa(q):\n",
    "    Zbottom = 0.4  # \n",
    "    depth_sensors = [0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "    Layer1 = Layer.from_dict({\n",
    "    \"name\": \"Sable homogène\",\n",
    "    \"zLow\": Zbottom,\n",
    "    \"moinslog10IntrinK\": 12,\n",
    "    \"n\": 0.1,\n",
    "    \"lambda_s\": 1.0,\n",
    "    \"rhos_cs\": 4e6,\n",
    "    \"q\": q,\n",
    "    })\n",
    "\n",
    "    t_debut = (2011,1,1); t_fin = (2011,2,28,23,59,59)\n",
    "    dt = 15*NSECINMIN  # pas de 15 s\n",
    "    T_riv_amp, T_riv_offset = 1, 12 + ZERO_CELSIUS\n",
    "    nday = 1\n",
    "    P_T_riv = nday*NHOURINDAY*4*dt  # période ≈ 1 jour\n",
    "\n",
    "    time_series_dict = {\n",
    "        \"offset\": 0.0,\n",
    "        \"depth_sensors\": depth_sensors,\n",
    "        \"param_time_dates\": [t_debut, t_fin, dt],\n",
    "        \"param_dH_signal\": [0, -9999, 0.05],\n",
    "        \"param_T_riv_signal\": [[T_riv_offset], [T_riv_amp, P_T_riv, 0], [1, P_T_riv*30, 0]],\n",
    "        \"param_T_aq_signal\": [[T_riv_offset], [0, -9999, 0]],\n",
    "    }\n",
    "    emu = synthetic_MOLONARI.from_dict(time_series_dict)\n",
    "\n",
    "    col = Column.from_dict({\n",
    "    \"river_bed\": 1,\n",
    "    \"depth_sensors\": depth_sensors,\n",
    "    \"offset\": 0.0,\n",
    "    \"dH_measures\": emu._molonariP_data,\n",
    "    \"T_measures\": emu._T_Shaft_measures,\n",
    "    \"nb_cells\": 100,\n",
    "    \"sigma_meas_P\": 0.01,\n",
    "    \"sigma_meas_T\": 0.1,\n",
    "    }, verbose=False)\n",
    "\n",
    "    col.set_layers(Layer1)\n",
    "    col.compute_solve_transi()\n",
    "    emu._measures_column_one_layer(col)\n",
    "\n",
    "    dates = emu._dates\n",
    "    river = emu._T_riv\n",
    "    temps_all = col.get_temperature_at_sensors()\n",
    "    signals = [river] + [temps_all[i, :] for i in range(1, temps_all.shape[0]-1)]\n",
    "    depths = [0.0] + list(depth_sensors)\n",
    "\n",
    "    fa = frequentiel_analysis()\n",
    "    fa.fft_sensors(dates, signals, depths)\n",
    "    \n",
    "    depths = np.array(depth_sensors)\n",
    "\n",
    "    dominant_periods_days, dominant_freqs, dominant_amps, meta = fa.find_dominant_periods(signals, river, draw=True)\n",
    "\n",
    "    dominant_periods_days = dominant_periods_days[meta['accepted_mask']]\n",
    "    dominant_freqs = dominant_freqs[meta['accepted_mask']]\n",
    "    dominant_amps = dominant_amps[meta['accepted_mask']]\n",
    "\n",
    "    a_est, a_R2 = fa.estimate_a(dates, signals, depths, dominant_periods_days, draw=True)\n",
    "    b_est, b_R2 = fa.estimate_b(dates, signals, depths, dominant_periods_days, draw=True)\n",
    "    #On utilise ces méthodes pour que fa ait accès à fa._AMPL_AT_PEAKS_, qui est définit uniquement lorsqu'on utilise fa.estimate_a\n",
    "    return depths, fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9f91b7",
   "metadata": {},
   "source": [
    "On définit ici les 2 modèles, LRT et AICC.\n",
    "\n",
    "Elles sont présentées dans le papier de Moonz. Vous pouvez aller voir directement sur le PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def rss_score(y_true, y_pred):\n",
    "    return np.sum((y_true - y_pred)**2)\n",
    "\n",
    "\n",
    "def regression_poly(reg, z_values, deg, show_plot=False, coeff_value=False):\n",
    "    #fft puis ln amplitude et on a les 4 points dans le tableau reg\n",
    "    coeffs = np.polyfit(z_values, reg, deg)\n",
    "    p = np.poly1d(coeffs)\n",
    "\n",
    "    # Prédictions\n",
    "    y_pred = p(z_values)\n",
    "    r2 = r2_score(reg, y_pred)\n",
    "    if show_plot:\n",
    "        plt.scatter(z_values, reg, label='Données FFT mesurées')\n",
    "        plt.plot(z_values, y_pred, 'r--', label=f'Ajustement poly {deg}: R²={r2:.3f}')\n",
    "        plt.xlabel('Profondeur z (m)')\n",
    "        plt.ylabel('Log amplitude ln(A(z))')\n",
    "        plt.title(f\"Régression polynomiale de degré {deg}, Le r carré vaut {r2:.3f}\")\n",
    "        plt.show()\n",
    "    if coeff_value:\n",
    "        return coeffs, r2, rss_score(reg, y_pred)\n",
    "    else:\n",
    "        return r2, rss_score(reg, y_pred)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def critere_AICC(reg, z_values, t_sigma, show = False):\n",
    "    vraisemblance = []\n",
    "    for deg in range(1, 3):\n",
    "        _, rss = regression_poly(reg, z_values, deg)\n",
    "        L = -0.5 * len(z_values) * np.log(2*np.pi*t_sigma**2)- 0.5*rss/(t_sigma**2)\n",
    "        vr = 2*deg - 2*L+(2*deg)*(deg+1)/(len(z_values)-deg)\n",
    "        vraisemblance.append(vr)\n",
    "    min = np.inf\n",
    "    for i in range(len(vraisemblance)):\n",
    "        if vraisemblance[i] < min:\n",
    "            min = vraisemblance[i]\n",
    "            deg = i + 1\n",
    "    if deg == 1:\n",
    "        if show == True:\n",
    "            print(\"Modèle linéaire et donc modèle 1D validé préféré selon le critère d'information d'Akaike corrigé (AICc).\")\n",
    "            return(\"1D\")\n",
    "        else:\n",
    "            return(\"1D\")\n",
    "    else:\n",
    "        if show == True:\n",
    "            print(\"Modèle non linéaire et donc modèle 2D préférable selon le critère d'information d'Akaike corrigé (AICc).\")\n",
    "            return(\"2D\")\n",
    "        else:\n",
    "            return(\"2D\")\n",
    "\n",
    "\n",
    "def critere_LRT(reg, z_values, show = False):\n",
    "    RSS = []\n",
    "    for deg in range(1, 3):\n",
    "        _, RSS1 = regression_poly(reg, z_values, deg)\n",
    "        RSS.append(RSS1)\n",
    "    \n",
    "    LRT = 2 * np.log(RSS[0] / RSS[1])\n",
    "    df = 1\n",
    "    p_value = 1 - chi2.cdf(LRT, df)\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        if show == True:\n",
    "            print(\"Modèle non linéaire et donc modèle 2D préféré selon le critère d'information LRT\")\n",
    "            return(\"2D\")\n",
    "        else:\n",
    "            return(\"2D\")\n",
    "    else:\n",
    "        if show == True:\n",
    "            print(\"Modèle linéaire et donc modèle 1D préférable selon le critère d'information LRT\")\n",
    "            return(\"1D\")\n",
    "        else:\n",
    "            return(\"1D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf6919c",
   "metadata": {},
   "source": [
    "Ici une micro-fonction qui mets mon résultat **fa._AMPS_AT_PEAK** au bon format, car il nous renvoie une liste de liste de taille 1. On prend ensuite le log du rapport entre l'amplitude et celle initiale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791fff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitement_ln(brut):\n",
    "    traite = []\n",
    "    for i in range (len(brut)):\n",
    "        traite.append(np.log(brut[i][0]/brut[0][0]))\n",
    "    return traite\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb72638c",
   "metadata": {},
   "source": [
    "On parcourt ici 100 valeurs de q, et on remplit un tableau en fonction de ce que le modèle prédit.\n",
    "\n",
    "Simple problème: La génération d'une colonne, d'une couche ainsi que la résolution prennent beaucoup de temps. \n",
    "\n",
    "Ainsi, ceci à pris 22 minutes à tourner. De plus, il plot beaucoup de graphes qui sont automatiquement plot dans les différentes classes, à part cela, le code marche bien !\n",
    "\n",
    "**Important :**\n",
    "\n",
    "J'ai sauvegardé les valeurs de LRT et AICC dans le fichier csv: \"comparaison_LRT_AICC.csv\" pour ne pas avoir à relancer la simulation (elle a duré 20 minutes sur mon ordi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee719244",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"q_values = np.logspace(-11, -3, num = 100)\n",
    "LRT = np.ones(len(q_values))\n",
    "AICC = np.ones(len(q_values))\n",
    "\n",
    "for j in range(len(q_values)):\n",
    "    depths, fa = generate_fa(q_values[j])\n",
    "    brut = fa._AMPS_AT_PEAKS\n",
    "    traite = traitement_ln(brut)\n",
    "    rep_LRT = critere_LRT(traite, depths,)\n",
    "    rep_AICC = critere_AICC(traite, depths, 0.3)\n",
    "    if rep_LRT == \"2D\":\n",
    "        LRT[j] = 2\n",
    "    if rep_AICC == \"2D\":\n",
    "        AICC[j] = 2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c40c20",
   "metadata": {},
   "source": [
    "On trace ici les prédictions des 2 modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f1d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"comparaison_LRT_AICC.csv\")\n",
    "q_values = df['q_values']\n",
    "plt.figure()\n",
    "\n",
    "# Tracer les deux courbes\n",
    "plt.plot(q_values, df[\"LRT\"], label='Modèle LRT')\n",
    "plt.plot(q_values, df[\"AICC\"], label='Modèle AICC')\n",
    "\n",
    "\n",
    "# Mettre l’axe des x en échelle logarithmique\n",
    "plt.xscale('log')\n",
    "\n",
    "# Ajouter titres, labels et légende\n",
    "plt.xlabel(\"variations de q\")\n",
    "plt.ylabel(\"prédiction du modèle\")\n",
    "plt.title('Comparaison des modèles LRT et AICC')\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "# Affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c573222e",
   "metadata": {},
   "source": [
    "On récupère la valeur de débit à partir de laquelle les modèles prédisent un écoulement 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c5c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i_LRT = 0\n",
    "j_AICC = 0\n",
    "while df['LRT'][i_LRT] == 1:\n",
    "    i_LRT += 1\n",
    "while df['AICC'][j_AICC] == 1:\n",
    "    j_AICC += 1\n",
    "print(f\"La valeur de débit à partir duquel LRT donne un écoulement 2D est {q_values[i_LRT]}\")\n",
    "print(f\"La valeur de débit à partir duquel AICC donne un écoulement 2D est {q_values[j_AICC]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4e1120",
   "metadata": {},
   "source": [
    "# Création d'un critère à la main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48718ae9",
   "metadata": {},
   "source": [
    "On part simplement du critère des $r^2$, mais on l'adapte légèrement.\n",
    "\n",
    "Une régression de degrès supérieur aura forcément un avantage sur celles de degrès inférieur (degrès de liberté en plus). On part donc du principe que si le $r^2$ de la régression linéaire est plus grand que $0.99$, alors on choisit le modèle \n",
    "1D.\n",
    "\n",
    "Sinon, on compare les deux $r^2$, et si celui du modèle 2D est supérieur à celui du 1D ET que le coefficient en $X^2$ est plus grand que $0.1$, alors on choisit le 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb32b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def critere_maison(reg, z_values, show_reg=False):\n",
    "    r2_list = []\n",
    "    coeffs = []\n",
    "    for deg in range(1, 3):\n",
    "        coeff, r2, _ = regression_poly(reg, z_values, deg, coeff_value=True, show_plot= show_reg)\n",
    "        r2_list.append(r2)\n",
    "        coeffs.append(coeff)\n",
    "    if r2_list[0] > 0.99:\n",
    "        modele = \"1D\"\n",
    "    elif r2_list[1] > r2_list[0] and np.absolute(coeffs[1][0])> 0.1:\n",
    "        modele = \"2D\"\n",
    "    else:\n",
    "        modele = \"1D\"\n",
    "    return modele"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0604ca5b",
   "metadata": {},
   "source": [
    "Idem que pour les 2 critères précédents, le calcul avec les 100 valeurs de q prend du temps. J'ai enregistré les résultats dans \"critère_maison.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa28e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "q_values = np.logspace(-11, -3, num = 100)\n",
    "maison = np.ones(len(q_values))\n",
    "\n",
    "\n",
    "for j in range(len(q_values)):\n",
    "    depths, fa = generate_fa(q_values[j])\n",
    "    brut = fa._AMPS_AT_PEAKS\n",
    "    traite = traitement_ln(brut)\n",
    "    rep_maison = critere_maison(traite, depths,)\n",
    "    if rep_maison == \"2D\":\n",
    "        maison[j] = 2\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109bc899",
   "metadata": {},
   "source": [
    "On plot la courbe du critère maison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d8f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv(\"critere_maison.csv\")\n",
    "q_values = df_2['q_values']\n",
    "maison = df_2['maison']\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Tracer les deux courbes\n",
    "plt.plot(q_values, maison, label='Modèle maison')\n",
    "\n",
    "\n",
    "# Mettre l’axe des x en échelle logarithmique\n",
    "plt.xscale('log')\n",
    "\n",
    "# Ajouter titres, labels et légende\n",
    "plt.xlabel(\"variations de q\")\n",
    "plt.ylabel(\"prédiction du modèle\")\n",
    "plt.title('Modèle maison')\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "# Affichage\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73bece5",
   "metadata": {},
   "source": [
    "# Comparaison des 3 critères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d00f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Tracer les deux courbes\n",
    "plt.plot(q_values, df[\"LRT\"], label='Modèle LRT')\n",
    "plt.plot(q_values, df[\"AICC\"], label='Modèle AICC')\n",
    "plt.plot(q_values, df_2[\"maison\"], label='Modèle maison')\n",
    "\n",
    "# Mettre l’axe des x en échelle logarithmique\n",
    "plt.xscale('log')\n",
    "\n",
    "# Ajouter titres, labels et légende\n",
    "plt.xlabel(\"variations de q\")\n",
    "plt.ylabel(\"prédiction du modèle\")\n",
    "plt.title('Comparaison des modèles LRT,AICC et du critère maison')\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "# Affichage\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
