{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyheatmy Demo Notebook\n",
    "\n",
    "This notebook aims to present the various features of `pyheatmy`. It explains how to:\n",
    "- create a `Column` object from an easy reading of dates\n",
    "- execute the direct model, for homogeneous (section 2)  and heterogeneous (section 3) riverbeds\n",
    "- execute the MCMC\n",
    "- retrieve and display the various results produced during the executions of the direct model or the MCMC\n",
    "\n",
    "This notebook doesn't provide yet information on the DREAM method implemented in 2023. For that purpose please refer to the `DREAM_VX.ipynb` notebooks\n",
    "\n",
    "`pyheatmy` is built around the monolithic `Column` class in `core.py`. It can be executed from this class. Calculation, data retrieval, and plotting are methods provided by the `Column` class.\n",
    "\n",
    "It is based on real data, which can be found in the `data` folder.\n",
    "\n",
    "We recommend reading the API for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyheatmy import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "NBCHAINS = 10\n",
    "DELTA = 4\n",
    "NCR = 3\n",
    "NBITERMCMC = 35\n",
    "NBBURNING = 20\n",
    "DEBUGRUB = 2. # Gelman Rubin criteria\n",
    "NBCELLS = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des données et définition d'un objet ``Column``\n",
    "\n",
    "On doit d'abord récupérer les données issues des capteurs, qui se trouvent dans le dossier ``data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capteur_riviere = pd.read_csv(\"./data/Point034_processed/processed_pressures.csv\", sep = ',', names = ['dates', 'tension', 'temperature_riviere'], skiprows=1)\n",
    "capteur_ZH = pd.read_csv(\"./data/Point034_processed/processed_temperatures.csv\", sep = ',', names = ['dates', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_40'], skiprows=1)\n",
    "etalonage_capteur_riv = pd.read_csv(\"./configuration/pressure_sensors/P508.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit une fonction pour convertir les dates des dataframe, cela peut éviter certains problèmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDates(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Convert dates from a list of strings by testing several different input formats\n",
    "    Try all date formats already encountered in data points\n",
    "    If none of them is OK, try the generic way (None)\n",
    "    If the generic way doesn't work, this method fails\n",
    "    (in that case, you should add the new format to the list)\n",
    "    \n",
    "    This function works directly on the giving Pandas dataframe (in place)\n",
    "    This function assumes that the first column of the given Pandas dataframe\n",
    "    contains the dates as characters string type\n",
    "    \n",
    "    For datetime conversion performance, see:\n",
    "    See https://stackoverflow.com/questions/40881876/python-pandas-convert-datetime-to-timestamp-effectively-through-dt-accessor\n",
    "    \"\"\"\n",
    "    formats = (\"%m/%d/%y %H:%M:%S\", \"%m/%d/%y %I:%M:%S %p\",\n",
    "               \"%d/%m/%y %H:%M\",    \"%d/%m/%y %I:%M %p\",\n",
    "               \"%m/%d/%Y %H:%M:%S\", \"%m/%d/%Y %I:%M:%S %p\", \n",
    "               \"%d/%m/%Y %H:%M\",    \"%d/%m/%Y %I:%M %p\",\n",
    "               \"%y/%m/%d %H:%M:%S\", \"%y/%m/%d %I:%M:%S %p\", \n",
    "               \"%y/%m/%d %H:%M\",    \"%y/%m/%d %I:%M %p\",\n",
    "               \"%Y/%m/%d %H:%M:%S\", \"%Y/%m/%d %I:%M:%S %p\", \n",
    "               \"%Y/%m/%d %H:%M\",    \"%Y/%m/%d %I:%M %p\",\n",
    "               None)\n",
    "    times = df[df.columns[0]]\n",
    "    for f in formats:\n",
    "        try:\n",
    "            # Convert strings to datetime objects\n",
    "            new_times = pd.to_datetime(times, format=f)\n",
    "            # Convert datetime series to numpy array of integers (timestamps)\n",
    "            new_ts = new_times.values.astype(np.int64)\n",
    "            # If times are not ordered, this is not the appropriate format\n",
    "            test = np.sort(new_ts) - new_ts\n",
    "            if np.sum(abs(test)) != 0 :\n",
    "                #print(\"Order is not the same\")\n",
    "                raise ValueError()\n",
    "            # Else, the conversion is a success\n",
    "            #print(\"Found format \", f)\n",
    "            df[df.columns[0]] = new_times\n",
    "            return\n",
    "        \n",
    "        except ValueError:\n",
    "            #print(\"Format \", f, \" not valid\")\n",
    "            continue\n",
    "    \n",
    "    # None of the known format are valid\n",
    "    raise ValueError(\"Cannot convert dates: No known formats match your data!\")\n",
    "\n",
    "convertDates(capteur_riviere)\n",
    "convertDates(capteur_ZH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit les objets ``dH_measures`` et ``T_measures``, nécessaires à la création d'un objet ``Column``, qui réalisera les calculs :\n",
    "- ``dH_measures`` contient les dates des mesures, les mesures de différence de charge, et les températures de la rivière.\n",
    "- ``T_measures`` contient les dates des mesures, et les températures mesurées par les 4 capteurs de la tige."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# conversion des mesures de pression\n",
    "intercept = float(etalonage_capteur_riv['P508'][2])\n",
    "a = float(etalonage_capteur_riv['P508'][3])\n",
    "b = float(etalonage_capteur_riv['P508'][4])\n",
    "capteur_riviere['dH'] = (capteur_riviere['tension'].astype(float)-intercept-capteur_riviere['temperature_riviere'].astype(float)*b)/a\n",
    "\n",
    "# conversion mesures de tempétratures\n",
    "capteur_riviere['temperature_riviere'] = capteur_riviere['temperature_riviere'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_10'] = capteur_ZH['temperature_10'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_20'] = capteur_ZH['temperature_20'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_30'] = capteur_ZH['temperature_30'] + ZERO_CELSIUS\n",
    "capteur_ZH['temperature_40'] = capteur_ZH['temperature_40'] + ZERO_CELSIUS\n",
    "\n",
    "# définition des attributs de colonnes\n",
    "dH_measures = list(zip(capteur_riviere['dates'],list(zip(capteur_riviere['dH'], capteur_riviere['temperature_riviere']))))\n",
    "T_measures = list(zip(capteur_ZH['dates'], capteur_ZH[['temperature_10', 'temperature_20', 'temperature_30', 'temperature_40']].to_numpy()))\n",
    "\n",
    "print(f\"dH : {dH_measures}\")\n",
    "print(f\"Tshaft : {T_measures}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit maintenant l'objet ``Column`` à partir d'un dictionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zbottom = 0.4\n",
    "\n",
    "col_dict = {\n",
    "\t\"river_bed\": 1., \n",
    "    \"depth_sensors\": [.1, .2, .3, Zbottom],\n",
    "\t\"offset\": .0,\n",
    "    \"dH_measures\": dH_measures,\n",
    "\t\"T_measures\": T_measures,\n",
    "    \"sigma_meas_P\": None,\n",
    "    \"sigma_meas_T\": None,\n",
    "    \"inter_mode\": 'lagrange',\n",
    "    \"nb_cells\": NBCELLS,\n",
    "}\n",
    "\n",
    "col = Column.from_dict(col_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objet créé a déjà un certain nombre d'attributs, certains étant initialisés. Se reporter au code ``core.py``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Colonne homogène\n",
    "\n",
    "Le modèle direct calcule les températures au cours du temps dans la colonne. Ensuite, on a accès aux flux, à la RMSE...\n",
    "\n",
    "### 2.1. Modèle direct\n",
    "\n",
    "Pour une colonne homogène, on définit un seul jeu de paramètres, par un tuple ou via la classe ``Param`` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer_homogenous = {\n",
    "    \"name\": \"Layer_homogenous\",\n",
    "    \"zLow\": Zbottom,\n",
    "    \"moinslog10IntrinK\": 12,\n",
    "    \"n\": .1,\n",
    "    \"lambda_s\": 2,\n",
    "    \"rhos_cs\": 4e6,\n",
    "    \"q\": 1e-5\n",
    "}\n",
    "\n",
    "Layer_homogenous = Layer.from_dict(Layer_homogenous)\n",
    "\n",
    "col.set_layers(Layer_homogenous)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on appelle le modèle direct :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.compute_solve_transi(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et on utilise les méthodes de récupération des résultats et de tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.plot_temperature_at_sensors()\n",
    "\n",
    "nt = len(col._temperatures[0,:])\n",
    "dplot=15\n",
    "col.plot_temperatures_umbrella(round(nt/dplot))\n",
    "\n",
    "flows = col.get_flows_solve()\n",
    "unitLeg=\"m/s\"\n",
    "title=\"Débits\"\n",
    "col.plot_it_Zt(flows,title,unitLeg,1.04,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul des écarts de température et comparaison des températures simulées et observées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.print_RMSE_at_sensor()\n",
    "col.plot_compare_temperatures_sensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulations are of very pour quality. Let's inverse the data with mcmc\n",
    "\n",
    "### 2.2 Bayesian inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = {\n",
    "    \"Prior_moinslog10IntrinK\": ((4+7, 9+7), .01), # (intervalle, sigma)\n",
    "    \"Prior_n\": ((.01, .25), .01),\n",
    "    \"Prior_lambda_s\": ((1, 10), .1),\n",
    "    \"Prior_rhos_cs\": ((1e6,1e7), 1e5),\n",
    "    \"Prior_q\": ((1e-12, 1e-4), 1e-10),\n",
    "}\n",
    "\n",
    "Layer_homogenous.set_priors_from_dict(priors)\n",
    "print(Layer_homogenous.Prior_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_chains=NBCHAINS\n",
    "\n",
    "col.compute_mcmc(\n",
    "    nb_iter = NBITERMCMC,\n",
    "    verbose=True,\n",
    "    nb_chain = nb_chains,\n",
    "    nitmaxburning=NBBURNING,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met à jour les paramètres de la colonne avec les paramètres qui minimisent l'erreur après la MCMC\n",
    "col.get_best_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.compute_solve_transi(verbose=False)\n",
    "col.print_RMSE_at_sensor()\n",
    "col.plot_compare_temperatures_sensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the simulation is way closer to the measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.plot_all_param_pdf()\n",
    "print(f\"acceptance : {col._acceptance[-1]}\")\n",
    "col.plot_all_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3 Quantiles\n",
    "\n",
    "Une MCMC calcule aussi des quantiles de températures et de débits d'eau. On peut les récupérer de la façon suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.plot_darcy_flow_quantile()\n",
    "col.plot_quantile_temperatures_sensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi regarder les quantiles au niveau des capteurs, et comparer avec les mesures :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multilayer Column\n",
    "\n",
    "### 3.1. Direct Model\n",
    "\n",
    "Pour une colonne stratifiée, on doit d'abord définir une liste d'objets ``Layer`` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zinterface = 0.2\n",
    "EPS = 1e-15\n",
    "\n",
    "\n",
    "Couche_1 = {\n",
    "    \"name\": \"Couche 1\",\n",
    "    \"zLow\": Zinterface,\n",
    "    \"moinslog10IntrinK\": 11,\n",
    "    \"n\": .1,\n",
    "    \"lambda_s\": 2,\n",
    "    \"rhos_cs\": 4e6,\n",
    "    \"q\": EPS\n",
    "}\n",
    "\n",
    "Couche_2 = {\n",
    "    \"name\": \"Couche 2\",\n",
    "    \"zLow\": Zbottom,\n",
    "    \"moinslog10IntrinK\": 11,\n",
    "    \"n\": .1,\n",
    "    \"lambda_s\": 2,\n",
    "    \"rhos_cs\": 4e6,\n",
    "    \"q\": EPS\n",
    "}\n",
    "\n",
    "Layer1 = Layer.from_dict(Couche_1)\n",
    "Layer2 = Layer.from_dict(Couche_2)\n",
    "\n",
    "col.set_layers([Layer1, Layer2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on appelle le modèle direct :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.compute_solve_transi(verbose=False)\n",
    "\n",
    "col.print_RMSE_at_sensor()\n",
    "col.plot_compare_temperatures_sensors()\n",
    "col.plot_temperature_at_sensors()\n",
    "nt = len(col._temperatures[0,:])\n",
    "dplot=15\n",
    "col.plot_temperatures_umbrella(round(nt/dplot))\n",
    "flows = col.get_flows_solve()\n",
    "unitLeg=\"m/s\"\n",
    "title=\"Débits\"\n",
    "col.plot_it_Zt(flows,title,unitLeg,1.04,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Inférence bayésienne\n",
    "\n",
    "L'inférence bayésienne va nous permettre d'estimer une distribution a posteriori pour chaque paramètre.\n",
    "\n",
    "### 3.2.1. MCMC sans estimation de l'erreur\n",
    "\n",
    "On peut lancer une MCMC en gardant $\\sigma^2$ constant. On définit des distributions a priori pour chaque couche :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilat = 10\n",
    "step = dilat*10\n",
    "\n",
    "\n",
    "priors_couche_1 = {\n",
    "    \"Prior_moinslog10IntrinK\": ((4+7, 9+7), .01), # (intervalle, sigma)\n",
    "    \"Prior_n\": ((.001, .25), .005),\n",
    "    \"Prior_lambda_s\": ((1, 10), .1),\n",
    "    \"Prior_rhos_cs\": ((1e6,1e7), 1e5),\n",
    "   # \"Prior_q\": ((1e-12,1e-4), 1e-10)\n",
    "    \"Prior_q\": ((EPS/dilat,dilat*EPS), EPS/step)\n",
    "}\n",
    "\n",
    "priors_couche_2 = {\n",
    "    \"Prior_moinslog10IntrinK\": ((4+7, 9+7), .01), # (intervalle, sigma)\n",
    "    \"Prior_n\": ((.001, .25), .005),\n",
    "    \"Prior_lambda_s\": ((1, 10), .1),\n",
    "    \"Prior_rhos_cs\": ((1e6,1e7), 1e5),\n",
    "   # \"Prior_q\": ((1e-12,1e-4), 1e-10)\n",
    "    \"Prior_q\": ((EPS/dilat,dilat*EPS), EPS/step)\n",
    "}\n",
    "\n",
    "Layer1.set_priors_from_dict(priors_couche_1)\n",
    "Layer2.set_priors_from_dict(priors_couche_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.compute_mcmc(verbose=True, nb_chain = nb_chains, nitmaxburning=NBBURNING, nb_iter = NBITERMCMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recupération et affichage des distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.plot_all_param_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.get_best_layers()\n",
    "col.compute_solve_transi(verbose=False)\n",
    "col.plot_all_results()\n",
    "col.plot_darcy_flow_quantile()\n",
    "col.plot_quantile_temperatures_sensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 MCMC avec estimation de l'erreur\n",
    "\n",
    "Pour lancer une MCMC avec estimation de la distribution de $\\sigma^2$, il suffit d'ajouter une distribution a priori sur ce paramètre. On utilise pour cela la classe ``Prior``, qui est initialisée avec :\n",
    "- un tuple pour l'intervalle dans lequel le paramètre varie\n",
    "- un écart type pour la marche aléatoire\n",
    "- une densité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_chains=1\n",
    "\n",
    "col.compute_mcmc(verbose=True, nb_chain = nb_chains, typealgo=\"estimesigma\")\n",
    "\n",
    "col.get_best_layers()\n",
    "col.compute_solve_transi(verbose=False)\n",
    "col.plot_all_param_pdf()\n",
    "col.plot_all_results()\n",
    "col.plot_darcy_flow_quantile()\n",
    "col.plot_quantile_temperatures_sensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nb_chains>1:\n",
    "    print(f\"acceptance : {col._acceptance[-1]}\")\n",
    "else:\n",
    "    print(f\"acceptance : {col._acceptance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(col._quantiles_flows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recupérer la valeur finale de sigma2 sur les obs et sa distrib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma2=col.get_best_sigma2()\n",
    "print(f\"Variance of the temperature measurment error : {sigma2}°C\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
