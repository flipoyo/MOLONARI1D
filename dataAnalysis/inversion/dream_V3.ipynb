{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation & Test de Dream-MCMC avec sous-échantillonnage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Compute Solve Transi ---\n",
      "Layer 1 : ends at 0.4 m. Parametres(moinslog10K=7, n=0.1, lambda_s=2, rhos_cs=4000000.0)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "PARAM_LIST = (\"moinslog10K\", \"n\", \"lambda_s\", \"rhos_cs\")\n",
    "\n",
    "capteur_riviere = pd.read_csv(\"../data/Point034_processed/processed_pressures.csv\", sep = ',', names = ['dates', 'tension', 'temperature_riviere'], skiprows=1)\n",
    "capteur_ZH = pd.read_csv(\"../data/Point034_processed/processed_temperatures.csv\", sep = ',', names = ['dates', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_40'], skiprows=1)\n",
    "etalonage_capteur_riv = pd.read_csv(\"../configuration/pressure_sensors/P508.csv\")\n",
    "\n",
    "def convertDates(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Convert dates from a list of strings by testing several different input formats\n",
    "    Try all date formats already encountered in data points\n",
    "    If none of them is OK, try the generic way (None)\n",
    "    If the generic way doesn't work, this method fails\n",
    "    (in that case, you should add the new format to the list)\n",
    "    \n",
    "    This function works directly on the giving Pandas dataframe (in place)\n",
    "    This function assumes that the first column of the given Pandas dataframe\n",
    "    contains the dates as characters string type\n",
    "    \n",
    "    For datetime conversion performance, see:\n",
    "    See https://stackoverflow.com/questions/40881876/python-pandas-convert-datetime-to-timestamp-effectively-through-dt-accessor\n",
    "    \"\"\"\n",
    "    formats = (\"%m/%d/%y %H:%M:%S\", \"%m/%d/%y %I:%M:%S %p\",\n",
    "               \"%d/%m/%y %H:%M\",    \"%d/%m/%y %I:%M %p\",\n",
    "               \"%m/%d/%Y %H:%M:%S\", \"%m/%d/%Y %I:%M:%S %p\", \n",
    "               \"%d/%m/%Y %H:%M\",    \"%d/%m/%Y %I:%M %p\",\n",
    "               \"%y/%m/%d %H:%M:%S\", \"%y/%m/%d %I:%M:%S %p\", \n",
    "               \"%y/%m/%d %H:%M\",    \"%y/%m/%d %I:%M %p\",\n",
    "               \"%Y/%m/%d %H:%M:%S\", \"%Y/%m/%d %I:%M:%S %p\", \n",
    "               \"%Y/%m/%d %H:%M\",    \"%Y/%m/%d %I:%M %p\",\n",
    "               None)\n",
    "    times = df[df.columns[0]]\n",
    "    for f in formats:\n",
    "        try:\n",
    "            # Convert strings to datetime objects\n",
    "            new_times = pd.to_datetime(times, format=f)\n",
    "            # Convert datetime series to numpy array of integers (timestamps)\n",
    "            new_ts = new_times.values.astype(np.int64)\n",
    "            # If times are not ordered, this is not the appropriate format\n",
    "            test = np.sort(new_ts) - new_ts\n",
    "            if np.sum(abs(test)) != 0 :\n",
    "                #print(\"Order is not the same\")\n",
    "                raise ValueError()\n",
    "            # Else, the conversion is a success\n",
    "            #print(\"Found format \", f)\n",
    "            df[df.columns[0]] = new_times\n",
    "            return\n",
    "        \n",
    "        except ValueError:\n",
    "            #print(\"Format \", f, \" not valid\")\n",
    "            continue\n",
    "    \n",
    "    # None of the known format are valid\n",
    "    raise ValueError(\"Cannot convert dates: No known formats match your data!\")\n",
    "\n",
    "convertDates(capteur_riviere)\n",
    "convertDates(capteur_ZH)\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# conversion des mesures de pression\n",
    "intercept = float(etalonage_capteur_riv['P508'][2])\n",
    "a = float(etalonage_capteur_riv['P508'][3])\n",
    "b = float(etalonage_capteur_riv['P508'][4])\n",
    "capteur_riviere['dH'] = (capteur_riviere['tension'].astype(float)-intercept-capteur_riviere['temperature_riviere'].astype(float)*b)/a\n",
    "\n",
    "# conversion mesures de tempétratures\n",
    "capteur_riviere['temperature_riviere'] = capteur_riviere['temperature_riviere'] + 273.15\n",
    "capteur_ZH['temperature_10'] = capteur_ZH['temperature_10'] + 273.15\n",
    "capteur_ZH['temperature_20'] = capteur_ZH['temperature_20'] + 273.15\n",
    "capteur_ZH['temperature_30'] = capteur_ZH['temperature_30'] + 273.15\n",
    "capteur_ZH['temperature_40'] = capteur_ZH['temperature_40'] + 273.15\n",
    "\n",
    "# définition des attributs de colonnes\n",
    "dH_measures = list(zip(capteur_riviere['dates'],list(zip(capteur_riviere['dH'], capteur_riviere['temperature_riviere']))))\n",
    "T_measures = list(zip(capteur_ZH['dates'], capteur_ZH[['temperature_10', 'temperature_20', 'temperature_30', 'temperature_40']].to_numpy()))\n",
    "\n",
    "col_dict = {\n",
    "\t\"river_bed\": 1., \n",
    "    \"depth_sensors\": [.1, .2, .3, .4],\n",
    "\t\"offset\": .0,\n",
    "    \"dH_measures\": dH_measures,\n",
    "\t\"T_measures\": T_measures,\n",
    "    \"sigma_meas_P\": None,\n",
    "    \"sigma_meas_T\": None,\n",
    "    \"inter_mode\": 'lagrange'\n",
    "}\n",
    "\n",
    "col = Column.from_dict(col_dict)\n",
    "\n",
    "params = Param(\n",
    "    moinslog10K = 7,\n",
    "    n = .1,\n",
    "    lambda_s = 2,\n",
    "    rhos_cs = 4e6\n",
    ")\n",
    "\n",
    "params_tuple = (7, .1, 2, 4e6)\n",
    "\n",
    "assert params == params_tuple\n",
    "\n",
    "col.compute_solve_transi(params, nb_cells=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors_couche_1 = {\n",
    "    \"moinslog10K\": ((1, 10), .01), # (intervalle, sigma)\n",
    "    \"n\": ((.001, .25), .005),\n",
    "    \"lambda_s\": ((1, 10), .1),\n",
    "    \"rhos_cs\": ((1e6,1e7), 1e5),\n",
    "}\n",
    "\n",
    "priors_couche_2 = {\n",
    "    \"moinslog10K\": ((4, 9), .01), # (intervalle, sigma)\n",
    "    \"n\": ((.001, .25), .005),\n",
    "    \"lambda_s\": ((1, 10), .1),\n",
    "    \"rhos_cs\": ((1e6,1e7), 1e5),\n",
    "}\n",
    "\n",
    "priors_couche_3 = {\n",
    "    \"moinslog10K\": ((4, 9), .01), # (intervalle, sigma)\n",
    "    \"n\": ((.001, .25), .005),\n",
    "    \"lambda_s\": ((1, 10), .1),\n",
    "    \"rhos_cs\": ((1e6,1e7), 1e5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécution de dream_mcmc sur l'objet Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Compute DREAM MCMC ---\n",
      "Priors :\n",
      "    [Prior sur une valeure qui évolue entre 1 et 10, Prior sur une valeure qui évolue entre 0.001 et 0.25, Prior sur une valeure qui évolue entre 1 et 10, Prior sur une valeure qui évolue entre 1000000.0 et 10000000.0]\n",
      "Number of cells : 100\n",
      "Number of iterations : 1000\n",
      "Number of chains : 10\n",
      "--------------------\n",
      "Initialisation - Utilisation de la mémoire (en Mo) : 287.698944\n",
      "--- Begin Burn in phase ---\n",
      "Burn in finished after : 101 iterations\n",
      "Initialisation post burn-in - Utilisation de la mémoire (en Mo) : 332.111872\n",
      "DREAM MCMC Computation: 100%|██████████| 1000/1000 [02:00<00:00,  8.29it/s]\n",
      "Occupation mémoire des températures (en Mo) :  528.836\n",
      "Occupation mémoire des flux (en Mo) :  528.836\n",
      "Fin itérations MCMC, avant le calcul des quantiles - Utilisation de la mémoire (en Mo) : 1379.438592\n",
      "Quantiles computed\n",
      "Fin de l'exécution - Utilisation de la mémoire (en Mo) : 1385.795584\n",
      "Après la fin de l'exécution - Utilisation de la mémoire (en Mo) : 307.163136\n"
     ]
    }
   ],
   "source": [
    "nb_chain = 10\n",
    "nb_iter = 1000\n",
    "nb_param = 4\n",
    "nb_cells = 100\n",
    "\n",
    "all_priors = [\n",
    "    ['Couche 1', 0.4, priors_couche_1]\n",
    "]\n",
    "\n",
    "if not isinstance(all_priors, AllPriors):\n",
    "    all_priors = AllPriors([LayerPriors(*conv(layer)) for layer in all_priors])\n",
    "\n",
    "col.compute_dream_mcmc_without_sigma2(\n",
    "    nb_iter,\n",
    "    all_priors,\n",
    "    nb_cells,\n",
    "    nb_chain=nb_chain,\n",
    "    verbose=True\n",
    ")\n",
    "process = psutil.Process()\n",
    "print(f\"Après la fin de l'exécution - Utilisation de la mémoire (en Mo) : {process.memory_info().rss /1e6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nicolas\\Documents\\Work\\2A\\MOLONARI\\MOLONARI1D\\pyheatmy2022\\pyheatmy\\dream_V3.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nicolas/Documents/Work/2A/MOLONARI/MOLONARI1D/pyheatmy2022/pyheatmy/dream_V3.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m _params \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([col\u001b[39m.\u001b[39m_states[k]\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mparams \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39;49m(col\u001b[39m.\u001b[39;49m_states))])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nicolas/Documents/Work/2A/MOLONARI/MOLONARI1D/pyheatmy2022/pyheatmy/dream_V3.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m threshold \u001b[39m=\u001b[39m \u001b[39m1.1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nicolas/Documents/Work/2A/MOLONARI/MOLONARI1D/pyheatmy2022/pyheatmy/dream_V3.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m,\u001b[39m15\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "_params = np.array([col._states[k].layers[0].params for k in range(len(col._states))])\n",
    "threshold = 1.1\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(f\"Threshold = {threshold}        Burn-in over after {col.nb_burn_in_iter} iterations\")\n",
    "plt.axis('off')\n",
    "dico = {0 : \"$-log(K)$\", 1 : \"$\\lambda_s$\", 2 : \"$n$\", 3 : \"$rho * C$\"}\n",
    "for k in range(nb_param):\n",
    "    plt.subplot(2, 2, k+1)\n",
    "    plt.hist(_params[:,k], bins = 100, label=f\"{dico[k]}\")\n",
    "    plt.legend();\n",
    "plt.savefig(f\"../images/threshold_{int(threshold*100)}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation de la mémoire vive nécessaire pour l'inversion MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deux approches possibles pour l'utilisateur :\n",
    "* L'ordinateur lui propose un pas de sous-échantillonnage directement. 10 dans le meilleur des cas, plus sinon.\n",
    "* Il entre ses pas de sous-échantillonnage puis l'ordinateur lui dit si ça passe au niveau de la mémoire vive;\n",
    "\n",
    "Nous allons laisser les deux possibilités à l'utilisateur. Il pourra par exemple cliquer sur un bouton \"pas de sous-échantillonnage automatique\" pour activer la seconde option, sinon il entrera lui-même les pas de sous-échantillonnage et on utilisera le code de l'option 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation de la mémoire vive impliquée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ram_estimation(nb_iter, nb_chain, nb_cells, nb_times, nb_layer, n_sous_ech_iter=10, n_sous_ech_space=1, n_sous_ech_time=1, nb_bytes=4):\n",
    "    \"\"\"\n",
    "    Input : le nombre d'itérations, de chaînes, de cellules, de couches,\n",
    "            les pas de sous-échantillonnage respectivement pour les itérations MCMC,\n",
    "            l'espace et le temps\n",
    "            nb_bytes est la taille en octets d'un élément de tableau, par exemple 4 pour float32\n",
    "    Output : estimation de la mémoire vive recquise pour réaliser les inversions MCMC\n",
    "    Method : calcule la RAM nécessaire pour stocker les arrays et y ajoute x % (à déterminer)\n",
    "    \"\"\"\n",
    "    nb_iter_sous_ech = int( np.ceil( (nb_iter+1) / n_sous_ech_iter))\n",
    "    nb_cells_sous_ech = int( np.ceil(nb_cells / n_sous_ech_space) )\n",
    "    nb_times_sous_ech = int( np.ceil(nb_times / n_sous_ech_time) )\n",
    "\n",
    "\n",
    "\n",
    "    ram = 0 # initialisation\n",
    "    ram += (4*nb_chain+1)*nb_cells*nb_times # _temp_act, temp_old, temp_new, _flow_act, _flow_old\n",
    "    ram += 2*nb_chain # _energy, _energy_old\n",
    "    ram += nb_cells*nb_times # temp_new\n",
    "    ram += nb_iter*nb_chain # acceptance\n",
    "    ram += (nb_iter+1)*nb_chain*nb_layer*nb_param # _params\n",
    "    ram += (nb_chain+2)*nb_layer*nb_param #x_new, X_new et dX\n",
    "    ram += 2*nb_iter_sous_ech*nb_chain*nb_cells_sous_ech*nb_times_sous_ech # _flows, _temp\n",
    "    ram += 6*nb_cells_sous_ech*nb_times_sous_ech # quantiles_temps, quantiles_flows\n",
    "\n",
    "    ram *= 1.3 # Correction\n",
    "\n",
    "    return ram*nb_bytes # + inconnue à déterminer dans la partie suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_chain = 20\n",
    "nb_iter = 500\n",
    "nb_param = 4\n",
    "nb_cells = 100\n",
    "nb_times = 1309\n",
    "nb_layer = 1\n",
    "\n",
    "n_sous_ech_iter = 10\n",
    "n_sous_ech_space = 1\n",
    "n_sous_ech_time = 1\n",
    "\n",
    "# ram_est = ram_estimation(nb_iter, nb_chain, nb_cells, nb_times, nb_layer, )\n",
    "# print(\"Estimation de la mémoire recquise (en Mo) : \", ram_est /1e6)\n",
    "\n",
    "# all_priors = [\n",
    "#     ['Couche 1', 0.4, priors_couche_1]\n",
    "# ]\n",
    "\n",
    "# if not isinstance(all_priors, AllPriors):\n",
    "#     all_priors = AllPriors([LayerPriors(*conv(layer)) for layer in all_priors])\n",
    "\n",
    "# col.compute_dream_mcmc_without_sigma2(\n",
    "#     nb_iter,\n",
    "#     all_priors,\n",
    "#     nb_cells,\n",
    "#     n_sous_ech_iter=n_sous_ech_iter,\n",
    "#     n_sous_ech_space=n_sous_ech_space,\n",
    "#     n_sous_ech_time=n_sous_ech_time,\n",
    "#     nb_chain=nb_chain,\n",
    "#     verbose=True\n",
    "# )\n",
    "# process = psutil.Process()\n",
    "# print(f\"Après la fin de l'exécution - Utilisation de la mémoire (en Mo) : {process.memory_info().rss /1e6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1 : l'ordinateur propose un pas de sous-échantillonnage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propose_n_iter_sous_ech(nb_iter, nb_chain, nb_cells, nb_times, nb_layer, n_sous_ech_space=1, n_sous_ech_time=1, nb_bytes=4):\n",
    "    n_sous_ech_iter = 10\n",
    "    while ram_estimation(nb_iter, nb_chain, nb_cells, nb_times, nb_layer, n_sous_ech_iter, n_sous_ech_space, n_sous_ech_time, nb_bytes) > 2e9:\n",
    "        n_sous_ech_iter += 1\n",
    "    print(f\"You should use n_sous_ech_iter = \", n_sous_ech_iter)\n",
    "    return n_sous_ech_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2 : l'utilisateur entre lui-même les pas de sous-échantillonnage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avertissement en cas de dépassement du seuil de mémoire vive (2Go) et confirmation de continuation. En cas de refus, proposer un pas de sous-échantillonnage en itérations MCMC possible en conservant les autres pas de sous-échantillonnage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warning_ram(nb_iter, nb_chain, nb_cells, nb_times, nb_layer, n_sous_ech_iter=10, n_sous_ech_space=1, n_sous_ech_time=1, nb_bytes=4):\n",
    "    \"\"\"\n",
    "    Input : Parameters of MCMC\n",
    "    Output : Bool - Do we compute MCMC ?\n",
    "             Parameters - if bool, parameters used in the MCMC we are about to compute.\n",
    "    \"\"\"\n",
    "    ram_est = ram_estimation(nb_iter, nb_chain, nb_cells, nb_times, nb_layer, n_sous_ech_iter, n_sous_ech_space, n_sous_ech_time, nb_bytes)\n",
    "    if ram_est > 2e9:\n",
    "        while True:\n",
    "            user_input = input(f\"// WARNING - The given parameters recquire {ram_est/1e9} > 2Go RAM for the MCMC inversions \\\\ \\n Input 0 if you want to continue anyway \\n Input 1 if you want the computer to automatically choose the parameters in order to be under 2Go RAM \\n Input 2 if you want to stop the algorithm.\")\n",
    "            print(f\"// WARNING - The given parameters recquire {ram_est/1e9} > 2Go RAM for the MCMC inversions \\n Input 0 if you want to continue anyway \\n Input 1 if you want the computer to automatically choose the parameters in order to be under 2Go RAM \\n Input 2 if you want to stop the algorithm.\")\n",
    "\n",
    "            # Vérifie si l'entrée est valide\n",
    "            if user_input in ('0', '1', '2'):\n",
    "                break  # Sort de la boucle si l'entrée est valide\n",
    "            else:\n",
    "                print(\"Entrée invalide. Veuillez entrer 0; 1 ou 2.\")\n",
    "\n",
    "        if user_input == 0:\n",
    "            # Continue anyway\n",
    "            return True, [nb_iter, nb_chain, nb_cells, nb_times, nb_layer, n_sous_ech_iter, n_sous_ech_space, n_sous_ech_time, nb_bytes]\n",
    "        \n",
    "        elif user_input == 1:\n",
    "            # Compute parameters in order to use less than 2Go RAM for the MCMC inversions.\n",
    "            parameters = ...\n",
    "            return True, parameters\n",
    "        \n",
    "        else:\n",
    "            # Stop the algorithm\n",
    "            return False, []\n",
    "        \n",
    "    else:\n",
    "        return True, [nb_iter, nb_chain, nb_cells, nb_times, nb_layer, n_sous_ech_iter, n_sous_ech_space, n_sous_ech_time, nb_bytes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// WARNING - The given parameters recquire 81.78432812160001 > 2Go RAM for the MCMC inversions \\ \n",
      " Input 0 if you want to continue anyway \n",
      " Input 1 if you want the computer to automatically choose the parameters in order to be under 2Go RAM \n",
      " Input 2 if you want to stop the algorithm.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, [])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_iter = 30000\n",
    "warning_ram(nb_iter, nb_chain, nb_cells, nb_times, nb_layer, n_sous_ech_iter, n_sous_ech_space, n_sous_ech_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
